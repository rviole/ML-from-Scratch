{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_SingleOutput:\n",
    "    def __init__(self, input_dim, output_dim=1, verbose=False):\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = 1\n",
    "\n",
    "        # 0.1 ~ 1.1 | 0.1 is to avoid 0 weights and biases\n",
    "        self.bias = np.round(np.random.random() + 0.1, 2)\n",
    "        self.weights = np.round(np.random.random(input_dim) + 0.1, 2)\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"Dense_SingleOutput layer with input_dim: {self.input_dim} and output_dim: 1\"\n",
    "            )\n",
    "            print(f\"Initial weights: {self.weights}\")\n",
    "            print(f\"Initial bias: {self.bias}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return np.dot(self.weights, x.T) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.array([[1, 4], [2, 3], [3, 5]])\n",
    "# y = np.array([10, 9, 14])\n",
    "\n",
    "# model = Dense_SingleOutput(input_dim=2, verbose=True)\n",
    "\n",
    "\n",
    "# print(model.forward(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, learning_rate=0.01, beta_1=0.85, beta_2=0.99):\n",
    "        self.lr = learning_rate\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        \n",
    "        self.m = 0 \n",
    "        self.v = 0\n",
    "        \n",
    "        self.m_prev = 0\n",
    "        self.v_prev = 0\n",
    "        \n",
    "    def adam(self, gradients:list, epoch):\n",
    "        self.prev_m = self.m\n",
    "        self.prev_v = self.v\n",
    "        \n",
    "        self.m = self.beta_1 * self.prev_m + (1 - self.beta_1) * gradients\n",
    "        self.v = self.beta_2 * self.prev_v + (1 - self.beta_2) * (gradients**2)\n",
    "        \n",
    "        m_hat = self.m / (1 - self.beta_1 ** (epoch+1))\n",
    "        v_hat = self.v / (1 - self.beta_2 ** (epoch+1))\n",
    "        \n",
    "        \n",
    "        learning_rate = self.lr / (np.sqrt(v_hat) + 1e-8)\n",
    "        return learning_rate * m_hat      \n",
    "        \n",
    "        \n",
    "    def step(self, parameters:list, gradients:list, epoch):\n",
    "        parameters = np.array(parameters).flatten()\n",
    "        gradients = np.array(gradients).flatten()\n",
    "        \n",
    "        new_parameters = []\n",
    "        for param, gradient in zip(parameters, gradients):\n",
    "            update = self.adam(gradient, epoch)\n",
    "            param -= update\n",
    "            new_parameters.append(param)\n",
    "        return np.array(new_parameters)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSELoss:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def calculate_loss(self, y_pred, y_true):\n",
    "        return np.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "    def calculate_gradient_coeff(self, y_pred, y_true, X):\n",
    "        errors = y_pred - y_true\n",
    "        print(errors.shape, X.shape)\n",
    "        return (2 / len(y_true)) * np.dot(errors, X)\n",
    "\n",
    "    def calculate_gradient_bias(self, y_pred, y_true):\n",
    "        errors = y_pred - y_true\n",
    "        return (2 / len(y_true)) * np.sum(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense_SingleOutput layer with input_dim: 2 and output_dim: 1\n",
      "Initial weights: [0.65 0.33]\n",
      "Initial bias: 0.14\n",
      "(3,) (3, 2)\n",
      "Epoch: 0 | Loss: 23.8425\n",
      "(3,) (3, 2)\n",
      "Epoch: 1 | Loss: 22.8521\n",
      "(3,) (3, 2)\n",
      "Epoch: 2 | Loss: 21.9062\n",
      "(3,) (3, 2)\n",
      "Epoch: 3 | Loss: 21.0607\n",
      "(3,) (3, 2)\n",
      "Epoch: 4 | Loss: 20.3054\n",
      "(3,) (3, 2)\n",
      "Epoch: 5 | Loss: 19.6247\n",
      "(3,) (3, 2)\n",
      "Epoch: 6 | Loss: 19.0044\n",
      "(3,) (3, 2)\n",
      "Epoch: 7 | Loss: 18.4331\n",
      "(3,) (3, 2)\n",
      "Epoch: 8 | Loss: 17.9014\n",
      "(3,) (3, 2)\n",
      "Epoch: 9 | Loss: 17.4024\n",
      "(3,) (3, 2)\n",
      "Epoch: 10 | Loss: 16.9303\n",
      "(3,) (3, 2)\n",
      "Epoch: 11 | Loss: 16.4807\n",
      "(3,) (3, 2)\n",
      "Epoch: 12 | Loss: 16.0501\n",
      "(3,) (3, 2)\n",
      "Epoch: 13 | Loss: 15.6358\n",
      "(3,) (3, 2)\n",
      "Epoch: 14 | Loss: 15.2354\n",
      "(3,) (3, 2)\n",
      "Epoch: 15 | Loss: 14.8473\n",
      "(3,) (3, 2)\n",
      "Epoch: 16 | Loss: 14.4700\n",
      "(3,) (3, 2)\n",
      "Epoch: 17 | Loss: 14.1024\n",
      "(3,) (3, 2)\n",
      "Epoch: 18 | Loss: 13.7436\n",
      "(3,) (3, 2)\n",
      "Epoch: 19 | Loss: 13.3928\n",
      "(3,) (3, 2)\n",
      "Epoch: 20 | Loss: 13.0494\n",
      "(3,) (3, 2)\n",
      "Epoch: 21 | Loss: 12.7129\n",
      "(3,) (3, 2)\n",
      "Epoch: 22 | Loss: 12.3830\n",
      "(3,) (3, 2)\n",
      "Epoch: 23 | Loss: 12.0593\n",
      "(3,) (3, 2)\n",
      "Epoch: 24 | Loss: 11.7414\n",
      "(3,) (3, 2)\n",
      "Epoch: 25 | Loss: 11.4293\n",
      "(3,) (3, 2)\n",
      "Epoch: 26 | Loss: 11.1226\n",
      "(3,) (3, 2)\n",
      "Epoch: 27 | Loss: 10.8214\n",
      "(3,) (3, 2)\n",
      "Epoch: 28 | Loss: 10.5253\n",
      "(3,) (3, 2)\n",
      "Epoch: 29 | Loss: 10.2344\n",
      "(3,) (3, 2)\n",
      "Epoch: 30 | Loss: 9.9485\n",
      "(3,) (3, 2)\n",
      "Epoch: 31 | Loss: 9.6676\n",
      "(3,) (3, 2)\n",
      "Epoch: 32 | Loss: 9.3917\n",
      "(3,) (3, 2)\n",
      "Epoch: 33 | Loss: 9.1205\n",
      "(3,) (3, 2)\n",
      "Epoch: 34 | Loss: 8.8542\n",
      "(3,) (3, 2)\n",
      "Epoch: 35 | Loss: 8.5927\n",
      "(3,) (3, 2)\n",
      "Epoch: 36 | Loss: 8.3360\n",
      "(3,) (3, 2)\n",
      "Epoch: 37 | Loss: 8.0839\n",
      "(3,) (3, 2)\n",
      "Epoch: 38 | Loss: 7.8366\n",
      "(3,) (3, 2)\n",
      "Epoch: 39 | Loss: 7.5940\n",
      "(3,) (3, 2)\n",
      "Epoch: 40 | Loss: 7.3560\n",
      "(3,) (3, 2)\n",
      "Epoch: 41 | Loss: 7.1226\n",
      "(3,) (3, 2)\n",
      "Epoch: 42 | Loss: 6.8939\n",
      "(3,) (3, 2)\n",
      "Epoch: 43 | Loss: 6.6698\n",
      "(3,) (3, 2)\n",
      "Epoch: 44 | Loss: 6.4502\n",
      "(3,) (3, 2)\n",
      "Epoch: 45 | Loss: 6.2352\n",
      "(3,) (3, 2)\n",
      "Epoch: 46 | Loss: 6.0248\n",
      "(3,) (3, 2)\n",
      "Epoch: 47 | Loss: 5.8189\n",
      "(3,) (3, 2)\n",
      "Epoch: 48 | Loss: 5.6174\n",
      "(3,) (3, 2)\n",
      "Epoch: 49 | Loss: 5.4205\n",
      "(3,) (3, 2)\n",
      "Epoch: 50 | Loss: 5.2280\n",
      "(3,) (3, 2)\n",
      "Epoch: 51 | Loss: 5.0399\n",
      "(3,) (3, 2)\n",
      "Epoch: 52 | Loss: 4.8563\n",
      "(3,) (3, 2)\n",
      "Epoch: 53 | Loss: 4.6770\n",
      "(3,) (3, 2)\n",
      "Epoch: 54 | Loss: 4.5021\n",
      "(3,) (3, 2)\n",
      "Epoch: 55 | Loss: 4.3314\n",
      "(3,) (3, 2)\n",
      "Epoch: 56 | Loss: 4.1651\n",
      "(3,) (3, 2)\n",
      "Epoch: 57 | Loss: 4.0030\n",
      "(3,) (3, 2)\n",
      "Epoch: 58 | Loss: 3.8452\n",
      "(3,) (3, 2)\n",
      "Epoch: 59 | Loss: 3.6915\n",
      "(3,) (3, 2)\n",
      "Epoch: 60 | Loss: 3.5420\n",
      "(3,) (3, 2)\n",
      "Epoch: 61 | Loss: 3.3966\n",
      "(3,) (3, 2)\n",
      "Epoch: 62 | Loss: 3.2552\n",
      "(3,) (3, 2)\n",
      "Epoch: 63 | Loss: 3.1179\n",
      "(3,) (3, 2)\n",
      "Epoch: 64 | Loss: 2.9846\n",
      "(3,) (3, 2)\n",
      "Epoch: 65 | Loss: 2.8552\n",
      "(3,) (3, 2)\n",
      "Epoch: 66 | Loss: 2.7297\n",
      "(3,) (3, 2)\n",
      "Epoch: 67 | Loss: 2.6081\n",
      "(3,) (3, 2)\n",
      "Epoch: 68 | Loss: 2.4903\n",
      "(3,) (3, 2)\n",
      "Epoch: 69 | Loss: 2.3762\n",
      "(3,) (3, 2)\n",
      "Epoch: 70 | Loss: 2.2658\n",
      "(3,) (3, 2)\n",
      "Epoch: 71 | Loss: 2.1591\n",
      "(3,) (3, 2)\n",
      "Epoch: 72 | Loss: 2.0560\n",
      "(3,) (3, 2)\n",
      "Epoch: 73 | Loss: 1.9564\n",
      "(3,) (3, 2)\n",
      "Epoch: 74 | Loss: 1.8603\n",
      "(3,) (3, 2)\n",
      "Epoch: 75 | Loss: 1.7676\n",
      "(3,) (3, 2)\n",
      "Epoch: 76 | Loss: 1.6783\n",
      "(3,) (3, 2)\n",
      "Epoch: 77 | Loss: 1.5924\n",
      "(3,) (3, 2)\n",
      "Epoch: 78 | Loss: 1.5096\n",
      "(3,) (3, 2)\n",
      "Epoch: 79 | Loss: 1.4301\n",
      "(3,) (3, 2)\n",
      "Epoch: 80 | Loss: 1.3537\n",
      "(3,) (3, 2)\n",
      "Epoch: 81 | Loss: 1.2803\n",
      "(3,) (3, 2)\n",
      "Epoch: 82 | Loss: 1.2100\n",
      "(3,) (3, 2)\n",
      "Epoch: 83 | Loss: 1.1426\n",
      "(3,) (3, 2)\n",
      "Epoch: 84 | Loss: 1.0780\n",
      "(3,) (3, 2)\n",
      "Epoch: 85 | Loss: 1.0163\n",
      "(3,) (3, 2)\n",
      "Epoch: 86 | Loss: 0.9573\n",
      "(3,) (3, 2)\n",
      "Epoch: 87 | Loss: 0.9010\n",
      "(3,) (3, 2)\n",
      "Epoch: 88 | Loss: 0.8472\n",
      "(3,) (3, 2)\n",
      "Epoch: 89 | Loss: 0.7960\n",
      "(3,) (3, 2)\n",
      "Epoch: 90 | Loss: 0.7472\n",
      "(3,) (3, 2)\n",
      "Epoch: 91 | Loss: 0.7009\n",
      "(3,) (3, 2)\n",
      "Epoch: 92 | Loss: 0.6568\n",
      "(3,) (3, 2)\n",
      "Epoch: 93 | Loss: 0.6150\n",
      "(3,) (3, 2)\n",
      "Epoch: 94 | Loss: 0.5754\n",
      "(3,) (3, 2)\n",
      "Epoch: 95 | Loss: 0.5379\n",
      "(3,) (3, 2)\n",
      "Epoch: 96 | Loss: 0.5024\n",
      "(3,) (3, 2)\n",
      "Epoch: 97 | Loss: 0.4689\n",
      "(3,) (3, 2)\n",
      "Epoch: 98 | Loss: 0.4373\n",
      "(3,) (3, 2)\n",
      "Epoch: 99 | Loss: 0.4075\n"
     ]
    }
   ],
   "source": [
    "class Model:\n",
    "    def __init__(self, layer):\n",
    "        self.layer = layer  # not initialized\n",
    "        self.initiated = False\n",
    "        self.compiled = False\n",
    "\n",
    "    def compile(self, loss, optimizer):\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.compiled = True\n",
    "\n",
    "    def _forward(self, x):\n",
    "        if not self.initiated:\n",
    "            raise Exception(\"Model not initiated - call `fit()` method first\")\n",
    "\n",
    "        return self.layer.forward(x)\n",
    "\n",
    "    def _backward(self, y_pred, y_real, X):\n",
    "        if not self.initiated:\n",
    "            raise Exception(\"Model not initiated - call `fit()` method first\")\n",
    "\n",
    "        loss = self.loss.calculate_loss(y_pred, y_real)\n",
    "        gradient_coeff = self.loss.calculate_gradient_coeff(y_pred, y_real, X)\n",
    "        gradient_bias = self.loss.calculate_gradient_bias(y_pred, y_real)\n",
    "\n",
    "        return loss, gradient_coeff, gradient_bias\n",
    "\n",
    "    def fit(self, X, y, epochs=100):\n",
    "        if not self.compiled:\n",
    "            raise Exception(\"Model not compiled - call `compile()` method first\")\n",
    "        input_dim = X.shape[-1]\n",
    "        self.layer = self.layer(input_dim=input_dim, verbose=True)\n",
    "        self.initiated = True\n",
    "\n",
    "        ### ------------------- ###\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # ---Forward pass---------\n",
    "            y_pred = self._forward(X)\n",
    "\n",
    "            # ---------Backward pass---------\n",
    "            loss, gradient_coeff, gradient_bias = self._backward(y_pred, y, X)\n",
    "\n",
    "            # Update weights and biases\n",
    "            self.layer.weights = self.optimizer.step(\n",
    "                self.layer.weights, gradient_coeff, epoch\n",
    "            )\n",
    "            self.layer.bias = self.optimizer.step(\n",
    "                [self.layer.bias], [gradient_bias], epoch\n",
    "            )\n",
    "\n",
    "            print(f\"Epoch: {epoch} | Loss: {loss:.4f}\")\n",
    "\n",
    "\n",
    "model = Model(layer=Dense_SingleOutput)\n",
    "model.compile(loss=MSELoss(), optimizer=Adam(learning_rate=0.01))\n",
    "\n",
    "X_train = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "y_train = np.array([4, 8, 12])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
