{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_loss(self, y_pred, y_true):\n",
    "        errors = y_pred - y_true\n",
    "        return np.mean(errors**2)\n",
    "\n",
    "    def get_coeff_gradient(self, y_pred, y_true, X):\n",
    "        errors = y_pred - y_true\n",
    "        return (2 / len(X)) * np.dot(errors, X)\n",
    "\n",
    "    def get_bias_gradient(self, y_pred, y_true, X):\n",
    "        errors = y_pred - y_true\n",
    "        return (2 / len(X)) * np.sum(errors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(\n",
    "        self,\n",
    "        param,\n",
    "        lr=0.01,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "    ):\n",
    "        self.param = param\n",
    "        self.beta_m = beta_1\n",
    "        self.beta_v = beta_2\n",
    "        self.lr = lr\n",
    "\n",
    "        # other parameters\n",
    "        self.momentum = 0\n",
    "        self.prev_momentum = 0\n",
    "        self.v = 0\n",
    "        self.prev_v = 0\n",
    "\n",
    "    def step(self, gradient, epoch):\n",
    "        self.prev_momentum = self.momentum\n",
    "        self.prev_v = self.v\n",
    "\n",
    "        # calculate the moving average of the momentum and the squared gradients\n",
    "        self.momentum = (self.beta_m * self.prev_momentum) + (\n",
    "            1 - self.beta_m\n",
    "        ) * gradient\n",
    "        self.v = (self.beta_v * self.prev_v) + (1 - self.beta_v) * (gradient**2)\n",
    "\n",
    "        # bias correction\n",
    "        momentum_hat = self.momentum / (1 - self.beta_m ** (epoch + 1))\n",
    "        v_hat = self.v / (1 - self.beta_v ** (epoch + 1))\n",
    "\n",
    "        learning_rate = self.lr / (np.sqrt(v_hat) + 1e-8)\n",
    "        self.param -= learning_rate * momentum_hat\n",
    "\n",
    "    def get_param(self):\n",
    "        return self.param\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "    def __init__(self, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "        # add bool to check if the layer has been initialized\n",
    "        self.initialized = False\n",
    "\n",
    "    def forward(self, X):\n",
    "        if not self.initialized:\n",
    "            raise Exception(\"Layer not initialized\")\n",
    "        return np.dot(self.weights, X.T) + self.bias\n",
    "\n",
    "    def initialize(self, input_dim, output_dim=1):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = 1\n",
    "\n",
    "        self.weights = np.random.randn(self.input_dim)\n",
    "        self.bias = np.random.randn(1)\n",
    "        if self.verbose:\n",
    "            print(\"Weights: \", self.weights, \"Shape: \", self.weights.shape)\n",
    "            print(\"Bias: \", self.bias, \"Shape: \", self.bias.shape)\n",
    "        \n",
    "        self.initialized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, layer, loss, otimizer):\n",
    "        self.layer = layer(verbose=False)\n",
    "        self.loss = loss()\n",
    "        self.optimizer = otimizer\n",
    "        self.initialized = False\n",
    "\n",
    "    def forward(self, X):\n",
    "        if not self.initialized:\n",
    "            raise Exception(\"Model not initialized. Please call the fit method\")\n",
    "        return self.layer.forward(X)\n",
    "\n",
    "    def backward(self, y_pred, y_true, X):\n",
    "        if not self.initialized:\n",
    "            raise Exception(\"Model not initialized. Please call the fit method\")\n",
    "        # Get the gradient\n",
    "        coeff_gradient = self.loss.get_coeff_gradient(y_pred, y_true, X)\n",
    "        bias_gradient = self.loss.get_bias_gradient(y_pred, y_true, X)\n",
    "        return coeff_gradient, bias_gradient\n",
    "\n",
    "    def fit(self, X, y, epochs=100):\n",
    "        # Initialize the layer\n",
    "        input_dim = X.shape[-1]\n",
    "        self.layer.initialize(input_dim)\n",
    "\n",
    "        # initialize the optimizers\n",
    "        self.optimizers = [\n",
    "            self.optimizer(param) for param in [*self.layer.weights, self.layer.bias]\n",
    "        ]\n",
    "        self.initialized = True\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for idx, x_i in enumerate(X):\n",
    "\n",
    "                self.layer.weights = [\n",
    "                    optimizer.get_param() for optimizer in self.optimizers[:-1]\n",
    "                ]\n",
    "                self.layer.bias = self.optimizers[-1].get_param()\n",
    "\n",
    "                y_i = y[idx]\n",
    "                # Forward pass\n",
    "                # [0] IS BECAUSE of bias = [b] the float turns into [float] so we extract float by [float][0]\n",
    "                y_i_pred = self.forward(x_i)[0]\n",
    "\n",
    "                loss = self.loss.get_loss(y_i_pred, y[idx])\n",
    "                print(f\"\\nEpoch: {epoch}.{idx} | Loss: {loss}\")\n",
    "\n",
    "                # Backward pass\n",
    "                coeff_gradients, bias_gradient = self.backward(y_i_pred, y_i, x_i)\n",
    "\n",
    "                # Update the weights\n",
    "                for idx, optimizer in enumerate(self.optimizers[:-1]):\n",
    "                    optimizer.step(coeff_gradients[idx], epoch)\n",
    "\n",
    "                self.optimizers[-1].step(bias_gradient, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0.0 | Loss: 7.963379690707535\n",
      "\n",
      "Epoch: 0.1 | Loss: 5.508233636045702\n",
      "\n",
      "Epoch: 0.2 | Loss: 3.2590931017218865\n",
      "\n",
      "Epoch: 0.3 | Loss: 1.411517304048891\n",
      "\n",
      "Epoch: 0.4 | Loss: 0.2409884110619407\n",
      "\n",
      "Epoch: 1.0 | Loss: 6.409892370527004\n",
      "\n",
      "Epoch: 1.1 | Loss: 3.573567114555549\n",
      "\n",
      "Epoch: 1.2 | Loss: 1.4184831558821376\n",
      "\n",
      "Epoch: 1.3 | Loss: 0.18768315905070324\n",
      "\n",
      "Epoch: 1.4 | Loss: 0.14092918741545174\n",
      "\n",
      "Epoch: 2.0 | Loss: 5.15207637664007\n",
      "\n",
      "Epoch: 2.1 | Loss: 2.297517694477029\n",
      "\n",
      "Epoch: 2.2 | Loss: 0.5177376230225498\n",
      "\n",
      "Epoch: 2.3 | Loss: 0.013571754423542628\n",
      "\n",
      "Epoch: 2.4 | Loss: 0.9570414957185491\n",
      "\n",
      "Epoch: 3.0 | Loss: 4.364239400205943\n",
      "\n",
      "Epoch: 3.1 | Loss: 1.6160840140648713\n",
      "\n",
      "Epoch: 3.2 | Loss: 0.1834371262832343\n",
      "\n",
      "Epoch: 3.3 | Loss: 0.19094305089282873\n",
      "\n",
      "Epoch: 3.4 | Loss: 1.7157835645923747\n",
      "\n",
      "Epoch: 4.0 | Loss: 3.945187732538418\n",
      "\n",
      "Epoch: 4.1 | Loss: 1.303830304815382\n",
      "\n",
      "Epoch: 4.2 | Loss: 0.08119467194866739\n",
      "\n",
      "Epoch: 4.3 | Loss: 0.3390324114169334\n",
      "\n",
      "Epoch: 4.4 | Loss: 2.0951000159211555\n",
      "\n",
      "Epoch: 5.0 | Loss: 3.756174082400236\n",
      "\n",
      "Epoch: 5.1 | Loss: 1.1865818731264115\n",
      "\n",
      "Epoch: 5.2 | Loss: 0.055436955217060574\n",
      "\n",
      "Epoch: 5.3 | Loss: 0.3869871551816789\n",
      "\n",
      "Epoch: 5.4 | Loss: 2.1708144176354756\n",
      "\n",
      "Epoch: 6.0 | Loss: 3.692436835111676\n",
      "\n",
      "Epoch: 6.1 | Loss: 1.1652993879263644\n",
      "\n",
      "Epoch: 6.2 | Loss: 0.05576000110236089\n",
      "\n",
      "Epoch: 6.3 | Loss: 0.36935533664152026\n",
      "\n",
      "Epoch: 6.4 | Loss: 2.085184990438216\n",
      "\n",
      "Epoch: 7.0 | Loss: 3.6900549576887776\n",
      "\n",
      "Epoch: 7.1 | Loss: 1.1882873030952232\n",
      "\n",
      "Epoch: 7.2 | Loss: 0.06738731251456051\n",
      "\n",
      "Epoch: 7.3 | Loss: 0.3251439455877179\n",
      "\n",
      "Epoch: 7.4 | Loss: 1.9388645468632781\n",
      "\n",
      "Epoch: 8.0 | Loss: 3.71281465241636\n",
      "\n",
      "Epoch: 8.1 | Loss: 1.228129405997207\n",
      "\n",
      "Epoch: 8.2 | Loss: 0.08432906069354323\n",
      "\n",
      "Epoch: 8.3 | Loss: 0.27721800461776497\n",
      "\n",
      "Epoch: 8.4 | Loss: 1.78616133044883\n",
      "\n",
      "Epoch: 9.0 | Loss: 3.7411216860915992\n",
      "\n",
      "Epoch: 9.1 | Loss: 1.2701651737588704\n",
      "\n",
      "Epoch: 9.2 | Loss: 0.10275643425839094\n",
      "\n",
      "Epoch: 9.3 | Loss: 0.23547264525846054\n",
      "\n",
      "Epoch: 9.4 | Loss: 1.6511247809419367\n",
      "\n",
      "Epoch: 10.0 | Loss: 3.7651602755745373\n",
      "\n",
      "Epoch: 10.1 | Loss: 1.3069986942587786\n",
      "\n",
      "Epoch: 10.2 | Loss: 0.12001131231561296\n",
      "\n",
      "Epoch: 10.3 | Loss: 0.20266092032483957\n",
      "\n",
      "Epoch: 10.4 | Loss: 1.5413888505600593\n",
      "\n",
      "Epoch: 11.0 | Loss: 3.7808037312165186\n",
      "\n",
      "Epoch: 11.1 | Loss: 1.3355494185442474\n",
      "\n",
      "Epoch: 11.2 | Loss: 0.13453630130704203\n",
      "\n",
      "Epoch: 11.3 | Loss: 0.17836599257642857\n",
      "\n",
      "Epoch: 11.4 | Loss: 1.4567493217575644\n",
      "\n",
      "Epoch: 12.0 | Loss: 3.7871196751461063\n",
      "\n",
      "Epoch: 12.1 | Loss: 1.3552495170732561\n",
      "\n",
      "Epoch: 12.2 | Loss: 0.14571716439822843\n",
      "\n",
      "Epoch: 12.3 | Loss: 0.16109872660546912\n",
      "\n",
      "Epoch: 12.4 | Loss: 1.3938106435766875\n",
      "\n",
      "Epoch: 13.0 | Loss: 3.7848330980380185\n",
      "\n",
      "Epoch: 13.1 | Loss: 1.366876021775648\n",
      "\n",
      "Epoch: 13.2 | Loss: 0.1536046494714139\n",
      "\n",
      "Epoch: 13.3 | Loss: 0.14923245131555748\n",
      "\n",
      "Epoch: 13.4 | Loss: 1.3482883820315068\n",
      "\n",
      "Epoch: 14.0 | Loss: 3.775394766333767\n",
      "\n",
      "Epoch: 14.1 | Loss: 1.3718022918776995\n",
      "\n",
      "Epoch: 14.2 | Loss: 0.15862791621535977\n",
      "\n",
      "Epoch: 14.3 | Loss: 0.1413439503910549\n",
      "\n",
      "Epoch: 14.4 | Loss: 1.316052282238677\n",
      "\n",
      "Epoch: 15.0 | Loss: 3.760441413162647\n",
      "\n",
      "Epoch: 15.1 | Loss: 1.3715448216062867\n",
      "\n",
      "Epoch: 15.2 | Loss: 0.1613694435420044\n",
      "\n",
      "Epoch: 15.3 | Loss: 0.1362927956927114\n",
      "\n",
      "Epoch: 15.4 | Loss: 1.293536896333271\n",
      "\n",
      "Epoch: 16.0 | Loss: 3.7415076906675315\n",
      "\n",
      "Epoch: 16.1 | Loss: 1.3675146943695333\n",
      "\n",
      "Epoch: 16.2 | Loss: 0.16241896273092168\n",
      "\n",
      "Epoch: 16.3 | Loss: 0.1332034946414889\n",
      "\n",
      "Epoch: 16.4 | Loss: 1.2778512465489862\n",
      "\n",
      "Epoch: 17.0 | Loss: 3.719894902529854\n",
      "\n",
      "Epoch: 17.1 | Loss: 1.3609034144262144\n",
      "\n",
      "Epoch: 17.2 | Loss: 0.16229522519719644\n",
      "\n",
      "Epoch: 17.3 | Loss: 0.13142123777048173\n",
      "\n",
      "Epoch: 17.4 | Loss: 1.2667531906762748\n",
      "\n",
      "Epoch: 18.0 | Loss: 3.6966323522339892\n",
      "\n",
      "Epoch: 18.1 | Loss: 1.3526506496808057\n",
      "\n",
      "Epoch: 18.2 | Loss: 0.1614153257871752\n",
      "\n",
      "Epoch: 18.3 | Loss: 0.13046699213016083\n",
      "\n",
      "Epoch: 18.4 | Loss: 1.2585685218947351\n",
      "\n",
      "Epoch: 19.0 | Loss: 3.672489122757051\n",
      "\n",
      "Epoch: 19.1 | Loss: 1.343457140097749\n",
      "\n",
      "Epoch: 19.2 | Loss: 0.16009255582833795\n",
      "\n",
      "Epoch: 19.3 | Loss: 0.12999894518399657\n",
      "\n",
      "Epoch: 19.4 | Loss: 1.2520929162533203\n",
      "\n",
      "Epoch: 20.0 | Loss: 3.6480096797550647\n",
      "\n",
      "Epoch: 20.1 | Loss: 1.3338187828487258\n",
      "\n",
      "Epoch: 20.2 | Loss: 0.1585486591120822\n",
      "\n",
      "Epoch: 20.3 | Loss: 0.12978084739667395\n",
      "\n",
      "Epoch: 20.4 | Loss: 1.2464948325578638\n",
      "\n",
      "Epoch: 21.0 | Loss: 3.6235574118349145\n",
      "\n",
      "Epoch: 21.1 | Loss: 1.324067386135464\n",
      "\n",
      "Epoch: 21.2 | Loss: 0.15693144649524512\n",
      "\n",
      "Epoch: 21.3 | Loss: 0.12965624913548646\n",
      "\n",
      "Epoch: 21.4 | Loss: 1.241227806823355\n",
      "\n",
      "Epoch: 22.0 | Loss: 3.5993573214108556\n",
      "\n",
      "Epoch: 22.1 | Loss: 1.3144101067031644\n",
      "\n",
      "Epoch: 22.2 | Loss: 0.15533268918190524\n",
      "\n",
      "Epoch: 22.3 | Loss: 0.1295276242430329\n",
      "\n",
      "Epoch: 22.4 | Loss: 1.2359556720330758\n",
      "\n",
      "Epoch: 23.0 | Loss: 3.575533576459725\n",
      "\n",
      "Epoch: 23.1 | Loss: 1.3049637702929358\n",
      "\n",
      "Epoch: 23.2 | Loss: 0.1538038628127428\n",
      "\n",
      "Epoch: 23.3 | Loss: 0.12933964011703147\n",
      "\n",
      "Epoch: 23.4 | Loss: 1.230491561772799\n",
      "\n",
      "Epoch: 24.0 | Loss: 3.552140335493394\n",
      "\n",
      "Epoch: 24.1 | Loss: 1.2957827743623798\n",
      "\n",
      "Epoch: 24.2 | Loss: 0.15236889440011406\n",
      "\n",
      "Epoch: 24.3 | Loss: 0.12906601402133436\n",
      "\n",
      "Epoch: 24.4 | Loss: 1.2247500466483736\n",
      "\n",
      "Epoch: 25.0 | Loss: 3.5291857732028764\n",
      "\n",
      "Epoch: 25.1 | Loss: 1.28688064474606\n",
      "\n",
      "Epoch: 25.2 | Loss: 0.1510339029398316\n",
      "\n",
      "Epoch: 25.3 | Loss: 0.12869946375278576\n",
      "\n",
      "Epoch: 25.4 | Loss: 1.2187109333778545\n",
      "\n",
      "Epoch: 26.0 | Loss: 3.506649997471062\n",
      "\n",
      "Epoch: 26.1 | Loss: 1.2782459811458255\n",
      "\n",
      "Epoch: 26.2 | Loss: 0.14979430545764827\n",
      "\n",
      "Epoch: 26.3 | Loss: 0.12824427413541298\n",
      "\n",
      "Epoch: 26.4 | Loss: 1.2123928892416684\n",
      "\n",
      "Epoch: 27.0 | Loss: 3.4844978576251666\n",
      "\n",
      "Epoch: 27.1 | Loss: 1.2698537706246074\n",
      "\n",
      "Epoch: 27.2 | Loss: 0.14863978427739913\n",
      "\n",
      "Epoch: 27.3 | Loss: 0.12771100765585067\n",
      "\n",
      "Epoch: 27.4 | Loss: 1.2058349877693395\n",
      "\n",
      "Epoch: 28.0 | Loss: 3.4626876948650684\n",
      "\n",
      "Epoch: 28.1 | Loss: 1.2616730626395631\n",
      "\n",
      "Epoch: 28.2 | Loss: 0.14755760555022845\n",
      "\n",
      "Epoch: 28.3 | Loss: 0.12711291099850594\n",
      "\n",
      "Epoch: 28.4 | Loss: 1.1990843931733859\n",
      "\n",
      "Epoch: 29.0 | Loss: 3.441177002797911\n",
      "\n",
      "Epoch: 29.1 | Loss: 1.253671900313338\n",
      "\n",
      "Epoch: 29.2 | Loss: 0.14653471713202648\n",
      "\n",
      "Epoch: 29.3 | Loss: 0.12646361294339942\n",
      "\n",
      "Epoch: 29.4 | Loss: 1.1921886259170276\n",
      "\n",
      "Epoch: 30.0 | Loss: 3.419925824236826\n",
      "\n",
      "Epoch: 30.1 | Loss: 1.245820259003416\n",
      "\n",
      "Epoch: 30.2 | Loss: 0.145558974910138\n",
      "\n",
      "Epoch: 30.3 | Loss: 0.12577576702716498\n",
      "\n",
      "Epoch: 30.4 | Loss: 1.1851911181415073\n",
      "\n",
      "Epoch: 31.0 | Loss: 3.398898553307774\n",
      "\n",
      "Epoch: 31.1 | Loss: 1.23809159248308\n",
      "\n",
      "Epoch: 31.2 | Loss: 0.144619769582851\n",
      "\n",
      "Epoch: 31.3 | Loss: 0.12506035598394613\n",
      "\n",
      "Epoch: 31.4 | Loss: 1.1781290343597175\n",
      "\n",
      "Epoch: 32.0 | Loss: 3.3780646627100315\n",
      "\n",
      "Epoch: 32.1 | Loss: 1.2304634482009076\n",
      "\n",
      "Epoch: 32.2 | Loss: 0.14370825854452507\n",
      "\n",
      "Epoch: 32.3 | Loss: 0.12432643694647146\n",
      "\n",
      "Epoch: 32.4 | Loss: 1.1710325755766957\n",
      "\n",
      "Epoch: 33.0 | Loss: 3.3573987456261283\n",
      "\n",
      "Epoch: 33.1 | Loss: 1.222917494236305\n",
      "\n",
      "Epoch: 33.2 | Loss: 0.14281735216927796\n",
      "\n",
      "Epoch: 33.3 | Loss: 0.12358116187154035\n",
      "\n",
      "Epoch: 33.4 | Loss: 1.1639251920824776\n",
      "\n",
      "Epoch: 34.0 | Loss: 3.3368801539926825\n",
      "\n",
      "Epoch: 34.1 | Loss: 1.2154392037421469\n",
      "\n",
      "Epoch: 34.2 | Loss: 0.14194156005404404\n",
      "\n",
      "Epoch: 34.3 | Loss: 0.12282995427640746\n",
      "\n",
      "Epoch: 34.4 | Loss: 1.1568242982924308\n",
      "\n",
      "Epoch: 35.0 | Loss: 3.3164924293538633\n",
      "\n",
      "Epoch: 35.1 | Loss: 1.2080173667336507\n",
      "\n",
      "Epoch: 35.2 | Loss: 0.14107676926488433\n",
      "\n",
      "Epoch: 35.3 | Loss: 0.12207676059383019\n",
      "\n",
      "Epoch: 35.4 | Loss: 1.1497422140219917\n",
      "\n",
      "Epoch: 36.0 | Loss: 3.2962226570594577\n",
      "\n",
      "Epoch: 36.1 | Loss: 1.2006435414663204\n",
      "\n",
      "Epoch: 36.2 | Loss: 0.14022000162147683\n",
      "\n",
      "Epoch: 36.3 | Loss: 0.12132432289328514\n",
      "\n",
      "Epoch: 36.4 | Loss: 1.1426871549827795\n",
      "\n",
      "Epoch: 37.0 | Loss: 3.2760608260636443\n",
      "\n",
      "Epoch: 37.1 | Loss: 1.1933115152801952\n",
      "\n",
      "Epoch: 37.2 | Loss: 0.1393691788900228\n",
      "\n",
      "Epoch: 37.3 | Loss: 0.12057444058749944\n",
      "\n",
      "Epoch: 37.4 | Loss: 1.13566416660565\n",
      "\n",
      "Epoch: 38.0 | Loss: 3.2559992418193135\n",
      "\n",
      "Epoch: 38.1 | Loss: 1.1860168146427843\n",
      "\n",
      "Epoch: 38.2 | Loss: 0.13852291195151764\n",
      "\n",
      "Epoch: 38.3 | Loss: 0.11982820345720313\n",
      "\n",
      "Epoch: 38.4 | Loss: 1.1286759450831854\n",
      "\n",
      "Epoch: 39.0 | Loss: 3.236032015758872\n",
      "\n",
      "Epoch: 39.1 | Loss: 1.178756283459272\n",
      "\n",
      "Epoch: 39.2 | Loss: 0.13768032130856653\n",
      "\n",
      "Epoch: 39.3 | Loss: 0.11908618825401766\n",
      "\n",
      "Epoch: 39.4 | Loss: 1.1217235228094284\n",
      "\n",
      "Epoch: 40.0 | Loss: 3.2161546390080393\n",
      "\n",
      "Epoch: 40.1 | Loss: 1.1715277351960398\n",
      "\n",
      "Epoch: 40.2 | Loss: 0.13684089064930785\n",
      "\n",
      "Epoch: 40.3 | Loss: 0.11834861748862287\n",
      "\n",
      "Epoch: 40.4 | Loss: 1.1148068164502\n",
      "\n",
      "Epoch: 41.0 | Loss: 3.196363638136255\n",
      "\n",
      "Epoch: 41.1 | Loss: 1.1643296760606905\n",
      "\n",
      "Epoch: 41.2 | Loss: 0.1360043517650773\n",
      "\n",
      "Epoch: 41.3 | Loss: 0.11761548277749602\n",
      "\n",
      "Epoch: 41.4 | Loss: 1.1079250481691667\n",
      "\n",
      "Epoch: 42.0 | Loss: 3.17665630517793\n",
      "\n",
      "Epoch: 42.1 | Loss: 1.1571610918727255\n",
      "\n",
      "Epoch: 42.2 | Loss: 0.1351705972614891\n",
      "\n",
      "Epoch: 42.3 | Loss: 0.11688663709487482\n",
      "\n",
      "Epoch: 42.4 | Loss: 1.1010770567698478\n",
      "\n",
      "Epoch: 43.0 | Loss: 3.157030491521418\n",
      "\n",
      "Epoch: 43.1 | Loss: 1.1500212891662898\n",
      "\n",
      "Epoch: 43.2 | Loss: 0.1343396167064644\n",
      "\n",
      "Epoch: 43.3 | Loss: 0.1161618610568802\n",
      "\n",
      "Epoch: 43.4 | Loss: 1.0942615177433368\n",
      "\n",
      "Epoch: 44.0 | Loss: 3.1374844545451475\n",
      "\n",
      "Epoch: 44.1 | Loss: 1.1429097806071653\n",
      "\n",
      "Epoch: 44.2 | Loss: 0.13351145174586757\n",
      "\n",
      "Epoch: 44.3 | Loss: 0.115440908393403\n",
      "\n",
      "Epoch: 44.4 | Loss: 1.0874770909401128\n",
      "\n",
      "Epoch: 45.0 | Loss: 3.118016746342775\n",
      "\n",
      "Epoch: 45.1 | Loss: 1.1358262053369703\n",
      "\n",
      "Epoch: 45.2 | Loss: 0.13268616601343244\n",
      "\n",
      "Epoch: 45.3 | Loss: 0.114723535354981\n",
      "\n",
      "Epoch: 45.4 | Loss: 1.0807225128829543\n",
      "\n",
      "Epoch: 46.0 | Loss: 3.098626134995611\n",
      "\n",
      "Epoch: 46.1 | Loss: 1.1287702759250389\n",
      "\n",
      "Epoch: 46.2 | Loss: 0.13186382617395928\n",
      "\n",
      "Epoch: 46.3 | Loss: 0.11400951817327695\n",
      "\n",
      "Epoch: 46.4 | Loss: 1.0739966483430279\n",
      "\n",
      "Epoch: 47.0 | Loss: 3.079311550262445\n",
      "\n",
      "Epoch: 47.1 | Loss: 1.1217417449051805\n",
      "\n",
      "Epoch: 47.2 | Loss: 0.1310444910365958\n",
      "\n",
      "Epoch: 47.3 | Loss: 0.11329866198772734\n",
      "\n",
      "Epoch: 47.4 | Loss: 1.0672985131941775\n",
      "\n",
      "Epoch: 48.0 | Loss: 3.0600720470311336\n",
      "\n",
      "Epoch: 48.1 | Loss: 1.1147403852022488\n",
      "\n",
      "Epoch: 48.2 | Loss: 0.1302282062755746\n",
      "\n",
      "Epoch: 48.3 | Loss: 0.11259080395698674\n",
      "\n",
      "Epoch: 48.4 | Loss: 1.0606272780413126\n",
      "\n",
      "Epoch: 49.0 | Loss: 3.0409067812701727\n",
      "\n",
      "Epoch: 49.1 | Loss: 1.1077659799932449\n",
      "\n",
      "Epoch: 49.2 | Loss: 0.12941500284945257\n",
      "\n",
      "Epoch: 49.3 | Loss: 0.11188581264282373\n",
      "\n",
      "Epoch: 49.4 | Loss: 1.0539822598547188\n",
      "\n",
      "Epoch: 50.0 | Loss: 3.0218149944550983\n",
      "\n",
      "Epoch: 50.1 | Loss: 1.1008183186368135\n",
      "\n",
      "Epoch: 50.2 | Loss: 0.12860489769165384\n",
      "\n",
      "Epoch: 50.3 | Loss: 0.11118358521126669\n",
      "\n",
      "Epoch: 50.4 | Loss: 1.047362906911058\n",
      "\n",
      "Epoch: 51.0 | Loss: 3.0027960034906154\n",
      "\n",
      "Epoch: 51.1 | Loss: 1.093897196217993\n",
      "\n",
      "Epoch: 51.2 | Loss: 0.12779789564560157\n",
      "\n",
      "Epoch: 51.3 | Loss: 0.11048404354856656\n",
      "\n",
      "Epoch: 51.4 | Loss: 1.0407687807638784\n",
      "\n",
      "Epoch: 52.0 | Loss: 2.9838491939999296\n",
      "\n",
      "Epoch: 52.1 | Loss: 1.0870024149913216\n",
      "\n",
      "Epoch: 52.2 | Loss: 0.12699399193800606\n",
      "\n",
      "Epoch: 52.3 | Loss: 0.10978713003480703\n",
      "\n",
      "Epoch: 52.4 | Loss: 1.0341995377243738\n",
      "\n",
      "Epoch: 53.0 | Loss: 2.964974015520574\n",
      "\n",
      "Epoch: 53.1 | Loss: 1.0801337865777771\n",
      "\n",
      "Epoch: 53.2 | Loss: 0.12619317473088126\n",
      "\n",
      "Epoch: 53.3 | Loss: 0.10909280344692979\n",
      "\n",
      "Epoch: 53.4 | Loss: 1.0276549113909275\n",
      "\n",
      "Epoch: 54.0 | Loss: 2.9461699776526915\n",
      "\n",
      "Epoch: 54.1 | Loss: 1.073291134201053\n",
      "\n",
      "Epoch: 54.2 | Loss: 0.12539542747659616\n",
      "\n",
      "Epoch: 54.3 | Loss: 0.10840103526295111\n",
      "\n",
      "Epoch: 54.4 | Loss: 1.021134697077849\n",
      "\n",
      "Epoch: 55.0 | Loss: 2.9274366465771378\n",
      "\n",
      "Epoch: 55.1 | Loss: 1.066474294559447\n",
      "\n",
      "Epoch: 55.2 | Loss: 0.12460073093153229\n",
      "\n",
      "Epoch: 55.3 | Loss: 0.10771180649792346\n",
      "\n",
      "Epoch: 55.4 | Loss: 1.0146387385124351\n",
      "\n",
      "Epoch: 56.0 | Loss: 2.908773641622236\n",
      "\n",
      "Epoch: 56.1 | Loss: 1.0596831191448488\n",
      "\n",
      "Epoch: 56.2 | Loss: 0.12380906477356424\n",
      "\n",
      "Epoch: 56.3 | Loss: 0.1070251051072293\n",
      "\n",
      "Epoch: 56.4 | Loss: 1.00816691685067\n",
      "\n",
      "Epoch: 57.0 | Loss: 2.890180631734098\n",
      "\n",
      "Epoch: 57.1 | Loss: 1.0529174749618326\n",
      "\n",
      "Epoch: 57.2 | Loss: 0.12302040882611194\n",
      "\n",
      "Epoch: 57.3 | Loss: 0.10634092393295563\n",
      "\n",
      "Epoch: 57.4 | Loss: 1.001719141865394\n",
      "\n",
      "Epoch: 58.0 | Loss: 2.87165733181688\n",
      "\n",
      "Epoch: 58.1 | Loss: 1.0461772446856974\n",
      "\n",
      "Epoch: 58.2 | Loss: 0.12223474392534985\n",
      "\n",
      "Epoch: 58.3 | Loss: 0.10565925913539811\n",
      "\n",
      "Epoch: 58.4 | Loss: 0.9952953450543098\n",
      "\n",
      "Epoch: 59.0 | Loss: 2.853203498973569\n",
      "\n",
      "Epoch: 59.1 | Loss: 1.0394623263447464\n",
      "\n",
      "Epoch: 59.2 | Loss: 0.12145205248407615\n",
      "\n",
      "Epoch: 59.3 | Loss: 0.10498010903599733\n",
      "\n",
      "Epoch: 59.4 | Loss: 0.9888954743701361\n",
      "\n",
      "Epoch: 60.0 | Loss: 2.834818928709892\n",
      "\n",
      "Epoch: 60.1 | Loss: 1.0327726326310367\n",
      "\n",
      "Epoch: 60.2 | Loss: 0.12067231881129543\n",
      "\n",
      "Epoch: 60.3 | Loss: 0.10430347329471863\n",
      "\n",
      "Epoch: 60.4 | Loss: 0.982519490271877\n",
      "\n",
      "Epoch: 61.0 | Loss: 2.8165034511735203\n",
      "\n",
      "Epoch: 61.1 | Loss: 1.0261080899451753\n",
      "\n",
      "Epoch: 61.2 | Loss: 0.11989552924475387\n",
      "\n",
      "Epoch: 61.3 | Loss: 0.10362935234897377\n",
      "\n",
      "Epoch: 61.4 | Loss: 0.9761673628173748\n",
      "\n",
      "Epoch: 62.0 | Loss: 2.7982569274977243\n",
      "\n",
      "Epoch: 62.1 | Loss: 1.0194686372715467\n",
      "\n",
      "Epoch: 62.2 | Loss: 0.11912167214780765\n",
      "\n",
      "Epoch: 62.3 | Loss: 0.10295774704955857\n",
      "\n",
      "Epoch: 62.4 | Loss: 0.9698390695520059\n",
      "\n",
      "Epoch: 63.0 | Loss: 2.7800792463076065\n",
      "\n",
      "Epoch: 63.1 | Loss: 1.0128542249657146\n",
      "\n",
      "Epoch: 63.2 | Loss: 0.11835073781399023\n",
      "\n",
      "Epoch: 63.3 | Loss: 0.10228865843937343\n",
      "\n",
      "Epoch: 63.4 | Loss: 0.9635345939884977\n",
      "\n",
      "Epoch: 64.0 | Loss: 2.7619703204331794\n",
      "\n",
      "Epoch: 64.1 | Loss: 1.0062648135191457\n",
      "\n",
      "Epoch: 64.2 | Loss: 0.11758271831419172\n",
      "\n",
      "Epoch: 64.3 | Loss: 0.1016220876311933\n",
      "\n",
      "Epoch: 64.4 | Loss: 0.9572539245128774\n",
      "\n",
      "Epoch: 65.0 | Loss: 2.7439300838589933\n",
      "\n",
      "Epoch: 65.1 | Loss: 0.9997003723501878\n",
      "\n",
      "Epoch: 65.2 | Loss: 0.1168176073132645\n",
      "\n",
      "Epoch: 65.3 | Loss: 0.10095803575055368\n",
      "\n",
      "Epoch: 65.4 | Loss: 0.9509970535882886\n",
      "\n",
      "Epoch: 66.0 | Loss: 2.7259584889267843\n",
      "\n",
      "Epoch: 66.1 | Loss: 0.9931608786555487\n",
      "\n",
      "Epoch: 66.2 | Loss: 0.11605539987567844\n",
      "\n",
      "Epoch: 66.3 | Loss: 0.10029650391860775\n",
      "\n",
      "Epoch: 66.4 | Loss: 0.9447639771607462\n",
      "\n",
      "Epoch: 67.0 | Loss: 2.7080555037962024\n",
      "\n",
      "Epoch: 67.1 | Loss: 0.9866463163441631\n",
      "\n",
      "Epoch: 67.2 | Loss: 0.11529609227377008\n",
      "\n",
      "Epoch: 67.3 | Loss: 0.09963749325686709\n",
      "\n",
      "Epoch: 67.4 | Loss: 0.9385546941972163\n",
      "\n",
      "Epoch: 68.0 | Loss: 2.6902211101597304\n",
      "\n",
      "Epoch: 68.1 | Loss: 0.9801566750653853\n",
      "\n",
      "Epoch: 68.2 | Loss: 0.11453968180734232\n",
      "\n",
      "Epoch: 68.3 | Loss: 0.09898100490165307\n",
      "\n",
      "Epoch: 68.4 | Loss: 0.9323692063078461\n",
      "\n",
      "Epoch: 69.0 | Loss: 2.672455301201303\n",
      "\n",
      "Epoch: 69.1 | Loss: 0.9736919493358408\n",
      "\n",
      "Epoch: 69.2 | Loss: 0.11378616663957823\n",
      "\n",
      "Epoch: 69.3 | Loss: 0.0983270400204494\n",
      "\n",
      "Epoch: 69.4 | Loss: 0.9262075174201639\n",
      "\n",
      "Epoch: 70.0 | Loss: 2.65475807978356\n",
      "\n",
      "Epoch: 70.1 | Loss: 0.967252137763928\n",
      "\n",
      "Epoch: 70.2 | Loss: 0.11303554565155864\n",
      "\n",
      "Epoch: 70.3 | Loss: 0.09767559982567\n",
      "\n",
      "Epoch: 70.4 | Loss: 0.9200696334853439\n",
      "\n",
      "Epoch: 71.0 | Loss: 2.637129456845962\n",
      "\n",
      "Epoch: 71.1 | Loss: 0.9608372423671045\n",
      "\n",
      "Epoch: 71.2 | Loss: 0.11228781831575509\n",
      "\n",
      "Epoch: 71.3 | Loss: 0.0970266855836213\n",
      "\n",
      "Epoch: 71.4 | Loss: 0.9139555622049133\n",
      "\n",
      "Epoch: 72.0 | Loss: 2.6195694499947235\n",
      "\n",
      "Epoch: 72.1 | Loss: 0.9544472679750053\n",
      "\n",
      "Epoch: 72.2 | Loss: 0.11154298458761414\n",
      "\n",
      "Epoch: 72.3 | Loss: 0.09638029861802902\n",
      "\n",
      "Epoch: 72.4 | Loss: 0.9078653127721698\n",
      "\n",
      "Epoch: 73.0 | Loss: 2.602078082265319\n",
      "\n",
      "Epoch: 73.1 | Loss: 0.9480822217101655\n",
      "\n",
      "Epoch: 73.2 | Loss: 0.11080104481369576\n",
      "\n",
      "Epoch: 73.3 | Loss: 0.09573644030840531\n",
      "\n",
      "Epoch: 73.4 | Loss: 0.9017988956260343\n",
      "\n",
      "Epoch: 74.0 | Loss: 2.5846553810388517\n",
      "\n",
      "Epoch: 74.1 | Loss: 0.9417421125378171\n",
      "\n",
      "Epoch: 74.2 | Loss: 0.11006199965437234\n",
      "\n",
      "Epoch: 74.3 | Loss: 0.0950951120840786\n",
      "\n",
      "Epoch: 74.4 | Loss: 0.895756322217248\n",
      "\n",
      "Epoch: 75.0 | Loss: 2.5673013770947666\n",
      "\n",
      "Epoch: 75.1 | Loss: 0.9354269508763793\n",
      "\n",
      "Epoch: 75.2 | Loss: 0.1093258500191097\n",
      "\n",
      "Epoch: 75.3 | Loss: 0.09445631541491988\n",
      "\n",
      "Epoch: 75.4 | Loss: 0.8897376047877915\n",
      "\n",
      "Epoch: 76.0 | Loss: 2.5500161037837894\n",
      "\n",
      "Epoch: 76.1 | Loss: 0.9291367482608016\n",
      "\n",
      "Epoch: 76.2 | Loss: 0.10859259701235217\n",
      "\n",
      "Epoch: 76.3 | Loss: 0.09382005179981799\n",
      "\n",
      "Epoch: 76.4 | Loss: 0.8837427561647967\n",
      "\n",
      "Epoch: 77.0 | Loss: 2.5327995963064165\n",
      "\n",
      "Epoch: 77.1 | Loss: 0.9228715170516377\n",
      "\n",
      "Epoch: 77.2 | Loss: 0.10786224188823589\n",
      "\n",
      "Epoch: 77.3 | Loss: 0.09318632275391225\n",
      "\n",
      "Epoch: 77.4 | Loss: 0.8777717895699115\n",
      "\n",
      "Epoch: 78.0 | Loss: 2.515651891084012\n",
      "\n",
      "Epoch: 78.1 | Loss: 0.9166312701835505\n",
      "\n",
      "Epoch: 78.2 | Loss: 0.10713478601258161\n",
      "\n",
      "Epoch: 78.3 | Loss: 0.0925551297953413\n",
      "\n",
      "Epoch: 78.4 | Loss: 0.8718247184449728\n",
      "\n",
      "Epoch: 79.0 | Loss: 2.498573025211009\n",
      "\n",
      "Epoch: 79.1 | Loss: 0.9104160209477338\n",
      "\n",
      "Epoch: 79.2 | Loss: 0.10641023083083678\n",
      "\n",
      "Epoch: 79.3 | Loss: 0.09192647443218856\n",
      "\n",
      "Epoch: 79.4 | Loss: 0.8659015562941806\n",
      "\n",
      "Epoch: 80.0 | Loss: 2.4815630359781555\n",
      "\n",
      "Epoch: 80.1 | Loss: 0.9042257828035716\n",
      "\n",
      "Epoch: 80.2 | Loss: 0.10568857784090042\n",
      "\n",
      "Epoch: 80.3 | Loss: 0.09130035815008553\n",
      "\n",
      "Epoch: 80.4 | Loss: 0.8600023165428472\n",
      "\n",
      "Epoch: 81.0 | Loss: 2.464621960458002\n",
      "\n",
      "Epoch: 81.1 | Loss: 0.8980605692154343\n",
      "\n",
      "Epoch: 81.2 | Loss: 0.10496982856991752\n",
      "\n",
      "Epoch: 81.3 | Loss: 0.09067678240075688\n",
      "\n",
      "Epoch: 81.4 | Loss: 0.8541270124120277\n",
      "\n",
      "Epoch: 82.0 | Loss: 2.4477498351450464\n",
      "\n",
      "Epoch: 82.1 | Loss: 0.8919203935113156\n",
      "\n",
      "Epoch: 82.2 | Loss: 0.10425398455436607\n",
      "\n",
      "Epoch: 82.3 | Loss: 0.09005574859173089\n",
      "\n",
      "Epoch: 82.4 | Loss: 0.8482756568083721\n",
      "\n",
      "Epoch: 83.0 | Loss: 2.4309466956438652\n",
      "\n",
      "Epoch: 83.1 | Loss: 0.8858052687603409\n",
      "\n",
      "Epoch: 83.2 | Loss: 0.10354104732286573\n",
      "\n",
      "Epoch: 83.3 | Loss: 0.08943725807724408\n",
      "\n",
      "Epoch: 83.4 | Loss: 0.8424482622281706\n",
      "\n",
      "Epoch: 84.0 | Loss: 2.414212576399458\n",
      "\n",
      "Epoch: 84.1 | Loss: 0.8797152076667596\n",
      "\n",
      "Epoch: 84.2 | Loss: 0.10283101838128747\n",
      "\n",
      "Epoch: 84.3 | Loss: 0.0888213121503795\n",
      "\n",
      "Epoch: 84.4 | Loss: 0.8366448406744609\n",
      "\n",
      "Epoch: 85.0 | Loss: 2.397547510464836\n",
      "\n",
      "Epoch: 85.1 | Loss: 0.8736502224783608\n",
      "\n",
      "Epoch: 85.2 | Loss: 0.10212389919980279\n",
      "\n",
      "Epoch: 85.3 | Loss: 0.08820791203637347\n",
      "\n",
      "Epoch: 85.4 | Loss: 0.830865403585983\n",
      "\n",
      "Epoch: 86.0 | Loss: 2.3809515293014\n",
      "\n",
      "Epoch: 86.1 | Loss: 0.8676103249075485\n",
      "\n",
      "Epoch: 86.2 | Loss: 0.10141969120163176\n",
      "\n",
      "Epoch: 86.3 | Loss: 0.08759705888699255\n",
      "\n",
      "Epoch: 86.4 | Loss: 0.8251099617768124\n",
      "\n",
      "Epoch: 87.0 | Loss: 2.364424662608279\n",
      "\n",
      "Epoch: 87.1 | Loss: 0.8615955260635699\n",
      "\n",
      "Epoch: 87.2 | Loss: 0.1007183957532558\n",
      "\n",
      "Epoch: 87.3 | Loss: 0.08698875377589697\n",
      "\n",
      "Epoch: 87.4 | Loss: 0.819378525385438\n",
      "\n",
      "Epoch: 88.0 | Loss: 2.3479669381772945\n",
      "\n",
      "Epoch: 88.1 | Loss: 0.85560583639458\n",
      "\n",
      "Epoch: 88.2 | Loss: 0.10002001415592195\n",
      "\n",
      "Epoch: 88.3 | Loss: 0.0863829976948729\n",
      "\n",
      "Epoch: 88.4 | Loss: 0.8136711038322776\n",
      "\n",
      "Epoch: 89.0 | Loss: 2.3315783817704814\n",
      "\n",
      "Epoch: 89.1 | Loss: 0.8496412656384417\n",
      "\n",
      "Epoch: 89.2 | Loss: 0.09932454763832295\n",
      "\n",
      "Epoch: 89.3 | Loss: 0.08577979155080019\n",
      "\n",
      "Epoch: 89.4 | Loss: 0.8079877057845026\n",
      "\n",
      "Epoch: 90.0 | Loss: 2.3152590170175893\n",
      "\n",
      "Epoch: 90.1 | Loss: 0.8437018227812135\n",
      "\n",
      "Epoch: 90.2 | Loss: 0.09863199735027876\n",
      "\n",
      "Epoch: 90.3 | Loss: 0.08517913616329366\n",
      "\n",
      "Epoch: 90.4 | Loss: 0.8023283391273072\n",
      "\n",
      "Epoch: 91.0 | Loss: 2.299008865331208\n",
      "\n",
      "Epoch: 91.1 | Loss: 0.8377875160224767\n",
      "\n",
      "Epoch: 91.2 | Loss: 0.0979423643573685\n",
      "\n",
      "Epoch: 91.3 | Loss: 0.08458103226288115\n",
      "\n",
      "Epoch: 91.4 | Loss: 0.7966930109407724\n",
      "\n",
      "Epoch: 92.0 | Loss: 2.282827945837387\n",
      "\n",
      "Epoch: 92.1 | Loss: 0.8318983527467125\n",
      "\n",
      "Epoch: 92.2 | Loss: 0.09725564963638457\n",
      "\n",
      "Epoch: 92.3 | Loss: 0.08398548048966185\n",
      "\n",
      "Epoch: 92.4 | Loss: 0.7910817274815808\n",
      "\n",
      "Epoch: 93.0 | Loss: 2.266716275319932\n",
      "\n",
      "Epoch: 93.1 | Loss: 0.8260343394999936\n",
      "\n",
      "Epoch: 93.2 | Loss: 0.09657185407152219\n",
      "\n",
      "Epoch: 93.3 | Loss: 0.08339248139235847\n",
      "\n",
      "Epoch: 93.4 | Loss: 0.7854944941689312\n",
      "\n",
      "Epoch: 94.0 | Loss: 2.2506738681767082\n",
      "\n",
      "Epoch: 94.1 | Loss: 0.8201954819713996\n",
      "\n",
      "Epoch: 94.2 | Loss: 0.09589097845124946\n",
      "\n",
      "Epoch: 94.3 | Loss: 0.0828020354277028\n",
      "\n",
      "Epoch: 94.4 | Loss: 0.7799313155740831\n",
      "\n",
      "Epoch: 95.0 | Loss: 2.2347007363864773\n",
      "\n",
      "Epoch: 95.1 | Loss: 0.8143817849785909\n",
      "\n",
      "Epoch: 95.2 | Loss: 0.09521302346575462\n",
      "\n",
      "Epoch: 95.3 | Loss: 0.08221414296009547\n",
      "\n",
      "Epoch: 95.4 | Loss: 0.7743921954130173\n",
      "\n",
      "Epoch: 96.0 | Loss: 2.2187968894849193\n",
      "\n",
      "Epoch: 96.1 | Loss: 0.8085932524569952\n",
      "\n",
      "Epoch: 96.2 | Loss: 0.09453798970494004\n",
      "\n",
      "Epoch: 96.3 | Loss: 0.08162880426151707\n",
      "\n",
      "Epoch: 96.4 | Loss: 0.7688771365418561\n",
      "\n",
      "Epoch: 97.0 | Loss: 2.2029623345487077\n",
      "\n",
      "Epoch: 97.1 | Loss: 0.8028298874521983\n",
      "\n",
      "Epoch: 97.2 | Loss: 0.09386587765686162\n",
      "\n",
      "Epoch: 97.3 | Loss: 0.08104601951162023\n",
      "\n",
      "Epoch: 97.4 | Loss: 0.7633861409545126\n",
      "\n",
      "Epoch: 98.0 | Loss: 2.187197076186554\n",
      "\n",
      "Epoch: 98.1 | Loss: 0.7970916921151012\n",
      "\n",
      "Epoch: 98.2 | Loss: 0.09319668770659278\n",
      "\n",
      "Epoch: 98.3 | Loss: 0.08046578879799908\n",
      "\n",
      "Epoch: 98.4 | Loss: 0.757919209782439\n",
      "\n",
      "Epoch: 99.0 | Loss: 2.1715011165362834\n",
      "\n",
      "Epoch: 99.1 | Loss: 0.791378667699505\n",
      "\n",
      "Epoch: 99.2 | Loss: 0.09253042013544172\n",
      "\n",
      "Epoch: 99.3 | Loss: 0.07988811211659311\n",
      "\n",
      "Epoch: 99.4 | Loss: 0.7524763432959936\n",
      "\n",
      "Epoch: 100.0 | Loss: 2.155874455267178\n",
      "\n",
      "Epoch: 100.1 | Loss: 0.7856908145617758\n",
      "\n",
      "Epoch: 100.2 | Loss: 0.09186707512049029\n",
      "\n",
      "Epoch: 100.3 | Loss: 0.07931298937220986\n",
      "\n",
      "Epoch: 100.4 | Loss: 0.7470575409073752\n",
      "\n",
      "Epoch: 101.0 | Loss: 2.1403170895867376\n",
      "\n",
      "Epoch: 101.1 | Loss: 0.7800281321623094\n",
      "\n",
      "Epoch: 101.2 | Loss: 0.09120665273439219\n",
      "\n",
      "Epoch: 101.3 | Loss: 0.0787404203791545\n",
      "\n",
      "Epoch: 101.4 | Loss: 0.741662801174682\n",
      "\n",
      "Epoch: 102.0 | Loss: 2.1248290142513366\n",
      "\n",
      "Epoch: 102.1 | Loss: 0.7743906190685519\n",
      "\n",
      "Epoch: 102.2 | Loss: 0.09054915294541807\n",
      "\n",
      "Epoch: 102.3 | Loss: 0.07817040486192613\n",
      "\n",
      "Epoch: 102.4 | Loss: 0.7362921218071551\n",
      "\n",
      "Epoch: 103.0 | Loss: 2.1094102215800823\n",
      "\n",
      "Epoch: 103.1 | Loss: 0.7687782729593243\n",
      "\n",
      "Epoch: 103.2 | Loss: 0.0898945756177022\n",
      "\n",
      "Epoch: 103.3 | Loss: 0.07760294245600143\n",
      "\n",
      "Epoch: 103.4 | Loss: 0.7309454996712265\n",
      "\n",
      "Epoch: 104.0 | Loss: 2.0940607014714505\n",
      "\n",
      "Epoch: 104.1 | Loss: 0.7631910906302593\n",
      "\n",
      "Epoch: 104.2 | Loss: 0.08924292051164459\n",
      "\n",
      "Epoch: 104.3 | Loss: 0.07703803270865836\n",
      "\n",
      "Epoch: 104.4 | Loss: 0.725622930797336\n",
      "\n",
      "Epoch: 105.0 | Loss: 2.0787804414222077\n",
      "\n",
      "Epoch: 105.1 | Loss: 0.7576290680001908\n",
      "\n",
      "Epoch: 105.2 | Loss: 0.08859418728448573\n",
      "\n",
      "Epoch: 105.3 | Loss: 0.0764756750798621\n",
      "\n",
      "Epoch: 105.4 | Loss: 0.7203244103874072\n",
      "\n",
      "Epoch: 106.0 | Loss: 2.063569426548239\n",
      "\n",
      "Epoch: 106.1 | Loss: 0.7520922001183151\n",
      "\n",
      "Epoch: 106.2 | Loss: 0.08794837549097817\n",
      "\n",
      "Epoch: 106.3 | Loss: 0.07591586894317237\n",
      "\n",
      "Epoch: 106.4 | Loss: 0.7150499328227474\n",
      "\n",
      "Epoch: 107.0 | Loss: 2.048427639606907\n",
      "\n",
      "Epoch: 107.1 | Loss: 0.7465804811719783\n",
      "\n",
      "Epoch: 107.2 | Loss: 0.0873054845841828\n",
      "\n",
      "Epoch: 107.3 | Loss: 0.07535861358668816\n",
      "\n",
      "Epoch: 107.4 | Loss: 0.7097994916724245\n",
      "\n",
      "Epoch: 108.0 | Loss: 2.0333550610207043\n",
      "\n",
      "Epoch: 108.1 | Loss: 0.7410939044950194\n",
      "\n",
      "Epoch: 108.2 | Loss: 0.08666551391633232\n",
      "\n",
      "Epoch: 108.3 | Loss: 0.07480390821401862\n",
      "\n",
      "Epoch: 108.4 | Loss: 0.7045730797019253\n",
      "\n",
      "Epoch: 109.0 | Loss: 2.0183516689018406\n",
      "\n",
      "Epoch: 109.1 | Loss: 0.7356324625764987\n",
      "\n",
      "Epoch: 109.2 | Loss: 0.08602846273977967\n",
      "\n",
      "Epoch: 109.3 | Loss: 0.07425175194525162\n",
      "\n",
      "Epoch: 109.4 | Loss: 0.69937068888207\n",
      "\n",
      "Epoch: 110.0 | Loss: 2.003417439077626\n",
      "\n",
      "Epoch: 110.1 | Loss: 0.7301961470697637\n",
      "\n",
      "Epoch: 110.2 | Loss: 0.08539433020798584\n",
      "\n",
      "Epoch: 110.3 | Loss: 0.07370214381796275\n",
      "\n",
      "Epoch: 110.4 | Loss: 0.6941923103981131\n",
      "\n",
      "Epoch: 111.0 | Loss: 1.988552345116358\n",
      "\n",
      "Epoch: 111.1 | Loss: 0.7247849488017599\n",
      "\n",
      "Epoch: 111.2 | Loss: 0.084763115376562\n",
      "\n",
      "Epoch: 111.3 | Loss: 0.07315508278818987\n",
      "\n",
      "Epoch: 111.4 | Loss: 0.6890379346589083\n",
      "\n",
      "Epoch: 112.0 | Loss: 1.9737563583536264\n",
      "\n",
      "Epoch: 112.1 | Loss: 0.7193988577825047\n",
      "\n",
      "Epoch: 112.2 | Loss: 0.08413481720435023\n",
      "\n",
      "Epoch: 112.3 | Loss: 0.07261056773144053\n",
      "\n",
      "Epoch: 112.4 | Loss: 0.68390755130621\n",
      "\n",
      "Epoch: 113.0 | Loss: 1.9590294479188122\n",
      "\n",
      "Epoch: 113.1 | Loss: 0.7140378632146878\n",
      "\n",
      "Epoch: 113.2 | Loss: 0.08350943455451583\n",
      "\n",
      "Epoch: 113.3 | Loss: 0.07206859744368277\n",
      "\n",
      "Epoch: 113.4 | Loss: 0.6788011492239511\n",
      "\n",
      "Epoch: 114.0 | Loss: 1.9443715807616795\n",
      "\n",
      "Epoch: 114.1 | Loss: 0.7087019535033289\n",
      "\n",
      "Epoch: 114.2 | Loss: 0.08288696619566085\n",
      "\n",
      "Epoch: 114.3 | Loss: 0.07152917064232595\n",
      "\n",
      "Epoch: 114.4 | Loss: 0.6737187165475201\n",
      "\n",
      "Epoch: 115.0 | Loss: 1.9297827216789576\n",
      "\n",
      "Epoch: 115.1 | Loss: 0.7033911162654399\n",
      "\n",
      "Epoch: 115.2 | Loss: 0.08226741080295608\n",
      "\n",
      "Epoch: 115.3 | Loss: 0.0709922859672087\n",
      "\n",
      "Epoch: 115.4 | Loss: 0.6686602406729871\n",
      "\n",
      "Epoch: 116.0 | Loss: 1.9152628333407882\n",
      "\n",
      "Epoch: 116.1 | Loss: 0.6981053383396757\n",
      "\n",
      "Epoch: 116.2 | Loss: 0.08165076695926934\n",
      "\n",
      "Epoch: 116.3 | Loss: 0.07045794198154555\n",
      "\n",
      "Epoch: 116.4 | Loss: 0.6636257082662532\n",
      "\n",
      "Epoch: 117.0 | Loss: 1.9008118763169801\n",
      "\n",
      "Epoch: 117.1 | Loss: 0.692844605795939\n",
      "\n",
      "Epoch: 117.2 | Loss: 0.08103703315629496\n",
      "\n",
      "Epoch: 117.3 | Loss: 0.0699261371729023\n",
      "\n",
      "Epoch: 117.4 | Loss: 0.6586151052721126\n",
      "\n",
      "Epoch: 118.0 | Loss: 1.886429809103009\n",
      "\n",
      "Epoch: 118.1 | Loss: 0.687608903944862\n",
      "\n",
      "Epoch: 118.2 | Loss: 0.080426207795678\n",
      "\n",
      "Epoch: 118.3 | Loss: 0.06939686995411239\n",
      "\n",
      "Epoch: 118.4 | Loss: 0.6536284169231886\n",
      "\n",
      "Epoch: 119.0 | Loss: 1.8721165881456443\n",
      "\n",
      "Epoch: 119.1 | Loss: 0.6823982173472365\n",
      "\n",
      "Epoch: 119.2 | Loss: 0.07981828919013631\n",
      "\n",
      "Epoch: 119.3 | Loss: 0.06887013866421361\n",
      "\n",
      "Epoch: 119.4 | Loss: 0.6486656277487195\n",
      "\n",
      "Epoch: 120.0 | Loss: 1.8578721678682566\n",
      "\n",
      "Epoch: 120.1 | Loss: 0.6772125298232762\n",
      "\n",
      "Epoch: 120.2 | Loss: 0.0792132755645648\n",
      "\n",
      "Epoch: 120.3 | Loss: 0.06834594156933874\n",
      "\n",
      "Epoch: 120.4 | Loss: 0.6437267215832352\n",
      "\n",
      "Epoch: 121.0 | Loss: 1.8436965006956572\n",
      "\n",
      "Epoch: 121.1 | Loss: 0.6720518244617426\n",
      "\n",
      "Epoch: 121.2 | Loss: 0.07861116505712241\n",
      "\n",
      "Epoch: 121.3 | Loss: 0.06782427686361514\n",
      "\n",
      "Epoch: 121.4 | Loss: 0.6388116815750285\n",
      "\n",
      "Epoch: 122.0 | Loss: 1.8295895370785331\n",
      "\n",
      "Epoch: 122.1 | Loss: 0.6669160836289295\n",
      "\n",
      "Epoch: 122.2 | Loss: 0.07801195572032066\n",
      "\n",
      "Epoch: 122.3 | Loss: 0.0673051426700172\n",
      "\n",
      "Epoch: 122.4 | Loss: 0.6339204901945075\n",
      "\n",
      "Epoch: 123.0 | Loss: 1.815551225517371\n",
      "\n",
      "Epoch: 123.1 | Loss: 0.6618052889774674\n",
      "\n",
      "Epoch: 123.2 | Loss: 0.0774156455220748\n",
      "\n",
      "Epoch: 123.3 | Loss: 0.06678853704122278\n",
      "\n",
      "Epoch: 123.4 | Loss: 0.6290531292423283\n",
      "\n",
      "Epoch: 124.0 | Loss: 1.801581512585915\n",
      "\n",
      "Epoch: 124.1 | Loss: 0.6567194214549548\n",
      "\n",
      "Epoch: 124.2 | Loss: 0.07682223234674013\n",
      "\n",
      "Epoch: 124.3 | Loss: 0.0662744579604403\n",
      "\n",
      "Epoch: 124.4 | Loss: 0.6242095798573795\n",
      "\n",
      "Epoch: 125.0 | Loss: 1.78768034295409\n",
      "\n",
      "Epoch: 125.1 | Loss: 0.6516584613124148\n",
      "\n",
      "Epoch: 125.2 | Loss: 0.07623171399614806\n",
      "\n",
      "Epoch: 125.3 | Loss: 0.06576290334221287\n",
      "\n",
      "Epoch: 125.4 | Loss: 0.6193898225245843\n",
      "\n",
      "Epoch: 126.0 | Loss: 1.773847659410449\n",
      "\n",
      "Epoch: 126.1 | Loss: 0.6466223881125502\n",
      "\n",
      "Epoch: 126.2 | Loss: 0.07564408819058917\n",
      "\n",
      "Epoch: 126.3 | Loss: 0.06525387103320943\n",
      "\n",
      "Epoch: 126.4 | Loss: 0.6145938370825021\n",
      "\n",
      "Epoch: 127.0 | Loss: 1.760083402884026\n",
      "\n",
      "Epoch: 127.1 | Loss: 0.641611180737828\n",
      "\n",
      "Epoch: 127.2 | Loss: 0.07505935256979944\n",
      "\n",
      "Epoch: 127.3 | Loss: 0.06474735881299432\n",
      "\n",
      "Epoch: 127.4 | Loss: 0.6098216027307565\n",
      "\n",
      "Epoch: 128.0 | Loss: 1.7463875124657464\n",
      "\n",
      "Epoch: 128.1 | Loss: 0.6366248173983512\n",
      "\n",
      "Epoch: 128.2 | Loss: 0.07447750469391297\n",
      "\n",
      "Epoch: 128.3 | Loss: 0.06424336439477536\n",
      "\n",
      "Epoch: 128.4 | Loss: 0.6050730980372793\n",
      "\n",
      "Epoch: 129.0 | Loss: 1.7327599254292305\n",
      "\n",
      "Epoch: 129.1 | Loss: 0.6316632756395582\n",
      "\n",
      "Epoch: 129.2 | Loss: 0.07389854204439683\n",
      "\n",
      "Epoch: 129.3 | Loss: 0.06374188542613282\n",
      "\n",
      "Epoch: 129.4 | Loss: 0.6003483009453738\n",
      "\n",
      "Epoch: 130.0 | Loss: 1.719200577251123\n",
      "\n",
      "Epoch: 130.1 | Loss: 0.626726532349712\n",
      "\n",
      "Epoch: 130.2 | Loss: 0.07332246202495891\n",
      "\n",
      "Epoch: 130.3 | Loss: 0.0632429194897331\n",
      "\n",
      "Epoch: 130.4 | Loss: 0.5956471887805854\n",
      "\n",
      "Epoch: 131.0 | Loss: 1.7057094016308705\n",
      "\n",
      "Epoch: 131.1 | Loss: 0.6218145637672139\n",
      "\n",
      "Epoch: 131.2 | Loss: 0.07274926196244064\n",
      "\n",
      "Epoch: 131.3 | Loss: 0.06274646410401298\n",
      "\n",
      "Epoch: 131.4 | Loss: 0.590969738257387\n",
      "\n",
      "Epoch: 132.0 | Loss: 1.6922863305100055\n",
      "\n",
      "Epoch: 132.1 | Loss: 0.6169273454877268\n",
      "\n",
      "Epoch: 132.2 | Loss: 0.07217893910768135\n",
      "\n",
      "Epoch: 132.3 | Loss: 0.062252516723862866\n",
      "\n",
      "Epoch: 132.4 | Loss: 0.5863159254857274\n",
      "\n",
      "Epoch: 133.0 | Loss: 1.678931294090902\n",
      "\n",
      "Epoch: 133.1 | Loss: 0.612064852471092\n",
      "\n",
      "Epoch: 133.2 | Loss: 0.07161149063635397\n",
      "\n",
      "Epoch: 133.3 | Loss: 0.06176107474127311\n",
      "\n",
      "Epoch: 133.4 | Loss: 0.5816857259773537\n",
      "\n",
      "Epoch: 134.0 | Loss: 1.665644220855035\n",
      "\n",
      "Epoch: 134.1 | Loss: 0.6072270590480867\n",
      "\n",
      "Epoch: 134.2 | Loss: 0.07104691364980091\n",
      "\n",
      "Epoch: 134.3 | Loss: 0.06127213548597543\n",
      "\n",
      "Epoch: 134.4 | Loss: 0.577079114651992\n",
      "\n",
      "Epoch: 135.0 | Loss: 1.652425037580762\n",
      "\n",
      "Epoch: 135.1 | Loss: 0.6024139389269899\n",
      "\n",
      "Epoch: 135.2 | Loss: 0.0704852051758199\n",
      "\n",
      "Epoch: 135.3 | Loss: 0.06078569622606248\n",
      "\n",
      "Epoch: 135.4 | Loss: 0.572496065843344\n",
      "\n",
      "Epoch: 136.0 | Loss: 1.6392736693606105\n",
      "\n",
      "Epoch: 136.1 | Loss: 0.5976254651999661\n",
      "\n",
      "Epoch: 136.2 | Loss: 0.06992636216945089\n",
      "\n",
      "Epoch: 136.3 | Loss: 0.06030175416858968\n",
      "\n",
      "Epoch: 136.4 | Loss: 0.5679365533049588\n",
      "\n",
      "Epoch: 137.0 | Loss: 1.626190039618103\n",
      "\n",
      "Epoch: 137.1 | Loss: 0.5928616103492933\n",
      "\n",
      "Epoch: 137.2 | Loss: 0.06937038151372986\n",
      "\n",
      "Epoch: 137.3 | Loss: 0.05982030646016039\n",
      "\n",
      "Epoch: 137.4 | Loss: 0.5634005502158911\n",
      "\n",
      "Epoch: 138.0 | Loss: 1.6131740701241224\n",
      "\n",
      "Epoch: 138.1 | Loss: 0.5881223462533997\n",
      "\n",
      "Epoch: 138.2 | Loss: 0.06881726002042535\n",
      "\n",
      "Epoch: 138.3 | Loss: 0.05934135018749827\n",
      "\n",
      "Epoch: 138.4 | Loss: 0.5588880291862478\n",
      "\n",
      "Epoch: 139.0 | Loss: 1.6002256810128341\n",
      "\n",
      "Epoch: 139.1 | Loss: 0.5834076441927551\n",
      "\n",
      "Epoch: 139.2 | Loss: 0.06826699443075696\n",
      "\n",
      "Epoch: 139.3 | Loss: 0.058864882378006134\n",
      "\n",
      "Epoch: 139.4 | Loss: 0.5543989622625507\n",
      "\n",
      "Epoch: 140.0 | Loss: 1.5873447907971712\n",
      "\n",
      "Epoch: 140.1 | Loss: 0.5787174748555887\n",
      "\n",
      "Epoch: 140.2 | Loss: 0.06771958141608975\n",
      "\n",
      "Epoch: 140.3 | Loss: 0.05839090000029787\n",
      "\n",
      "Epoch: 140.4 | Loss: 0.5499333209329971\n",
      "\n",
      "Epoch: 141.0 | Loss: 1.574531316383915\n",
      "\n",
      "Epoch: 141.1 | Loss: 0.5740518083434618\n",
      "\n",
      "Epoch: 141.2 | Loss: 0.06717501757861778\n",
      "\n",
      "Epoch: 141.3 | Loss: 0.05791939996472625\n",
      "\n",
      "Epoch: 141.4 | Loss: 0.5454910761325201\n",
      "\n",
      "Epoch: 142.0 | Loss: 1.5617851730883436\n",
      "\n",
      "Epoch: 142.1 | Loss: 0.5694106141766905\n",
      "\n",
      "Epoch: 142.2 | Loss: 0.0666332994520179\n",
      "\n",
      "Epoch: 142.3 | Loss: 0.05745037912389632\n",
      "\n",
      "Epoch: 142.4 | Loss: 0.5410721982477698\n",
      "\n",
      "Epoch: 143.0 | Loss: 1.5491062746485083\n",
      "\n",
      "Epoch: 143.1 | Loss: 0.5647938612995951\n",
      "\n",
      "Epoch: 143.2 | Loss: 0.06609442350209421\n",
      "\n",
      "Epoch: 143.3 | Loss: 0.056983834273166535\n",
      "\n",
      "Epoch: 143.4 | Loss: 0.5366766571219334\n",
      "\n",
      "Epoch: 144.0 | Loss: 1.536494533239115\n",
      "\n",
      "Epoch: 144.1 | Loss: 0.5602015180856583\n",
      "\n",
      "Epoch: 144.2 | Loss: 0.06555838612740372\n",
      "\n",
      "Epoch: 144.3 | Loss: 0.05651976215111997\n",
      "\n",
      "Epoch: 144.4 | Loss: 0.5323044220593995\n",
      "\n",
      "Epoch: 145.0 | Loss: 1.523949859485045\n",
      "\n",
      "Epoch: 145.1 | Loss: 0.5556335523424973\n",
      "\n",
      "Epoch: 145.2 | Loss: 0.06502518365986044\n",
      "\n",
      "Epoch: 145.3 | Loss: 0.05605815944005436\n",
      "\n",
      "Epoch: 145.4 | Loss: 0.5279554618303831\n",
      "\n",
      "Epoch: 146.0 | Loss: 1.5114721624745129\n",
      "\n",
      "Epoch: 146.1 | Loss: 0.551089931316734\n",
      "\n",
      "Epoch: 146.2 | Loss: 0.06449481236533045\n",
      "\n",
      "Epoch: 146.3 | Loss: 0.05559902276642419\n",
      "\n",
      "Epoch: 146.4 | Loss: 0.5236297446753145\n",
      "\n",
      "Epoch: 147.0 | Loss: 1.499061349771891\n",
      "\n",
      "Epoch: 147.1 | Loss: 0.5465706216987297\n",
      "\n",
      "Epoch: 147.2 | Loss: 0.06396726844420525\n",
      "\n",
      "Epoch: 147.3 | Loss: 0.05514234870130115\n",
      "\n",
      "Epoch: 147.4 | Loss: 0.5193272383092236\n",
      "\n",
      "Epoch: 148.0 | Loss: 1.486717327430182\n",
      "\n",
      "Epoch: 148.1 | Loss: 0.5420755896271826\n",
      "\n",
      "Epoch: 148.2 | Loss: 0.06344254803196117\n",
      "\n",
      "Epoch: 148.3 | Loss: 0.05468813376080407\n",
      "\n",
      "Epoch: 148.4 | Loss: 0.5150479099259372\n",
      "\n",
      "Epoch: 149.0 | Loss: 1.4744400000031963\n",
      "\n",
      "Epoch: 149.1 | Loss: 0.5376048006936331\n",
      "\n",
      "Epoch: 149.2 | Loss: 0.06292064719970958\n",
      "\n",
      "Epoch: 149.3 | Loss: 0.05423637440652084\n",
      "\n",
      "Epoch: 149.4 | Loss: 0.5107917262022035\n",
      "\n",
      "Epoch: 150.0 | Loss: 1.4622292705574176\n",
      "\n",
      "Epoch: 150.1 | Loss: 0.5331582199468337\n",
      "\n",
      "Epoch: 150.2 | Loss: 0.06240156195472278\n",
      "\n",
      "Epoch: 150.3 | Loss: 0.05378706704593295\n",
      "\n",
      "Epoch: 150.4 | Loss: 0.5065586533017019\n",
      "\n",
      "Epoch: 151.0 | Loss: 1.4500850406835402\n",
      "\n",
      "Epoch: 151.1 | Loss: 0.5287358118970201\n",
      "\n",
      "Epoch: 151.2 | Loss: 0.06188528824095677\n",
      "\n",
      "Epoch: 151.3 | Loss: 0.05334020803281396\n",
      "\n",
      "Epoch: 151.4 | Loss: 0.5023486568789727\n",
      "\n",
      "Epoch: 152.0 | Loss: 1.4380072105077837\n",
      "\n",
      "Epoch: 152.1 | Loss: 0.5243375405200654\n",
      "\n",
      "Epoch: 152.2 | Loss: 0.06137182193955129\n",
      "\n",
      "Epoch: 152.3 | Loss: 0.05289579366762208\n",
      "\n",
      "Epoch: 152.4 | Loss: 0.49816170208321503\n",
      "\n",
      "Epoch: 153.0 | Loss: 1.4259956787028663\n",
      "\n",
      "Epoch: 153.1 | Loss: 0.51996336926154\n",
      "\n",
      "Epoch: 153.2 | Loss: 0.0608611588693262\n",
      "\n",
      "Epoch: 153.3 | Loss: 0.05245382019789273\n",
      "\n",
      "Epoch: 153.4 | Loss: 0.4939977535620311\n",
      "\n",
      "Epoch: 154.0 | Loss: 1.414050342498766\n",
      "\n",
      "Epoch: 154.1 | Loss: 0.5156132610406843\n",
      "\n",
      "Epoch: 154.2 | Loss: 0.06035329478725766\n",
      "\n",
      "Epoch: 154.3 | Loss: 0.05201428381860993\n",
      "\n",
      "Epoch: 154.4 | Loss: 0.4898567754650734\n",
      "\n",
      "Epoch: 155.0 | Loss: 1.4021710976932011\n",
      "\n",
      "Epoch: 155.1 | Loss: 0.5112871782542588\n",
      "\n",
      "Epoch: 155.2 | Loss: 0.059848225388950134\n",
      "\n",
      "Epoch: 155.3 | Loss: 0.051577180672574045\n",
      "\n",
      "Epoch: 155.4 | Loss: 0.4857387314475712\n",
      "\n",
      "Epoch: 156.0 | Loss: 1.3903578386618998\n",
      "\n",
      "Epoch: 156.1 | Loss: 0.5069850827803392\n",
      "\n",
      "Epoch: 156.2 | Loss: 0.05934594630909228\n",
      "\n",
      "Epoch: 156.3 | Loss: 0.05114250685076588\n",
      "\n",
      "Epoch: 156.4 | Loss: 0.4816435846738425\n",
      "\n",
      "Epoch: 157.0 | Loss: 1.3786104583685883\n",
      "\n",
      "Epoch: 157.1 | Loss: 0.5027069359819923\n",
      "\n",
      "Epoch: 157.2 | Loss: 0.05884645312190053\n",
      "\n",
      "Epoch: 157.3 | Loss: 0.05071025839269368\n",
      "\n",
      "Epoch: 157.4 | Loss: 0.47757129782066127\n",
      "\n",
      "Epoch: 158.0 | Loss: 1.3669288483748148\n",
      "\n",
      "Epoch: 158.1 | Loss: 0.49845269871089853\n",
      "\n",
      "Epoch: 158.2 | Loss: 0.05834974134156344\n",
      "\n",
      "Epoch: 158.3 | Loss: 0.05028043128673937\n",
      "\n",
      "Epoch: 158.4 | Loss: 0.4735218330805938\n",
      "\n",
      "Epoch: 159.0 | Loss: 1.355312898849516\n",
      "\n",
      "Epoch: 159.1 | Loss: 0.4942223313108709\n",
      "\n",
      "Epoch: 159.2 | Loss: 0.05785580642265526\n",
      "\n",
      "Epoch: 159.3 | Loss: 0.04985302147049687\n",
      "\n",
      "Epoch: 159.4 | Loss: 0.4694951521652733\n",
      "\n",
      "Epoch: 160.0 | Loss: 1.343762498578401\n",
      "\n",
      "Epoch: 160.1 | Loss: 0.4900157936213122\n",
      "\n",
      "Epoch: 160.2 | Loss: 0.05736464376056536\n",
      "\n",
      "Epoch: 160.3 | Loss: 0.049428024831101945\n",
      "\n",
      "Epoch: 160.4 | Loss: 0.4654912163085483\n",
      "\n",
      "Epoch: 161.0 | Loss: 1.332277534973144\n",
      "\n",
      "Epoch: 161.1 | Loss: 0.48583304498059526\n",
      "\n",
      "Epoch: 161.2 | Loss: 0.056876248691896565\n",
      "\n",
      "Epoch: 161.3 | Loss: 0.04900543720555144\n",
      "\n",
      "Epoch: 161.4 | Loss: 0.46150998626962925\n",
      "\n",
      "Epoch: 162.0 | Loss: 1.3208578940803761\n",
      "\n",
      "Epoch: 162.1 | Loss: 0.48167404422937926\n",
      "\n",
      "Epoch: 162.2 | Loss: 0.05639061649487192\n",
      "\n",
      "Epoch: 162.3 | Loss: 0.04858525438102856\n",
      "\n",
      "Epoch: 162.4 | Loss: 0.45755142233613516\n",
      "\n",
      "Epoch: 163.0 | Loss: 1.3095034605905167\n",
      "\n",
      "Epoch: 163.1 | Loss: 0.4775387497138502\n",
      "\n",
      "Epoch: 163.2 | Loss: 0.05590774238971861\n",
      "\n",
      "Epoch: 163.3 | Loss: 0.04816747209520605\n",
      "\n",
      "Epoch: 163.4 | Loss: 0.45361548432710375\n",
      "\n",
      "Epoch: 164.0 | Loss: 1.2982141178464264\n",
      "\n",
      "Epoch: 164.1 | Loss: 0.4734271192889029\n",
      "\n",
      "Epoch: 164.2 | Loss: 0.05542762153905555\n",
      "\n",
      "Epoch: 164.3 | Loss: 0.04775208603655733\n",
      "\n",
      "Epoch: 164.4 | Loss: 0.4497021315959296\n",
      "\n",
      "Epoch: 165.0 | Loss: 1.2869897478518906\n",
      "\n",
      "Epoch: 165.1 | Loss: 0.4693391103212656\n",
      "\n",
      "Epoch: 165.2 | Loss: 0.05495024904826794\n",
      "\n",
      "Epoch: 165.3 | Loss: 0.047339091844653736\n",
      "\n",
      "Epoch: 165.4 | Loss: 0.44581132303325\n",
      "\n",
      "Epoch: 166.0 | Loss: 1.27583023127997\n",
      "\n",
      "Epoch: 166.1 | Loss: 0.4652746796925667\n",
      "\n",
      "Epoch: 166.2 | Loss: 0.05447561996587152\n",
      "\n",
      "Epoch: 166.3 | Loss: 0.04692848511046125\n",
      "\n",
      "Epoch: 166.4 | Loss: 0.44194301706979483\n",
      "\n",
      "Epoch: 167.0 | Loss: 1.264735447481196\n",
      "\n",
      "Epoch: 167.1 | Loss: 0.4612337838023374\n",
      "\n",
      "Epoch: 167.2 | Loss: 0.0540037292838817\n",
      "\n",
      "Epoch: 167.3 | Loss: 0.04652026137662778\n",
      "\n",
      "Epoch: 167.4 | Loss: 0.4380971716791635\n",
      "\n",
      "Epoch: 168.0 | Loss: 1.2537052744916164\n",
      "\n",
      "Epoch: 168.1 | Loss: 0.4572163785709844\n",
      "\n",
      "Epoch: 168.2 | Loss: 0.053534571938161225\n",
      "\n",
      "Epoch: 168.3 | Loss: 0.04611441613777005\n",
      "\n",
      "Epoch: 168.4 | Loss: 0.4342737443805828\n",
      "\n",
      "Epoch: 169.0 | Loss: 1.2427395890407145\n",
      "\n",
      "Epoch: 169.1 | Loss: 0.4532224194426767\n",
      "\n",
      "Epoch: 169.2 | Loss: 0.05306814280877129\n",
      "\n",
      "Epoch: 169.3 | Loss: 0.04571094484075677\n",
      "\n",
      "Epoch: 169.4 | Loss: 0.4304726922415993\n",
      "\n",
      "Epoch: 170.0 | Loss: 1.2318382665592182\n",
      "\n",
      "Epoch: 170.1 | Loss: 0.4492518613882261\n",
      "\n",
      "Epoch: 170.2 | Loss: 0.052604436720315735\n",
      "\n",
      "Epoch: 170.3 | Loss: 0.045309842884979405\n",
      "\n",
      "Epoch: 170.4 | Loss: 0.42669397188073893\n",
      "\n",
      "Epoch: 171.0 | Loss: 1.221001181186771\n",
      "\n",
      "Epoch: 171.1 | Loss: 0.44530465890789334\n",
      "\n",
      "Epoch: 171.2 | Loss: 0.052143448442274955\n",
      "\n",
      "Epoch: 171.3 | Loss: 0.044911105622632404\n",
      "\n",
      "Epoch: 171.4 | Loss: 0.42293753947013196\n",
      "\n",
      "Epoch: 172.0 | Loss: 1.2102282057794969\n",
      "\n",
      "Epoch: 172.1 | Loss: 0.44138076603417126\n",
      "\n",
      "Epoch: 172.2 | Loss: 0.051685172689339\n",
      "\n",
      "Epoch: 172.3 | Loss: 0.04451472835896943\n",
      "\n",
      "Epoch: 172.4 | Loss: 0.4192033507380774\n",
      "\n",
      "Epoch: 173.0 | Loss: 1.1995192119174654\n",
      "\n",
      "Epoch: 173.1 | Loss: 0.4374801363345121\n",
      "\n",
      "Epoch: 173.2 | Loss: 0.051229604121737195\n",
      "\n",
      "Epoch: 173.3 | Loss: 0.04412070635258704\n",
      "\n",
      "Epoch: 173.4 | Loss: 0.415491360971619\n",
      "\n",
      "Epoch: 174.0 | Loss: 1.1888740699120315\n",
      "\n",
      "Epoch: 174.1 | Loss: 0.4336027229140243\n",
      "\n",
      "Epoch: 174.2 | Loss: 0.050776737345554296\n",
      "\n",
      "Epoch: 174.3 | Loss: 0.043729034815669816\n",
      "\n",
      "Epoch: 174.4 | Loss: 0.41180152501903333\n",
      "\n",
      "Epoch: 175.0 | Loss: 1.178292648813127\n",
      "\n",
      "Epoch: 175.1 | Loss: 0.4297484784181427\n",
      "\n",
      "Epoch: 175.2 | Loss: 0.05032656691305166\n",
      "\n",
      "Epoch: 175.3 | Loss: 0.04333970891425488\n",
      "\n",
      "Epoch: 175.4 | Loss: 0.40813379729232496\n",
      "\n",
      "Epoch: 176.0 | Loss: 1.1677748164164072\n",
      "\n",
      "Epoch: 176.1 | Loss: 0.42591735503524597\n",
      "\n",
      "Epoch: 176.2 | Loss: 0.04987908732297914\n",
      "\n",
      "Epoch: 176.3 | Loss: 0.0429527237684925\n",
      "\n",
      "Epoch: 176.4 | Loss: 0.40448813176967263\n",
      "\n",
      "Epoch: 177.0 | Loss: 1.157320439270357\n",
      "\n",
      "Epoch: 177.1 | Loss: 0.42210930449925765\n",
      "\n",
      "Epoch: 177.2 | Loss: 0.04943429302088591\n",
      "\n",
      "Epoch: 177.3 | Loss: 0.04256807445289193\n",
      "\n",
      "Epoch: 177.4 | Loss: 0.400864481997855\n",
      "\n",
      "Epoch: 178.0 | Loss: 1.146929382683297\n",
      "\n",
      "Epoch: 178.1 | Loss: 0.41832427809220984\n",
      "\n",
      "Epoch: 178.2 | Loss: 0.048992178399422354\n",
      "\n",
      "Epoch: 178.3 | Loss: 0.04218575599657268\n",
      "\n",
      "Epoch: 178.4 | Loss: 0.3972628010946548\n",
      "\n",
      "Epoch: 179.0 | Loss: 1.1366015107303158\n",
      "\n",
      "Epoch: 179.1 | Loss: 0.4145622266467825\n",
      "\n",
      "Epoch: 179.2 | Loss: 0.04855273779864197\n",
      "\n",
      "Epoch: 179.3 | Loss: 0.041805763383515895\n",
      "\n",
      "Epoch: 179.4 | Loss: 0.3936830417512304\n",
      "\n",
      "Epoch: 180.0 | Loss: 1.1263366862601443\n",
      "\n",
      "Epoch: 180.1 | Loss: 0.4108231005488202\n",
      "\n",
      "Epoch: 180.2 | Loss: 0.04811596550630562\n",
      "\n",
      "Epoch: 180.3 | Loss: 0.04142809155281025\n",
      "\n",
      "Epoch: 180.4 | Loss: 0.39012515623447114\n",
      "\n",
      "Epoch: 181.0 | Loss: 1.1161347709019525\n",
      "\n",
      "Epoch: 181.1 | Loss: 0.4071068497398082\n",
      "\n",
      "Epoch: 181.2 | Loss: 0.04768185575816635\n",
      "\n",
      "Epoch: 181.3 | Loss: 0.04105273539888807\n",
      "\n",
      "Epoch: 181.4 | Loss: 0.38658909638931244\n",
      "\n",
      "Epoch: 182.0 | Loss: 1.1059956250720988\n",
      "\n",
      "Epoch: 182.1 | Loss: 0.40341342371935013\n",
      "\n",
      "Epoch: 182.2 | Loss: 0.04725040273827415\n",
      "\n",
      "Epoch: 182.3 | Loss: 0.04067968977177365\n",
      "\n",
      "Epoch: 182.4 | Loss: 0.3830748136410679\n",
      "\n",
      "Epoch: 183.0 | Loss: 1.0959191079808202\n",
      "\n",
      "Epoch: 183.1 | Loss: 0.3997427715476056\n",
      "\n",
      "Epoch: 183.2 | Loss: 0.046821600579250604\n",
      "\n",
      "Epoch: 183.3 | Loss: 0.04030894947732125\n",
      "\n",
      "Epoch: 183.4 | Loss: 0.37958225899771253\n",
      "\n",
      "Epoch: 184.0 | Loss: 1.085905077638851\n",
      "\n",
      "Epoch: 184.1 | Loss: 0.39609484184771365\n",
      "\n",
      "Epoch: 184.2 | Loss: 0.0463954433625914\n",
      "\n",
      "Epoch: 184.3 | Loss: 0.03994050927745519\n",
      "\n",
      "Epoch: 184.4 | Loss: 0.376111383052162\n",
      "\n",
      "Epoch: 185.0 | Loss: 1.0759533908640366\n",
      "\n",
      "Epoch: 185.1 | Loss: 0.3924695828082061\n",
      "\n",
      "Epoch: 185.2 | Loss: 0.045971925118937586\n",
      "\n",
      "Epoch: 185.3 | Loss: 0.03957436389039937\n",
      "\n",
      "Epoch: 185.4 | Loss: 0.3726621359845252\n",
      "\n",
      "Epoch: 186.0 | Loss: 1.0660639032878692\n",
      "\n",
      "Epoch: 186.1 | Loss: 0.3888669421853828\n",
      "\n",
      "Epoch: 186.2 | Loss: 0.04555103982836621\n",
      "\n",
      "Epoch: 186.3 | Loss: 0.0392105079909204\n",
      "\n",
      "Epoch: 186.4 | Loss: 0.3692344675643823\n",
      "\n",
      "Epoch: 187.0 | Loss: 1.0562364693619801\n",
      "\n",
      "Epoch: 187.1 | Loss: 0.3852868673057059\n",
      "\n",
      "Epoch: 187.2 | Loss: 0.045132781420667095\n",
      "\n",
      "Epoch: 187.3 | Loss: 0.03884893621055819\n",
      "\n",
      "Epoch: 187.4 | Loss: 0.36582832715296704\n",
      "\n",
      "Epoch: 188.0 | Loss: 1.0464709423646452\n",
      "\n",
      "Epoch: 188.1 | Loss: 0.38172930506815167\n",
      "\n",
      "Epoch: 188.2 | Loss: 0.04471714377562367\n",
      "\n",
      "Epoch: 188.3 | Loss: 0.03848964313785546\n",
      "\n",
      "Epoch: 188.4 | Loss: 0.36244366370544084\n",
      "\n",
      "Epoch: 189.0 | Loss: 1.0367671744071962\n",
      "\n",
      "Epoch: 189.1 | Loss: 0.3781942019465537\n",
      "\n",
      "Epoch: 189.2 | Loss: 0.04430412072328794\n",
      "\n",
      "Epoch: 189.3 | Loss: 0.03813262331859672\n",
      "\n",
      "Epoch: 189.4 | Loss: 0.35908042577307475\n",
      "\n",
      "Epoch: 190.0 | Loss: 1.0271250164404413\n",
      "\n",
      "Epoch: 190.1 | Loss: 0.37468150399195166\n",
      "\n",
      "Epoch: 190.2 | Loss: 0.04389370604425661\n",
      "\n",
      "Epoch: 190.3 | Loss: 0.03777787125603236\n",
      "\n",
      "Epoch: 190.4 | Loss: 0.355738561505473\n",
      "\n",
      "Epoch: 191.0 | Loss: 1.0175443182610577\n",
      "\n",
      "Epoch: 191.1 | Loss: 0.37119115683491427\n",
      "\n",
      "Epoch: 191.2 | Loss: 0.043485893469943165\n",
      "\n",
      "Epoch: 191.3 | Loss: 0.03742538141111093\n",
      "\n",
      "Epoch: 191.4 | Loss: 0.3524180186527603\n",
      "\n",
      "Epoch: 192.0 | Loss: 1.0080249285179566\n",
      "\n",
      "Epoch: 192.1 | Loss: 0.36772310568786204\n",
      "\n",
      "Epoch: 192.2 | Loss: 0.04308067668285714\n",
      "\n",
      "Epoch: 192.3 | Loss: 0.037075148202712\n",
      "\n",
      "Epoch: 192.4 | Loss: 0.3491187445677688\n",
      "\n",
      "Epoch: 193.0 | Loss: 0.9985666947186197\n",
      "\n",
      "Epoch: 193.1 | Loss: 0.36427729534737435\n",
      "\n",
      "Epoch: 193.2 | Loss: 0.04267804931686769\n",
      "\n",
      "Epoch: 193.3 | Loss: 0.03672716600787074\n",
      "\n",
      "Epoch: 193.4 | Loss: 0.3458406862082294\n",
      "\n",
      "Epoch: 194.0 | Loss: 0.9891694632354395\n",
      "\n",
      "Epoch: 194.1 | Loss: 0.3608536701965037\n",
      "\n",
      "Epoch: 194.2 | Loss: 0.04227800495747831\n",
      "\n",
      "Epoch: 194.3 | Loss: 0.036381429162010086\n",
      "\n",
      "Epoch: 194.4 | Loss: 0.342583790138959\n",
      "\n",
      "Epoch: 195.0 | Loss: 0.9798330793120444\n",
      "\n",
      "Epoch: 195.1 | Loss: 0.3574521742070702\n",
      "\n",
      "Epoch: 195.2 | Loss: 0.0418805371420986\n",
      "\n",
      "Epoch: 195.3 | Loss: 0.036037931959162876\n",
      "\n",
      "Epoch: 195.4 | Loss: 0.33934800253402453\n",
      "\n",
      "Epoch: 196.0 | Loss: 0.9705573870695959\n",
      "\n",
      "Epoch: 196.1 | Loss: 0.3540727509419613\n",
      "\n",
      "Epoch: 196.2 | Loss: 0.04148563936031025\n",
      "\n",
      "Epoch: 196.3 | Loss: 0.03569666865221111\n",
      "\n",
      "Epoch: 196.4 | Loss: 0.33613326917891523\n",
      "\n",
      "Epoch: 197.0 | Loss: 0.9613422295131078\n",
      "\n",
      "Epoch: 197.1 | Loss: 0.35071534355742967\n",
      "\n",
      "Epoch: 197.2 | Loss: 0.041093305054139266\n",
      "\n",
      "Epoch: 197.3 | Loss: 0.03535763345310312\n",
      "\n",
      "Epoch: 197.4 | Loss: 0.33293953547272975\n",
      "\n",
      "Epoch: 198.0 | Loss: 0.9521874485377311\n",
      "\n",
      "Epoch: 198.1 | Loss: 0.3473798948053828\n",
      "\n",
      "Epoch: 198.2 | Loss: 0.04070352761832108\n",
      "\n",
      "Epoch: 198.3 | Loss: 0.035020820533085306\n",
      "\n",
      "Epoch: 198.4 | Loss: 0.32976674643034043\n",
      "\n",
      "Epoch: 199.0 | Loss: 0.9430928849350733\n",
      "\n",
      "Epoch: 199.1 | Loss: 0.3440663470356719\n",
      "\n",
      "Epoch: 199.2 | Loss: 0.04031630040057267\n",
      "\n",
      "Epoch: 199.3 | Loss: 0.034686224022933615\n",
      "\n",
      "Epoch: 199.4 | Loss: 0.3266148466845688\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n",
    "y = np.array([0.5 * x1 + 1.5 * x2 + 3 for x1, x2 in X])\n",
    "\n",
    "model = Model(DenseLayer, MSE, Adam)\n",
    "model.fit(X, y, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
