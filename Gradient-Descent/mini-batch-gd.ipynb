{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_loss(self, y_pred, y_true):\n",
    "        errors = y_pred - y_true\n",
    "        return np.mean(errors**2)\n",
    "\n",
    "    def get_coeff_gradient(self, y_pred, y_true, X):\n",
    "        errors = y_pred - y_true\n",
    "        return (2 / len(X)) * np.dot(errors, X)\n",
    "\n",
    "    def get_bias_gradient(self, y_pred, y_true, X):\n",
    "        errors = y_pred - y_true\n",
    "        return (2 / len(X)) * np.sum(errors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1,3) (3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.33333333, 0.06666667])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lf = MSE()\n",
    "lf.get_coeff_gradient(np.array([1,2,4]), np.array([1.2, 2.3,3]), np.array([[1,2],[1,5], [4,2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, learning_rate=0.01, beta_1=0.85, beta_2=0.99):\n",
    "        self.lr = learning_rate\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        \n",
    "        self.m = 0 \n",
    "        self.v = 0\n",
    "        \n",
    "        self.m_prev = 0\n",
    "        self.v_prev = 0\n",
    "        \n",
    "    def adam(self, gradients:list, epoch):\n",
    "        self.prev_m = self.m\n",
    "        self.prev_v = self.v\n",
    "        \n",
    "        self.m = self.beta_1 * self.prev_m + (1 - self.beta_1) * gradients\n",
    "        self.v = self.beta_2 * self.prev_v + (1 - self.beta_2) * (gradients**2)\n",
    "        \n",
    "        m_hat = self.m / (1 - self.beta_1 ** (epoch+1))\n",
    "        v_hat = self.v / (1 - self.beta_2 ** (epoch+1))\n",
    "        \n",
    "        \n",
    "        learning_rate = self.lr / (np.sqrt(v_hat) + 1e-8)\n",
    "        return learning_rate * m_hat      \n",
    "        \n",
    "        \n",
    "    def step(self, parameters:list, gradients:list, epoch):\n",
    "        parameters = np.array(parameters).flatten()\n",
    "        gradients = np.array(gradients).flatten()\n",
    "        \n",
    "        new_parameters = []\n",
    "        for param, gradient in zip(parameters, gradients):\n",
    "            update = self.adam(gradient, epoch)\n",
    "            param -= update\n",
    "            new_parameters.append(param)\n",
    "        return np.array(new_parameters)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "    def __init__(self, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "        # add bool to check if the layer has been initialized\n",
    "        self.initialized = False\n",
    "\n",
    "    def forward(self, X):\n",
    "        if not self.initialized:\n",
    "            raise Exception(\"Layer not initialized\")\n",
    "        return np.dot(self.weights, X.T) + self.bias\n",
    "\n",
    "    def initialize(self, input_dim, output_dim=1):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = 1\n",
    "\n",
    "        self.weights = np.random.randn(self.input_dim)\n",
    "        self.bias = np.random.randn(1)\n",
    "        if self.verbose:\n",
    "            print(\"Weights: \", self.weights, \"Shape: \", self.weights.shape)\n",
    "            print(\"Bias: \", self.bias, \"Shape: \", self.bias.shape)\n",
    "        \n",
    "        self.initialized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, layer, loss, otimizer):\n",
    "        self.layer = layer(verbose=False)\n",
    "        self.loss = loss\n",
    "        self.optimizer = otimizer\n",
    "        self.initialized = False\n",
    "\n",
    "    def forward(self, X):\n",
    "        if not self.initialized:\n",
    "            raise Exception(\"Model not initialized. Please call the fit method\")\n",
    "        return self.layer.forward(X)\n",
    "\n",
    "    def backward(self, _y_pred, _y_true, _X):\n",
    "        if not self.initialized:\n",
    "            raise Exception(\"Model not initialized. Please call the fit method\")\n",
    "        # Get the gradient\n",
    "        coeff_gradient = self.loss.get_coeff_gradient(_y_pred, _y_true, _X)\n",
    "        bias_gradient = self.loss.get_bias_gradient(_y_pred, _y_true, _X)\n",
    "        return coeff_gradient, bias_gradient\n",
    "\n",
    "    def fit(self, X, y, epochs=100, batch_size=32):\n",
    "        # Initialize the layer\n",
    "        input_dim = X.shape[-1]\n",
    "        self.layer.initialize(input_dim)\n",
    "        self.initialized = True\n",
    "\n",
    "        loss: float = None\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            batch_start = 0\n",
    "            batch_end = batch_size\n",
    "            print(f\"Epoch: {epoch} | Loss: {loss}\")\n",
    "            \n",
    "            while batch_start < len(X):\n",
    "            \n",
    "                batch_x = X[batch_start:batch_end]\n",
    "                batch_y = y[batch_start:batch_end]\n",
    "\n",
    "                # Forward pass\n",
    "                y_pred = self.forward(batch_x)\n",
    "                loss = self.loss.get_loss(y_pred, batch_y)\n",
    "                \n",
    "                print(np.array(batch_x).shape, np.array(batch_y).shape, np.array(y_pred).shape)\n",
    "\n",
    "                # Backward pass\n",
    "                gradient_coeff, gradient_bias = self.backward(y_pred, batch_y, batch_x)\n",
    "\n",
    "                self.layer.weights = self.optimizer.step(\n",
    "                    [self.layer.weights], [gradient_coeff], epoch\n",
    "                )\n",
    "                self.layer.bias = self.optimizer.step(\n",
    "                    [self.layer.bias], [gradient_bias], epoch\n",
    "                )\n",
    "\n",
    "                batch_start = batch_end\n",
    "                batch_end += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: None\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 1 | Loss: 25.12038378325603\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 2 | Loss: 22.786039088056842\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 3 | Loss: 20.94880783195272\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 4 | Loss: 19.364224258073463\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 5 | Loss: 17.942703919868354\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 6 | Loss: 16.63967548796873\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 7 | Loss: 15.429059279162491\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 8 | Loss: 14.294260494566354\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 9 | Loss: 13.22416961286767\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 10 | Loss: 12.211095734464392\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 11 | Loss: 11.24959388118834\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 12 | Loss: 10.335753529919904\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 13 | Loss: 9.466744005231522\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 14 | Loss: 8.640511613130913\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 15 | Loss: 7.855570828714031\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 16 | Loss: 7.1108561699306\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 17 | Loss: 6.405614581245043\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 18 | Loss: 5.73932564753713\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 19 | Loss: 5.1116413881432905\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 20 | Loss: 4.522340084201547\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 21 | Loss: 3.971290284055782\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 22 | Loss: 3.4584222054309133\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 23 | Loss: 2.9837044306465166\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 24 | Loss: 2.5471241941977882\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 25 | Loss: 2.148669748805835\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 26 | Loss: 1.788313274510998\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 27 | Loss: 1.465992519467136\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 28 | Loss: 1.181588706397951\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 29 | Loss: 0.9348969460062619\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 30 | Loss: 0.7255829622247658\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 31 | Loss: 0.5531154081836827\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 32 | Loss: 0.4166548231903229\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 33 | Loss: 0.31486635899309146\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 34 | Loss: 0.24560509817850365\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 35 | Loss: 0.2054226209860797\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 36 | Loss: 0.1889594350498217\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 37 | Loss: 0.1887260751273997\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 38 | Loss: 0.19633957637057203\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 39 | Loss: 0.20525436264219837\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 40 | Loss: 0.21238392967826844\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 41 | Loss: 0.217189098822684\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 42 | Loss: 0.2201177785312646\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 43 | Loss: 0.22175521876612342\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 44 | Loss: 0.22256431625017548\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 45 | Loss: 0.22286008067711072\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 46 | Loss: 0.22284355508427833\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 47 | Loss: 0.22263903549397276\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 48 | Loss: 0.2223220517725647\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 49 | Loss: 0.22193803901504666\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 50 | Loss: 0.2215141575984719\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 51 | Loss: 0.22106657660329748\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 52 | Loss: 0.22060489429827035\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 53 | Loss: 0.2201347967327881\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 54 | Loss: 0.21965964741524677\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 55 | Loss: 0.2191814340927752\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 56 | Loss: 0.21870133101273903\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 57 | Loss: 0.2182200320841195\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 58 | Loss: 0.21773794792331563\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 59 | Loss: 0.21725532220918298\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 60 | Loss: 0.21677230029299632\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 61 | Loss: 0.21628896960396132\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 62 | Loss: 0.21580538341859443\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 63 | Loss: 0.2153215748312239\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 64 | Loss: 0.21483756496046424\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 65 | Loss: 0.21435336776928204\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 66 | Loss: 0.21386899289776115\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 67 | Loss: 0.21338444733075668\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 68 | Loss: 0.21289973638296647\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 69 | Loss: 0.2124148642842633\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 70 | Loss: 0.211929834530866\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 71 | Loss: 0.21144465009920288\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 72 | Loss: 0.2109593135790445\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 73 | Loss: 0.21047382725895758\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 74 | Loss: 0.20998819318336556\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 75 | Loss: 0.2095024131924931\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 76 | Loss: 0.2090164889517908\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 77 | Loss: 0.20853042197470723\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 78 | Loss: 0.20804421364110567\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 79 | Loss: 0.207557865212688\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 80 | Loss: 0.207071377846256\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 81 | Loss: 0.20658475260532455\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 82 | Loss: 0.20609799047042632\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 83 | Loss: 0.2056110923483172\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 84 | Loss: 0.20512405908025563\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 85 | Loss: 0.20463689144946462\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 86 | Loss: 0.2041495901878696\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 87 | Loss: 0.20366215598219348\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 88 | Loss: 0.2031745894794702\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 89 | Loss: 0.20268689129203257\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 90 | Loss: 0.2021990620020268\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 91 | Loss: 0.20171110216549837\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 92 | Loss: 0.20122301231608913\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 93 | Loss: 0.2007347929683814\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 94 | Loss: 0.2002464446209244\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 95 | Loss: 0.19975796775896945\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 96 | Loss: 0.19926936285694605\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 97 | Loss: 0.19878063038070148\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 98 | Loss: 0.19829177078952392\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n",
      "Epoch: 99 | Loss: 0.1978027845379753\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(16, 2) (16,) (16,)\n",
      "(4, 2) (4,) (4,)\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(100, 2)\n",
    "y = [0.5 * x1 + 1.5 * x2 + 3 for x1, x2 in X]\n",
    "\n",
    "\n",
    "model = Model(DenseLayer, MSE(), Adam(learning_rate=0.01, beta_1=0.85, beta_2=0.9))\n",
    "model.fit(X, y, epochs=100, batch_size=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
