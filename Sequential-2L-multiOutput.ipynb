{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- add mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, learning_rate=0.01, beta_1=0.85, beta_2=0.99):\n",
    "        self.lr = learning_rate\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "\n",
    "        self.m = 0\n",
    "        self.v = 0\n",
    "\n",
    "        self.m_prev = 0\n",
    "        self.v_prev = 0\n",
    "\n",
    "    def adam(self, gradients: list, epoch):\n",
    "        self.prev_m = self.m\n",
    "        self.prev_v = self.v\n",
    "\n",
    "        self.m = self.beta_1 * self.prev_m + (1 - self.beta_1) * gradients\n",
    "        self.v = self.beta_2 * self.prev_v + (1 - self.beta_2) * (gradients**2)\n",
    "\n",
    "        m_hat = self.m / (1 - self.beta_1 ** (epoch + 1))\n",
    "        v_hat = self.v / (1 - self.beta_2 ** (epoch + 1))\n",
    "\n",
    "        learning_rate = self.lr / (np.sqrt(v_hat) + 1e-8)\n",
    "        return learning_rate * m_hat\n",
    "\n",
    "    def step(self, parameters: list, gradients: list, epoch):\n",
    "        parameters = np.array(parameters).flatten()\n",
    "        gradients = np.array(gradients).flatten()\n",
    "\n",
    "        new_parameters = []\n",
    "        for param, gradient in zip(parameters, gradients):\n",
    "            update = self.adam(gradient, epoch)\n",
    "            param -= update\n",
    "            new_parameters.append(param)\n",
    "        return np.array(new_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSELoss:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def calculate_loss(self, y_pred, y_true):\n",
    "        return np.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "    def calculate_gradient_coeff(self, y_pred, y_true, X):\n",
    "        errors = y_pred - y_true\n",
    "        return (2 / len(y_true)) * np.dot(errors, X)\n",
    "\n",
    "    def calculate_gradient_bias(self, y_pred, y_true):\n",
    "        errors = y_pred - y_true\n",
    "        return (2 / len(y_true)) * np.sum(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, let's manually define the output size of the Dense layer, but in the future, we can infer it from the next layer\n",
    "class Dense:\n",
    "    def __init__(self, input_size, output_size, verbose=True):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.initialize_params()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return np.dot(self.weights, X.T) + self.bias\n",
    "\n",
    "    def initialize_params(self):\n",
    "        # new axis is because the dot product of x[100,3] and weights[3,2] will result in a shape of [100,2], but we have bias of shape [2]\n",
    "        # so we need to add a new axis to the bias to make it [2,1] so that we can add it to the dot product result\n",
    "        self.weights = np.random.randn(self.output_size, self.input_size)\n",
    "        self.bias = np.random.randn(self.output_size, 1)\n",
    "        if self.verbose:\n",
    "            print(f\"Weight shape: {self.weights.shape}\")\n",
    "            print(f\"Bias shape: {self.bias.shape}\")\n",
    "            print(\"Initialized weights:\", self.weights)\n",
    "            print(\"Initialized bias:\", self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, layer):\n",
    "        self.layer = layer  # not initialized\n",
    "        self.initiated = False\n",
    "        self.compiled = False\n",
    "\n",
    "    def compile(self, loss, optimizer):\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.compiled = True\n",
    "\n",
    "    def _forward(self, x):\n",
    "        if not self.initiated:\n",
    "            raise Exception(\"Model not initiated - call `fit()` method first\")\n",
    "\n",
    "        return self.layer.forward(x)\n",
    "\n",
    "    def _backward(self, y_pred, y_real, X):\n",
    "        if not self.initiated:\n",
    "            raise Exception(\"Model not initiated - call `fit()` method first\")\n",
    "\n",
    "        gradient_coeff = self.loss.calculate_gradient_coeff(y_pred, y_real, X)\n",
    "        gradient_bias = self.loss.calculate_gradient_bias(y_pred, y_real)\n",
    "\n",
    "        return gradient_coeff, gradient_bias\n",
    "\n",
    "    def fit(self, X, y, epochs=100):\n",
    "        if not self.compiled:\n",
    "            raise Exception(\"Model not compiled - call `compile()` method first\")\n",
    "\n",
    "        input_dim = X.shape[-1]\n",
    "        output_dim = y.shape[-1]\n",
    "        self.layer = self.layer(\n",
    "            input_size=input_dim, output_size=output_dim, verbose=True\n",
    "        )\n",
    "        self.initiated = True\n",
    "        \n",
    "        \n",
    "        loss = None\n",
    "        print(\"\\n------ Model initiated ------\")\n",
    "        for epoch in range(epochs):\n",
    "            # we need to find gradients of weights for each output separately\n",
    "            # so we need to iterate over each output\n",
    "            # for now let's use the batch (full) gradient descent\n",
    "\n",
    "            updated_weights = []\n",
    "            updated_bias = []\n",
    "            \n",
    "            print(f\"\\nEpoch {epoch} | Loss: {loss}\")\n",
    "            for i in range(output_dim):\n",
    "                # print(f\"\\nOutput {i}\")\n",
    "                weights = self.layer.weights[i, :]\n",
    "                bias = self.layer.bias[i]\n",
    "                # print(f\"Weights: {weights}\")\n",
    "                # print(f\"Bias: {bias}\")\n",
    "                \n",
    "                y_pred = self._forward(X)[i, :]\n",
    "                y_real = y[:, i]\n",
    "                # print(f\"X shape: {X.shape}\")\n",
    "                # print(f\"y_pred shape: {y_pred.shape}\")\n",
    "                # print(f\"y_real shape: {y_real.shape}\")\n",
    "                \n",
    "                loss = self.loss.calculate_loss(y_pred, y_real)\n",
    "                \n",
    "                \n",
    "                grad_coeff, grad_bias = self._backward(y_pred, y_real, X)\n",
    "                # print(f\"Gradient coeff: {grad_coeff}\")\n",
    "                # print(f\"Gradient bias: {grad_bias}\")\n",
    "                \n",
    "                new_weights = self.optimizer.step(weights, grad_coeff, epoch)\n",
    "                new_bias = self.optimizer.step(bias, grad_bias, epoch)\n",
    "                \n",
    "                updated_weights.append(new_weights)\n",
    "                updated_bias.append(new_bias)\n",
    "                \n",
    "            self.layer.weights = np.array(updated_weights)\n",
    "            self.layer.bias = np.array(updated_bias)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3) (100, 2)\n",
      "Weight shape: (2, 3)\n",
      "Bias shape: (2, 1)\n",
      "Initialized weights: [[-1.46913559  0.7994231   1.89602923]\n",
      " [-0.66094019  1.00755346  0.9390598 ]]\n",
      "Initialized bias: [[ 0.23205662]\n",
      " [-0.91170977]]\n",
      "\n",
      "------ Model initiated ------\n",
      "\n",
      "Epoch 0 | Loss: None\n",
      "\n",
      "Epoch 1 | Loss: 10.2780950819167\n",
      "\n",
      "Epoch 2 | Loss: 10.141569687333577\n",
      "\n",
      "Epoch 3 | Loss: 10.043207331583574\n",
      "\n",
      "Epoch 4 | Loss: 9.967702547737542\n",
      "\n",
      "Epoch 5 | Loss: 9.905516660662993\n",
      "\n",
      "Epoch 6 | Loss: 9.851534866931921\n",
      "\n",
      "Epoch 7 | Loss: 9.802900013296082\n",
      "\n",
      "Epoch 8 | Loss: 9.757914346666112\n",
      "\n",
      "Epoch 9 | Loss: 9.715506337870297\n",
      "\n",
      "Epoch 10 | Loss: 9.674963133220889\n",
      "\n",
      "Epoch 11 | Loss: 9.63578930718747\n",
      "\n",
      "Epoch 12 | Loss: 9.597628140301483\n",
      "\n",
      "Epoch 13 | Loss: 9.56021540455292\n",
      "\n",
      "Epoch 14 | Loss: 9.523350919891453\n",
      "\n",
      "Epoch 15 | Loss: 9.486880301232453\n",
      "\n",
      "Epoch 16 | Loss: 9.450682809665045\n",
      "\n",
      "Epoch 17 | Loss: 9.414663005372626\n",
      "\n",
      "Epoch 18 | Loss: 9.378744851165159\n",
      "\n",
      "Epoch 19 | Loss: 9.34286744436794\n",
      "\n",
      "Epoch 20 | Loss: 9.306981860163352\n",
      "\n",
      "Epoch 21 | Loss: 9.271048771946898\n",
      "\n",
      "Epoch 22 | Loss: 9.235036626695042\n",
      "\n",
      "Epoch 23 | Loss: 9.198920224554492\n",
      "\n",
      "Epoch 24 | Loss: 9.162679598085587\n",
      "\n",
      "Epoch 25 | Loss: 9.126299117264063\n",
      "\n",
      "Epoch 26 | Loss: 9.089766767106607\n",
      "\n",
      "Epoch 27 | Loss: 9.053073559095806\n",
      "\n",
      "Epoch 28 | Loss: 9.016213047608748\n",
      "\n",
      "Epoch 29 | Loss: 8.97918092969116\n",
      "\n",
      "Epoch 30 | Loss: 8.941974711672135\n",
      "\n",
      "Epoch 31 | Loss: 8.904593429885905\n",
      "\n",
      "Epoch 32 | Loss: 8.867037415563031\n",
      "\n",
      "Epoch 33 | Loss: 8.829308096051399\n",
      "\n",
      "Epoch 34 | Loss: 8.791407826120475\n",
      "\n",
      "Epoch 35 | Loss: 8.753339744325661\n",
      "\n",
      "Epoch 36 | Loss: 8.715107650358927\n",
      "\n",
      "Epoch 37 | Loss: 8.676715900056372\n",
      "\n",
      "Epoch 38 | Loss: 8.638169315322877\n",
      "\n",
      "Epoch 39 | Loss: 8.59947310670481\n",
      "\n",
      "Epoch 40 | Loss: 8.560632806721472\n",
      "\n",
      "Epoch 41 | Loss: 8.521654212373896\n",
      "\n",
      "Epoch 42 | Loss: 8.482543335502108\n",
      "\n",
      "Epoch 43 | Loss: 8.44330635986928\n",
      "\n",
      "Epoch 44 | Loss: 8.403949604023442\n",
      "\n",
      "Epoch 45 | Loss: 8.364479489130492\n",
      "\n",
      "Epoch 46 | Loss: 8.324902511092237\n",
      "\n",
      "Epoch 47 | Loss: 8.285225216363685\n",
      "\n",
      "Epoch 48 | Loss: 8.245454180968922\n",
      "\n",
      "Epoch 49 | Loss: 8.205595992286499\n",
      "\n",
      "Epoch 50 | Loss: 8.165657233236386\n",
      "\n",
      "Epoch 51 | Loss: 8.125644468552116\n",
      "\n",
      "Epoch 52 | Loss: 8.08556423286604\n",
      "\n",
      "Epoch 53 | Loss: 8.045423020373168\n",
      "\n",
      "Epoch 54 | Loss: 8.005227275871288\n",
      "\n",
      "Epoch 55 | Loss: 7.964983387002646\n",
      "\n",
      "Epoch 56 | Loss: 7.924697677546039\n",
      "\n",
      "Epoch 57 | Loss: 7.884376401628484\n",
      "\n",
      "Epoch 58 | Loss: 7.844025738742963\n",
      "\n",
      "Epoch 59 | Loss: 7.803651789473858\n",
      "\n",
      "Epoch 60 | Loss: 7.763260571844352\n",
      "\n",
      "Epoch 61 | Loss: 7.722858018211368\n",
      "\n",
      "Epoch 62 | Loss: 7.682449972643082\n",
      "\n",
      "Epoch 63 | Loss: 7.64204218872227\n",
      "\n",
      "Epoch 64 | Loss: 7.601640327725977\n",
      "\n",
      "Epoch 65 | Loss: 7.561249957138061\n",
      "\n",
      "Epoch 66 | Loss: 7.5208765494565535\n",
      "\n",
      "Epoch 67 | Loss: 7.480525481262373\n",
      "\n",
      "Epoch 68 | Loss: 7.440202032519973\n",
      "\n",
      "Epoch 69 | Loss: 7.39991138608392\n",
      "\n",
      "Epoch 70 | Loss: 7.359658627388517\n",
      "\n",
      "Epoch 71 | Loss: 7.319448744300148\n",
      "\n",
      "Epoch 72 | Loss: 7.279286627114384\n",
      "\n",
      "Epoch 73 | Loss: 7.239177068681828\n",
      "\n",
      "Epoch 74 | Loss: 7.199124764648547\n",
      "\n",
      "Epoch 75 | Loss: 7.15913431379838\n",
      "\n",
      "Epoch 76 | Loss: 7.119210218485824\n",
      "\n",
      "Epoch 77 | Loss: 7.079356885149407\n",
      "\n",
      "Epoch 78 | Loss: 7.039578624896447\n",
      "\n",
      "Epoch 79 | Loss: 6.999879654151147\n",
      "\n",
      "Epoch 80 | Loss: 6.960264095358658\n",
      "\n",
      "Epoch 81 | Loss: 6.9207359777386035\n",
      "\n",
      "Epoch 82 | Loss: 6.881299238082147\n",
      "\n",
      "Epoch 83 | Loss: 6.8419577215872645\n",
      "\n",
      "Epoch 84 | Loss: 6.802715182727477\n",
      "\n",
      "Epoch 85 | Loss: 6.763575286149626\n",
      "\n",
      "Epoch 86 | Loss: 6.724541607596897\n",
      "\n",
      "Epoch 87 | Loss: 6.685617634853438\n",
      "\n",
      "Epoch 88 | Loss: 6.64680676870747\n",
      "\n",
      "Epoch 89 | Loss: 6.60811232392998\n",
      "\n",
      "Epoch 90 | Loss: 6.569537530266358\n",
      "\n",
      "Epoch 91 | Loss: 6.531085533438653\n",
      "\n",
      "Epoch 92 | Loss: 6.492759396156319\n",
      "\n",
      "Epoch 93 | Loss: 6.454562099133526\n",
      "\n",
      "Epoch 94 | Loss: 6.4164965421113\n",
      "\n",
      "Epoch 95 | Loss: 6.378565544882917\n",
      "\n",
      "Epoch 96 | Loss: 6.340771848321173\n",
      "\n",
      "Epoch 97 | Loss: 6.303118115406265\n",
      "\n",
      "Epoch 98 | Loss: 6.265606932253117\n",
      "\n",
      "Epoch 99 | Loss: 6.228240809137166\n",
      "\n",
      "Epoch 100 | Loss: 6.1910221815177024\n",
      "\n",
      "Epoch 101 | Loss: 6.1539534110579295\n",
      "\n",
      "Epoch 102 | Loss: 6.117036786641051\n",
      "\n",
      "Epoch 103 | Loss: 6.080274525381741\n",
      "\n",
      "Epoch 104 | Loss: 6.04366877363242\n",
      "\n",
      "Epoch 105 | Loss: 6.007221607983874\n",
      "\n",
      "Epoch 106 | Loss: 5.970935036259741\n",
      "\n",
      "Epoch 107 | Loss: 5.934810998504554\n",
      "\n",
      "Epoch 108 | Loss: 5.898851367964938\n",
      "\n",
      "Epoch 109 | Loss: 5.86305795206377\n",
      "\n",
      "Epoch 110 | Loss: 5.827432493366988\n",
      "\n",
      "Epoch 111 | Loss: 5.791976670542914\n",
      "\n",
      "Epoch 112 | Loss: 5.756692099313893\n",
      "\n",
      "Epoch 113 | Loss: 5.721580333400162\n",
      "\n",
      "Epoch 114 | Loss: 5.6866428654557755\n",
      "\n",
      "Epoch 115 | Loss: 5.651881127996596\n",
      "\n",
      "Epoch 116 | Loss: 5.6172964943202395\n",
      "\n",
      "Epoch 117 | Loss: 5.582890279417979\n",
      "\n",
      "Epoch 118 | Loss: 5.5486637408785535\n",
      "\n",
      "Epoch 119 | Loss: 5.514618079783922\n",
      "\n",
      "Epoch 120 | Loss: 5.480754441596975\n",
      "\n",
      "Epoch 121 | Loss: 5.44707391704121\n",
      "\n",
      "Epoch 122 | Loss: 5.413577542972409\n",
      "\n",
      "Epoch 123 | Loss: 5.3802663032424185\n",
      "\n",
      "Epoch 124 | Loss: 5.347141129555025\n",
      "\n",
      "Epoch 125 | Loss: 5.314202902314022\n",
      "\n",
      "Epoch 126 | Loss: 5.2814524514635375\n",
      "\n",
      "Epoch 127 | Loss: 5.248890557320697\n",
      "\n",
      "Epoch 128 | Loss: 5.216517951400678\n",
      "\n",
      "Epoch 129 | Loss: 5.184335317234278\n",
      "\n",
      "Epoch 130 | Loss: 5.152343291178032\n",
      "\n",
      "Epoch 131 | Loss: 5.120542463216997\n",
      "\n",
      "Epoch 132 | Loss: 5.088933377760279\n",
      "\n",
      "Epoch 133 | Loss: 5.0575165344293795\n",
      "\n",
      "Epoch 134 | Loss: 5.026292388839452\n",
      "\n",
      "Epoch 135 | Loss: 4.9952613533735555\n",
      "\n",
      "Epoch 136 | Loss: 4.9644237979499835\n",
      "\n",
      "Epoch 137 | Loss: 4.933780050782737\n",
      "\n",
      "Epoch 138 | Loss: 4.903330399135254\n",
      "\n",
      "Epoch 139 | Loss: 4.87307509006742\n",
      "\n",
      "Epoch 140 | Loss: 4.8430143311759934\n",
      "\n",
      "Epoch 141 | Loss: 4.813148291328458\n",
      "\n",
      "Epoch 142 | Loss: 4.783477101390418\n",
      "\n",
      "Epoch 143 | Loss: 4.754000854946567\n",
      "\n",
      "Epoch 144 | Loss: 4.7247196090153185\n",
      "\n",
      "Epoch 145 | Loss: 4.695633384757127\n",
      "\n",
      "Epoch 146 | Loss: 4.666742168176602\n",
      "\n",
      "Epoch 147 | Loss: 4.6380459108183905\n",
      "\n",
      "Epoch 148 | Loss: 4.609544530456969\n",
      "\n",
      "Epoch 149 | Loss: 4.5812379117803115\n",
      "\n",
      "Epoch 150 | Loss: 4.553125907067514\n",
      "\n",
      "Epoch 151 | Loss: 4.525208336860416\n",
      "\n",
      "Epoch 152 | Loss: 4.497484990629225\n",
      "\n",
      "Epoch 153 | Loss: 4.469955627432201\n",
      "\n",
      "Epoch 154 | Loss: 4.4426199765694205\n",
      "\n",
      "Epoch 155 | Loss: 4.41547773823064\n",
      "\n",
      "Epoch 156 | Loss: 4.388528584137291\n",
      "\n",
      "Epoch 157 | Loss: 4.361772158178604\n",
      "\n",
      "Epoch 158 | Loss: 4.3352080770419015\n",
      "\n",
      "Epoch 159 | Loss: 4.30883593083706\n",
      "\n",
      "Epoch 160 | Loss: 4.282655283715144\n",
      "\n",
      "Epoch 161 | Loss: 4.256665674481228\n",
      "\n",
      "Epoch 162 | Loss: 4.230866617201413\n",
      "\n",
      "Epoch 163 | Loss: 4.205257601804029\n",
      "\n",
      "Epoch 164 | Loss: 4.179838094675026\n",
      "\n",
      "Epoch 165 | Loss: 4.154607539247563\n",
      "\n",
      "Epoch 166 | Loss: 4.129565356585767\n",
      "\n",
      "Epoch 167 | Loss: 4.104710945962674\n",
      "\n",
      "Epoch 168 | Loss: 4.080043685432339\n",
      "\n",
      "Epoch 169 | Loss: 4.055562932396102\n",
      "\n",
      "Epoch 170 | Loss: 4.031268024162991\n",
      "\n",
      "Epoch 171 | Loss: 4.00715827850427\n",
      "\n",
      "Epoch 172 | Loss: 3.983232994202092\n",
      "\n",
      "Epoch 173 | Loss: 3.959491451592267\n",
      "\n",
      "Epoch 174 | Loss: 3.9359329131010976\n",
      "\n",
      "Epoch 175 | Loss: 3.9125566237762968\n",
      "\n",
      "Epoch 176 | Loss: 3.8893618118119555\n",
      "\n",
      "Epoch 177 | Loss: 3.8663476890675263\n",
      "\n",
      "Epoch 178 | Loss: 3.8435134515808387\n",
      "\n",
      "Epoch 179 | Loss: 3.8208582800750928\n",
      "\n",
      "Epoch 180 | Loss: 3.798381340459831\n",
      "\n",
      "Epoch 181 | Loss: 3.776081784325866\n",
      "\n",
      "Epoch 182 | Loss: 3.753958749434133\n",
      "\n",
      "Epoch 183 | Loss: 3.7320113601984706\n",
      "\n",
      "Epoch 184 | Loss: 3.7102387281622873\n",
      "\n",
      "Epoch 185 | Loss: 3.688639952469103\n",
      "\n",
      "Epoch 186 | Loss: 3.667214120326959\n",
      "\n",
      "Epoch 187 | Loss: 3.645960307466658\n",
      "\n",
      "Epoch 188 | Loss: 3.6248775785938387\n",
      "\n",
      "Epoch 189 | Loss: 3.603964987834847\n",
      "\n",
      "Epoch 190 | Loss: 3.58322157917642\n",
      "\n",
      "Epoch 191 | Loss: 3.5626463868991216\n",
      "\n",
      "Epoch 192 | Loss: 3.5422384360045696\n",
      "\n",
      "Epoch 193 | Loss: 3.521996742636404\n",
      "\n",
      "Epoch 194 | Loss: 3.5019203144950093\n",
      "\n",
      "Epoch 195 | Loss: 3.482008151245957\n",
      "\n",
      "Epoch 196 | Loss: 3.4622592449221883\n",
      "\n",
      "Epoch 197 | Loss: 3.4426725803199174\n",
      "\n",
      "Epoch 198 | Loss: 3.42324713538824\n",
      "\n",
      "Epoch 199 | Loss: 3.40398188161247\n",
      "\n",
      "Epoch 200 | Loss: 3.384875784391172\n",
      "\n",
      "Epoch 201 | Loss: 3.365927803406917\n",
      "\n",
      "Epoch 202 | Loss: 3.3471368929907523\n",
      "\n",
      "Epoch 203 | Loss: 3.3285020024803758\n",
      "\n",
      "Epoch 204 | Loss: 3.310022076572038\n",
      "\n",
      "Epoch 205 | Loss: 3.29169605566619\n",
      "\n",
      "Epoch 206 | Loss: 3.273522876206839\n",
      "\n",
      "Epoch 207 | Loss: 3.255501471014682\n",
      "\n",
      "Epoch 208 | Loss: 3.2376307696139808\n",
      "\n",
      "Epoch 209 | Loss: 3.2199096985532294\n",
      "\n",
      "Epoch 210 | Loss: 3.202337181719605\n",
      "\n",
      "Epoch 211 | Loss: 3.1849121406472323\n",
      "\n",
      "Epoch 212 | Loss: 3.1676334948192832\n",
      "\n",
      "Epoch 213 | Loss: 3.150500161963933\n",
      "\n",
      "Epoch 214 | Loss: 3.1335110583441854\n",
      "\n",
      "Epoch 215 | Loss: 3.116665099041618\n",
      "\n",
      "Epoch 216 | Loss: 3.0999611982340425\n",
      "\n",
      "Epoch 217 | Loss: 3.0833982694671507\n",
      "\n",
      "Epoch 218 | Loss: 3.0669752259201295\n",
      "\n",
      "Epoch 219 | Loss: 3.0506909806653306\n",
      "\n",
      "Epoch 220 | Loss: 3.0345444469219824\n",
      "\n",
      "Epoch 221 | Loss: 3.0185345383040163\n",
      "\n",
      "Epoch 222 | Loss: 3.00266016906203\n",
      "\n",
      "Epoch 223 | Loss: 2.9869202543194255\n",
      "\n",
      "Epoch 224 | Loss: 2.971313710302785\n",
      "\n",
      "Epoch 225 | Loss: 2.9558394545665023\n",
      "\n",
      "Epoch 226 | Loss: 2.9404964062117234\n",
      "\n",
      "Epoch 227 | Loss: 2.9252834860996684\n",
      "\n",
      "Epoch 228 | Loss: 2.9101996170593365\n",
      "\n",
      "Epoch 229 | Loss: 2.895243724089695\n",
      "\n",
      "Epoch 230 | Loss: 2.880414734556359\n",
      "\n",
      "Epoch 231 | Loss: 2.8657115783828533\n",
      "\n",
      "Epoch 232 | Loss: 2.851133188236477\n",
      "\n",
      "Epoch 233 | Loss: 2.8366784997088645\n",
      "\n",
      "Epoch 234 | Loss: 2.8223464514912506\n",
      "\n",
      "Epoch 235 | Loss: 2.808135985544553\n",
      "\n",
      "Epoch 236 | Loss: 2.7940460472642945\n",
      "\n",
      "Epoch 237 | Loss: 2.780075585640424\n",
      "\n",
      "Epoch 238 | Loss: 2.7662235534121287\n",
      "\n",
      "Epoch 239 | Loss: 2.7524889072176766\n",
      "\n",
      "Epoch 240 | Loss: 2.738870607739345\n",
      "\n",
      "Epoch 241 | Loss: 2.7253676198435226\n",
      "\n",
      "Epoch 242 | Loss: 2.711978912716046\n",
      "\n",
      "Epoch 243 | Loss: 2.6987034599928124\n",
      "\n",
      "Epoch 244 | Loss: 2.6855402398857713\n",
      "\n",
      "Epoch 245 | Loss: 2.672488235304327\n",
      "\n",
      "Epoch 246 | Loss: 2.6595464339722588\n",
      "\n",
      "Epoch 247 | Loss: 2.6467138285401854\n",
      "\n",
      "Epoch 248 | Loss: 2.633989416693676\n",
      "\n",
      "Epoch 249 | Loss: 2.6213722012570653\n",
      "\n",
      "Epoch 250 | Loss: 2.6088611902930294\n",
      "\n",
      "Epoch 251 | Loss: 2.5964553971980244\n",
      "\n",
      "Epoch 252 | Loss: 2.584153840793627\n",
      "\n",
      "Epoch 253 | Loss: 2.5719555454138607\n",
      "\n",
      "Epoch 254 | Loss: 2.559859540988588\n",
      "\n",
      "Epoch 255 | Loss: 2.547864863123016\n",
      "\n",
      "Epoch 256 | Loss: 2.5359705531734127\n",
      "\n",
      "Epoch 257 | Loss: 2.5241756583190935\n",
      "\n",
      "Epoch 258 | Loss: 2.5124792316307367\n",
      "\n",
      "Epoch 259 | Loss: 2.5008803321351287\n",
      "\n",
      "Epoch 260 | Loss: 2.4893780248763746\n",
      "\n",
      "Epoch 261 | Loss: 2.4779713809736843\n",
      "\n",
      "Epoch 262 | Loss: 2.4666594776757713\n",
      "\n",
      "Epoch 263 | Loss: 2.4554413984119448\n",
      "\n",
      "Epoch 264 | Loss: 2.444316232839981\n",
      "\n",
      "Epoch 265 | Loss: 2.4332830768908265\n",
      "\n",
      "Epoch 266 | Loss: 2.4223410328101984\n",
      "\n",
      "Epoch 267 | Loss: 2.411489209197181\n",
      "\n",
      "Epoch 268 | Loss: 2.400726721039844\n",
      "\n",
      "Epoch 269 | Loss: 2.3900526897479963\n",
      "\n",
      "Epoch 270 | Loss: 2.3794662431831055\n",
      "\n",
      "Epoch 271 | Loss: 2.368966515685475\n",
      "\n",
      "Epoch 272 | Loss: 2.3585526480987364\n",
      "\n",
      "Epoch 273 | Loss: 2.3482237877917225\n",
      "\n",
      "Epoch 274 | Loss: 2.3379790886777894\n",
      "\n",
      "Epoch 275 | Loss: 2.327817711231654\n",
      "\n",
      "Epoch 276 | Loss: 2.3177388225038142\n",
      "\n",
      "Epoch 277 | Loss: 2.3077415961326\n",
      "\n",
      "Epoch 278 | Loss: 2.2978252123539464\n",
      "\n",
      "Epoch 279 | Loss: 2.2879888580089194\n",
      "\n",
      "Epoch 280 | Loss: 2.278231726549082\n",
      "\n",
      "Epoch 281 | Loss: 2.2685530180397557\n",
      "\n",
      "Epoch 282 | Loss: 2.258951939161218\n",
      "\n",
      "Epoch 283 | Loss: 2.249427703207929\n",
      "\n",
      "Epoch 284 | Loss: 2.239979530085816\n",
      "\n",
      "Epoch 285 | Loss: 2.230606646307696\n",
      "\n",
      "Epoch 286 | Loss: 2.2213082849868764\n",
      "\n",
      "Epoch 287 | Loss: 2.2120836858289996\n",
      "\n",
      "Epoch 288 | Loss: 2.20293209512219\n",
      "\n",
      "Epoch 289 | Loss: 2.193852765725543\n",
      "\n",
      "Epoch 290 | Loss: 2.1848449570560327\n",
      "\n",
      "Epoch 291 | Loss: 2.1759079350738655\n",
      "\n",
      "Epoch 292 | Loss: 2.1670409722663555\n",
      "\n",
      "Epoch 293 | Loss: 2.1582433476303544\n",
      "\n",
      "Epoch 294 | Loss: 2.1495143466532984\n",
      "\n",
      "Epoch 295 | Loss: 2.1408532612929165\n",
      "\n",
      "Epoch 296 | Loss: 2.132259389955645\n",
      "\n",
      "Epoch 297 | Loss: 2.1237320374738036\n",
      "\n",
      "Epoch 298 | Loss: 2.115270515081579\n",
      "\n",
      "Epoch 299 | Loss: 2.106874140389852\n",
      "\n",
      "Epoch 300 | Loss: 2.0985422373599265\n",
      "\n",
      "Epoch 301 | Loss: 2.090274136276191\n",
      "\n",
      "Epoch 302 | Loss: 2.082069173717775\n",
      "\n",
      "Epoch 303 | Loss: 2.0739266925292155\n",
      "\n",
      "Epoch 304 | Loss: 2.065846041790204\n",
      "\n",
      "Epoch 305 | Loss: 2.0578265767844273\n",
      "\n",
      "Epoch 306 | Loss: 2.0498676589675684\n",
      "\n",
      "Epoch 307 | Loss: 2.0419686559344803\n",
      "\n",
      "Epoch 308 | Loss: 2.0341289413855907\n",
      "\n",
      "Epoch 309 | Loss: 2.0263478950925693\n",
      "\n",
      "Epoch 310 | Loss: 2.0186249028632806\n",
      "\n",
      "Epoch 311 | Loss: 2.0109593565060795\n",
      "\n",
      "Epoch 312 | Loss: 2.0033506537934724\n",
      "\n",
      "Epoch 313 | Loss: 1.9957981984251676\n",
      "\n",
      "Epoch 314 | Loss: 1.9883013999905748\n",
      "\n",
      "Epoch 315 | Loss: 1.980859673930754\n",
      "\n",
      "Epoch 316 | Loss: 1.973472441499873\n",
      "\n",
      "Epoch 317 | Loss: 1.9661391297261832\n",
      "\n",
      "Epoch 318 | Loss: 1.958859171372558\n",
      "\n",
      "Epoch 319 | Loss: 1.9516320048966063\n",
      "\n",
      "Epoch 320 | Loss: 1.944457074410411\n",
      "\n",
      "Epoch 321 | Loss: 1.937333829639902\n",
      "\n",
      "Epoch 322 | Loss: 1.930261725883894\n",
      "\n",
      "Epoch 323 | Loss: 1.9232402239728237\n",
      "\n",
      "Epoch 324 | Loss: 1.9162687902271955\n",
      "\n",
      "Epoch 325 | Loss: 1.9093468964157791\n",
      "\n",
      "Epoch 326 | Loss: 1.902474019713569\n",
      "\n",
      "Epoch 327 | Loss: 1.89564964265953\n",
      "\n",
      "Epoch 328 | Loss: 1.8888732531141568\n",
      "\n",
      "Epoch 329 | Loss: 1.8821443442168704\n",
      "\n",
      "Epoch 330 | Loss: 1.8754624143432594\n",
      "\n",
      "Epoch 331 | Loss: 1.8688269670622006\n",
      "\n",
      "Epoch 332 | Loss: 1.8622375110928755\n",
      "\n",
      "Epoch 333 | Loss: 1.8556935602616937\n",
      "\n",
      "Epoch 334 | Loss: 1.8491946334591516\n",
      "\n",
      "Epoch 335 | Loss: 1.8427402545966403\n",
      "\n",
      "Epoch 336 | Loss: 1.8363299525632126\n",
      "\n",
      "Epoch 337 | Loss: 1.829963261182348\n",
      "\n",
      "Epoch 338 | Loss: 1.823639719168698\n",
      "\n",
      "Epoch 339 | Loss: 1.8173588700848595\n",
      "\n",
      "Epoch 340 | Loss: 1.8111202622981717\n",
      "\n",
      "Epoch 341 | Loss: 1.804923448937557\n",
      "\n",
      "Epoch 342 | Loss: 1.7987679878504212\n",
      "\n",
      "Epoch 343 | Loss: 1.7926534415596251\n",
      "\n",
      "Epoch 344 | Loss: 1.7865793772205343\n",
      "\n",
      "Epoch 345 | Loss: 1.780545366578174\n",
      "\n",
      "Epoch 346 | Loss: 1.774550985924488\n",
      "\n",
      "Epoch 347 | Loss: 1.7685958160557136\n",
      "\n",
      "Epoch 348 | Loss: 1.7626794422298928\n",
      "\n",
      "Epoch 349 | Loss: 1.7568014541245232\n",
      "\n",
      "Epoch 350 | Loss: 1.7509614457943556\n",
      "\n",
      "Epoch 351 | Loss: 1.7451590156293622\n",
      "\n",
      "Epoch 352 | Loss: 1.7393937663128647\n",
      "\n",
      "Epoch 353 | Loss: 1.7336653047798476\n",
      "\n",
      "Epoch 354 | Loss: 1.727973242175457\n",
      "\n",
      "Epoch 355 | Loss: 1.722317193813695\n",
      "\n",
      "Epoch 356 | Loss: 1.716696779136318\n",
      "\n",
      "Epoch 357 | Loss: 1.7111116216719469\n",
      "\n",
      "Epoch 358 | Loss: 1.7055613489953898\n",
      "\n",
      "Epoch 359 | Loss: 1.7000455926871978\n",
      "\n",
      "Epoch 360 | Loss: 1.6945639882934393\n",
      "\n",
      "Epoch 361 | Loss: 1.6891161752857249\n",
      "\n",
      "Epoch 362 | Loss: 1.683701797021463\n",
      "\n",
      "Epoch 363 | Loss: 1.6783205007043662\n",
      "\n",
      "Epoch 364 | Loss: 1.6729719373452143\n",
      "\n",
      "Epoch 365 | Loss: 1.6676557617228716\n",
      "\n",
      "Epoch 366 | Loss: 1.6623716323455624\n",
      "\n",
      "Epoch 367 | Loss: 1.6571192114124205\n",
      "\n",
      "Epoch 368 | Loss: 1.6518981647753\n",
      "\n",
      "Epoch 369 | Loss: 1.6467081619008672\n",
      "\n",
      "Epoch 370 | Loss: 1.6415488758329646\n",
      "\n",
      "Epoch 371 | Loss: 1.6364199831552582\n",
      "\n",
      "Epoch 372 | Loss: 1.6313211639541643\n",
      "\n",
      "Epoch 373 | Loss: 1.6262521017820664\n",
      "\n",
      "Epoch 374 | Loss: 1.6212124836208155\n",
      "\n",
      "Epoch 375 | Loss: 1.6162019998455301\n",
      "\n",
      "Epoch 376 | Loss: 1.6112203441886757\n",
      "\n",
      "Epoch 377 | Loss: 1.606267213704448\n",
      "\n",
      "Epoch 378 | Loss: 1.601342308733454\n",
      "\n",
      "Epoch 379 | Loss: 1.596445332867682\n",
      "\n",
      "Epoch 380 | Loss: 1.5915759929157804\n",
      "\n",
      "Epoch 381 | Loss: 1.5867339988686266\n",
      "\n",
      "Epoch 382 | Loss: 1.5819190638652085\n",
      "\n",
      "Epoch 383 | Loss: 1.577130904158799\n",
      "\n",
      "Epoch 384 | Loss: 1.572369239083437\n",
      "\n",
      "Epoch 385 | Loss: 1.5676337910207097\n",
      "\n",
      "Epoch 386 | Loss: 1.5629242853668404\n",
      "\n",
      "Epoch 387 | Loss: 1.5582404505000813\n",
      "\n",
      "Epoch 388 | Loss: 1.5535820177484032\n",
      "\n",
      "Epoch 389 | Loss: 1.5489487213575002\n",
      "\n",
      "Epoch 390 | Loss: 1.5443402984590833\n",
      "\n",
      "Epoch 391 | Loss: 1.5397564890394948\n",
      "\n",
      "Epoch 392 | Loss: 1.5351970359086102\n",
      "\n",
      "Epoch 393 | Loss: 1.5306616846690508\n",
      "\n",
      "Epoch 394 | Loss: 1.5261501836856957\n",
      "\n",
      "Epoch 395 | Loss: 1.5216622840554959\n",
      "\n",
      "Epoch 396 | Loss: 1.5171977395775886\n",
      "\n",
      "Epoch 397 | Loss: 1.5127563067237082\n",
      "\n",
      "Epoch 398 | Loss: 1.5083377446089008\n",
      "\n",
      "Epoch 399 | Loss: 1.5039418149625299\n",
      "\n",
      "Epoch 400 | Loss: 1.4995682820995861\n",
      "\n",
      "Epoch 401 | Loss: 1.4952169128922816\n",
      "\n",
      "Epoch 402 | Loss: 1.490887476741946\n",
      "\n",
      "Epoch 403 | Loss: 1.486579745551214\n",
      "\n",
      "Epoch 404 | Loss: 1.4822934936965004\n",
      "\n",
      "Epoch 405 | Loss: 1.478028498000765\n",
      "\n",
      "Epoch 406 | Loss: 1.473784537706568\n",
      "\n",
      "Epoch 407 | Loss: 1.4695613944494084\n",
      "\n",
      "Epoch 408 | Loss: 1.46535885223135\n",
      "\n",
      "Epoch 409 | Loss: 1.461176697394927\n",
      "\n",
      "Epoch 410 | Loss: 1.457014718597331\n",
      "\n",
      "Epoch 411 | Loss: 1.4528727067848795\n",
      "\n",
      "Epoch 412 | Loss: 1.4487504551677595\n",
      "\n",
      "Epoch 413 | Loss: 1.4446477591950486\n",
      "\n",
      "Epoch 414 | Loss: 1.4405644165300036\n",
      "\n",
      "Epoch 415 | Loss: 1.4365002270256297\n",
      "\n",
      "Epoch 416 | Loss: 1.4324549927005117\n",
      "\n",
      "Epoch 417 | Loss: 1.4284285177149167\n",
      "\n",
      "Epoch 418 | Loss: 1.4244206083471593\n",
      "\n",
      "Epoch 419 | Loss: 1.4204310729702332\n",
      "\n",
      "Epoch 420 | Loss: 1.4164597220286987\n",
      "\n",
      "Epoch 421 | Loss: 1.4125063680158385\n",
      "\n",
      "Epoch 422 | Loss: 1.408570825451058\n",
      "\n",
      "Epoch 423 | Loss: 1.404652910857552\n",
      "\n",
      "Epoch 424 | Loss: 1.400752442740215\n",
      "\n",
      "Epoch 425 | Loss: 1.3968692415638078\n",
      "\n",
      "Epoch 426 | Loss: 1.39300312973137\n",
      "\n",
      "Epoch 427 | Loss: 1.3891539315628754\n",
      "\n",
      "Epoch 428 | Loss: 1.385321473274136\n",
      "\n",
      "Epoch 429 | Loss: 1.3815055829559442\n",
      "\n",
      "Epoch 430 | Loss: 1.3777060905534537\n",
      "\n",
      "Epoch 431 | Loss: 1.3739228278458047\n",
      "\n",
      "Epoch 432 | Loss: 1.3701556284259657\n",
      "\n",
      "Epoch 433 | Loss: 1.3664043276808322\n",
      "\n",
      "Epoch 434 | Loss: 1.3626687627715324\n",
      "\n",
      "Epoch 435 | Loss: 1.3589487726139766\n",
      "\n",
      "Epoch 436 | Loss: 1.3552441978596215\n",
      "\n",
      "Epoch 437 | Loss: 1.351554880876468\n",
      "\n",
      "Epoch 438 | Loss: 1.3478806657302695\n",
      "\n",
      "Epoch 439 | Loss: 1.3442213981659648\n",
      "\n",
      "Epoch 440 | Loss: 1.340576925589329\n",
      "\n",
      "Epoch 441 | Loss: 1.3369470970488302\n",
      "\n",
      "Epoch 442 | Loss: 1.3333317632177084\n",
      "\n",
      "Epoch 443 | Loss: 1.329730776376258\n",
      "\n",
      "Epoch 444 | Loss: 1.326143990394317\n",
      "\n",
      "Epoch 445 | Loss: 1.3225712607139655\n",
      "\n",
      "Epoch 446 | Loss: 1.319012444332425\n",
      "\n",
      "Epoch 447 | Loss: 1.3154673997851574\n",
      "\n",
      "Epoch 448 | Loss: 1.3119359871291627\n",
      "\n",
      "Epoch 449 | Loss: 1.3084180679264765\n",
      "\n",
      "Epoch 450 | Loss: 1.3049135052278549\n",
      "\n",
      "Epoch 451 | Loss: 1.3014221635566627\n",
      "\n",
      "Epoch 452 | Loss: 1.2979439088929359\n",
      "\n",
      "Epoch 453 | Loss: 1.2944786086576459\n",
      "\n",
      "Epoch 454 | Loss: 1.2910261316971414\n",
      "\n",
      "Epoch 455 | Loss: 1.2875863482677778\n",
      "\n",
      "Epoch 456 | Loss: 1.2841591300207247\n",
      "\n",
      "Epoch 457 | Loss: 1.2807443499869553\n",
      "\n",
      "Epoch 458 | Loss: 1.2773418825624105\n",
      "\n",
      "Epoch 459 | Loss: 1.2739516034933422\n",
      "\n",
      "Epoch 460 | Loss: 1.2705733898618246\n",
      "\n",
      "Epoch 461 | Loss: 1.2672071200714412\n",
      "\n",
      "Epoch 462 | Loss: 1.2638526738331386\n",
      "\n",
      "Epoch 463 | Loss: 1.2605099321512447\n",
      "\n",
      "Epoch 464 | Loss: 1.2571787773096605\n",
      "\n",
      "Epoch 465 | Loss: 1.2538590928582047\n",
      "\n",
      "Epoch 466 | Loss: 1.250550763599128\n",
      "\n",
      "Epoch 467 | Loss: 1.2472536755737818\n",
      "\n",
      "Epoch 468 | Loss: 1.2439677160494433\n",
      "\n",
      "Epoch 469 | Loss: 1.2406927735063038\n",
      "\n",
      "Epoch 470 | Loss: 1.2374287376246014\n",
      "\n",
      "Epoch 471 | Loss: 1.2341754992719103\n",
      "\n",
      "Epoch 472 | Loss: 1.2309329504905813\n",
      "\n",
      "Epoch 473 | Loss: 1.2277009844853257\n",
      "\n",
      "Epoch 474 | Loss: 1.2244794956109515\n",
      "\n",
      "Epoch 475 | Loss: 1.2212683793602361\n",
      "\n",
      "Epoch 476 | Loss: 1.2180675323519545\n",
      "\n",
      "Epoch 477 | Loss: 1.2148768523190336\n",
      "\n",
      "Epoch 478 | Loss: 1.2116962380968561\n",
      "\n",
      "Epoch 479 | Loss: 1.2085255896116998\n",
      "\n",
      "Epoch 480 | Loss: 1.2053648078693115\n",
      "\n",
      "Epoch 481 | Loss: 1.2022137949436165\n",
      "\n",
      "Epoch 482 | Loss: 1.199072453965558\n",
      "\n",
      "Epoch 483 | Loss: 1.1959406891120732\n",
      "\n",
      "Epoch 484 | Loss: 1.1928184055951923\n",
      "\n",
      "Epoch 485 | Loss: 1.1897055096512705\n",
      "\n",
      "Epoch 486 | Loss: 1.186601908530341\n",
      "\n",
      "Epoch 487 | Loss: 1.183507510485601\n",
      "\n",
      "Epoch 488 | Loss: 1.1804222247630098\n",
      "\n",
      "Epoch 489 | Loss: 1.177345961591018\n",
      "\n",
      "Epoch 490 | Loss: 1.1742786321704115\n",
      "\n",
      "Epoch 491 | Loss: 1.1712201486642781\n",
      "\n",
      "Epoch 492 | Loss: 1.1681704241880848\n",
      "\n",
      "Epoch 493 | Loss: 1.1651293727998786\n",
      "\n",
      "Epoch 494 | Loss: 1.1620969094905957\n",
      "\n",
      "Epoch 495 | Loss: 1.1590729501744874\n",
      "\n",
      "Epoch 496 | Loss: 1.156057411679654\n",
      "\n",
      "Epoch 497 | Loss: 1.1530502117386918\n",
      "\n",
      "Epoch 498 | Loss: 1.1500512689794475\n",
      "\n",
      "Epoch 499 | Loss: 1.1470605029158785\n",
      "\n",
      "Epoch 500 | Loss: 1.1440778339390227\n",
      "\n",
      "Epoch 501 | Loss: 1.1411031833080691\n",
      "\n",
      "Epoch 502 | Loss: 1.1381364731415362\n",
      "\n",
      "Epoch 503 | Loss: 1.1351776264085476\n",
      "\n",
      "Epoch 504 | Loss: 1.132226566920212\n",
      "\n",
      "Epoch 505 | Loss: 1.1292832193211004\n",
      "\n",
      "Epoch 506 | Loss: 1.1263475090808266\n",
      "\n",
      "Epoch 507 | Loss: 1.1234193624857172\n",
      "\n",
      "Epoch 508 | Loss: 1.1204987066305836\n",
      "\n",
      "Epoch 509 | Loss: 1.1175854694105856\n",
      "\n",
      "Epoch 510 | Loss: 1.1146795795131914\n",
      "\n",
      "Epoch 511 | Loss: 1.1117809664102274\n",
      "\n",
      "Epoch 512 | Loss: 1.1088895603500202\n",
      "\n",
      "Epoch 513 | Loss: 1.1060052923496295\n",
      "\n",
      "Epoch 514 | Loss: 1.1031280941871682\n",
      "\n",
      "Epoch 515 | Loss: 1.1002578983942142\n",
      "\n",
      "Epoch 516 | Loss: 1.0973946382483037\n",
      "\n",
      "Epoch 517 | Loss: 1.0945382477655152\n",
      "\n",
      "Epoch 518 | Loss: 1.0916886616931365\n",
      "\n",
      "Epoch 519 | Loss: 1.0888458155024139\n",
      "\n",
      "Epoch 520 | Loss: 1.086009645381385\n",
      "\n",
      "Epoch 521 | Loss: 1.0831800882277958\n",
      "\n",
      "Epoch 522 | Loss: 1.0803570816420958\n",
      "\n",
      "Epoch 523 | Loss: 1.0775405639205122\n",
      "\n",
      "Epoch 524 | Loss: 1.074730474048205\n",
      "\n",
      "Epoch 525 | Loss: 1.071926751692497\n",
      "\n",
      "Epoch 526 | Loss: 1.069129337196186\n",
      "\n",
      "Epoch 527 | Loss: 1.0663381715709264\n",
      "\n",
      "Epoch 528 | Loss: 1.0635531964906906\n",
      "\n",
      "Epoch 529 | Loss: 1.0607743542853\n",
      "\n",
      "Epoch 530 | Loss: 1.0580015879340372\n",
      "\n",
      "Epoch 531 | Loss: 1.0552348410593178\n",
      "\n",
      "Epoch 532 | Loss: 1.0524740579204477\n",
      "\n",
      "Epoch 533 | Loss: 1.0497191834074397\n",
      "\n",
      "Epoch 534 | Loss: 1.0469701630349075\n",
      "\n",
      "Epoch 535 | Loss: 1.044226942936023\n",
      "\n",
      "Epoch 536 | Loss: 1.041489469856545\n",
      "\n",
      "Epoch 537 | Loss: 1.0387576911489154\n",
      "\n",
      "Epoch 538 | Loss: 1.0360315547664178\n",
      "\n",
      "Epoch 539 | Loss: 1.033311009257408\n",
      "\n",
      "Epoch 540 | Loss: 1.0305960037596023\n",
      "\n",
      "Epoch 541 | Loss: 1.0278864879944372\n",
      "\n",
      "Epoch 542 | Loss: 1.0251824122614863\n",
      "\n",
      "Epoch 543 | Loss: 1.0224837274329426\n",
      "\n",
      "Epoch 544 | Loss: 1.0197903849481629\n",
      "\n",
      "Epoch 545 | Loss: 1.0171023368082728\n",
      "\n",
      "Epoch 546 | Loss: 1.0144195355708305\n",
      "\n",
      "Epoch 547 | Loss: 1.0117419343445533\n",
      "\n",
      "Epoch 548 | Loss: 1.0090694867841001\n",
      "\n",
      "Epoch 549 | Loss: 1.0064021470849154\n",
      "\n",
      "Epoch 550 | Loss: 1.0037398699781273\n",
      "\n",
      "Epoch 551 | Loss: 1.001082610725504\n",
      "\n",
      "Epoch 552 | Loss: 0.9984303251144685\n",
      "\n",
      "Epoch 553 | Loss: 0.9957829694531647\n",
      "\n",
      "Epoch 554 | Loss: 0.9931405005655819\n",
      "\n",
      "Epoch 555 | Loss: 0.9905028757867332\n",
      "\n",
      "Epoch 556 | Loss: 0.9878700529578879\n",
      "\n",
      "Epoch 557 | Loss: 0.9852419904218513\n",
      "\n",
      "Epoch 558 | Loss: 0.982618647018305\n",
      "\n",
      "Epoch 559 | Loss: 0.9799999820791965\n",
      "\n",
      "Epoch 560 | Loss: 0.9773859554241766\n",
      "\n",
      "Epoch 561 | Loss: 0.97477652735609\n",
      "\n",
      "Epoch 562 | Loss: 0.9721716586565187\n",
      "\n",
      "Epoch 563 | Loss: 0.9695713105813683\n",
      "\n",
      "Epoch 564 | Loss: 0.9669754448565091\n",
      "\n",
      "Epoch 565 | Loss: 0.9643840236734619\n",
      "\n",
      "Epoch 566 | Loss: 0.9617970096851348\n",
      "\n",
      "Epoch 567 | Loss: 0.959214366001605\n",
      "\n",
      "Epoch 568 | Loss: 0.9566360561859458\n",
      "\n",
      "Epoch 569 | Loss: 0.9540620442501043\n",
      "\n",
      "Epoch 570 | Loss: 0.951492294650819\n",
      "\n",
      "Epoch 571 | Loss: 0.9489267722855896\n",
      "\n",
      "Epoch 572 | Loss: 0.9463654424886835\n",
      "\n",
      "Epoch 573 | Loss: 0.9438082710271929\n",
      "\n",
      "Epoch 574 | Loss: 0.9412552240971315\n",
      "\n",
      "Epoch 575 | Loss: 0.9387062683195769\n",
      "\n",
      "Epoch 576 | Loss: 0.9361613707368518\n",
      "\n",
      "Epoch 577 | Loss: 0.9336204988087524\n",
      "\n",
      "Epoch 578 | Loss: 0.9310836204088149\n",
      "\n",
      "Epoch 579 | Loss: 0.9285507038206238\n",
      "\n",
      "Epoch 580 | Loss: 0.9260217177341612\n",
      "\n",
      "Epoch 581 | Loss: 0.923496631242197\n",
      "\n",
      "Epoch 582 | Loss: 0.9209754138367178\n",
      "\n",
      "Epoch 583 | Loss: 0.9184580354053946\n",
      "\n",
      "Epoch 584 | Loss: 0.9159444662280909\n",
      "\n",
      "Epoch 585 | Loss: 0.9134346769734103\n",
      "\n",
      "Epoch 586 | Loss: 0.9109286386952776\n",
      "\n",
      "Epoch 587 | Loss: 0.9084263228295617\n",
      "\n",
      "Epoch 588 | Loss: 0.905927701190734\n",
      "\n",
      "Epoch 589 | Loss: 0.9034327459685635\n",
      "\n",
      "Epoch 590 | Loss: 0.9009414297248487\n",
      "\n",
      "Epoch 591 | Loss: 0.898453725390186\n",
      "\n",
      "Epoch 592 | Loss: 0.8959696062607708\n",
      "\n",
      "Epoch 593 | Loss: 0.8934890459952366\n",
      "\n",
      "Epoch 594 | Loss: 0.8910120186115276\n",
      "\n",
      "Epoch 595 | Loss: 0.888538498483807\n",
      "\n",
      "Epoch 596 | Loss: 0.8860684603393959\n",
      "\n",
      "Epoch 597 | Loss: 0.8836018792557496\n",
      "\n",
      "Epoch 598 | Loss: 0.8811387306574642\n",
      "\n",
      "Epoch 599 | Loss: 0.8786789903133164\n",
      "\n",
      "Epoch 600 | Loss: 0.8762226343333401\n",
      "\n",
      "Epoch 601 | Loss: 0.8737696391659243\n",
      "\n",
      "Epoch 602 | Loss: 0.8713199815949579\n",
      "\n",
      "Epoch 603 | Loss: 0.8688736387369904\n",
      "\n",
      "Epoch 604 | Loss: 0.8664305880384353\n",
      "\n",
      "Epoch 605 | Loss: 0.8639908072727966\n",
      "\n",
      "Epoch 606 | Loss: 0.8615542745379305\n",
      "\n",
      "Epoch 607 | Loss: 0.8591209682533332\n",
      "\n",
      "Epoch 608 | Loss: 0.8566908671574619\n",
      "\n",
      "Epoch 609 | Loss: 0.8542639503050808\n",
      "\n",
      "Epoch 610 | Loss: 0.8518401970646404\n",
      "\n",
      "Epoch 611 | Loss: 0.8494195871156812\n",
      "\n",
      "Epoch 612 | Loss: 0.847002100446269\n",
      "\n",
      "Epoch 613 | Loss: 0.844587717350456\n",
      "\n",
      "Epoch 614 | Loss: 0.8421764184257724\n",
      "\n",
      "Epoch 615 | Loss: 0.8397681845707382\n",
      "\n",
      "Epoch 616 | Loss: 0.8373629969824127\n",
      "\n",
      "Epoch 617 | Loss: 0.8349608371539606\n",
      "\n",
      "Epoch 618 | Loss: 0.8325616868722495\n",
      "\n",
      "Epoch 619 | Loss: 0.8301655282154737\n",
      "\n",
      "Epoch 620 | Loss: 0.8277723435508014\n",
      "\n",
      "Epoch 621 | Loss: 0.8253821155320482\n",
      "\n",
      "Epoch 622 | Loss: 0.8229948270973771\n",
      "\n",
      "Epoch 623 | Loss: 0.8206104614670209\n",
      "\n",
      "Epoch 624 | Loss: 0.8182290021410307\n",
      "\n",
      "Epoch 625 | Loss: 0.8158504328970493\n",
      "\n",
      "Epoch 626 | Loss: 0.8134747377881056\n",
      "\n",
      "Epoch 627 | Loss: 0.8111019011404365\n",
      "\n",
      "Epoch 628 | Loss: 0.8087319075513286\n",
      "\n",
      "Epoch 629 | Loss: 0.806364741886987\n",
      "\n",
      "Epoch 630 | Loss: 0.8040003892804216\n",
      "\n",
      "Epoch 631 | Loss: 0.8016388351293621\n",
      "\n",
      "Epoch 632 | Loss: 0.7992800650941898\n",
      "\n",
      "Epoch 633 | Loss: 0.7969240650958943\n",
      "\n",
      "Epoch 634 | Loss: 0.7945708213140535\n",
      "\n",
      "Epoch 635 | Loss: 0.7922203201848299\n",
      "\n",
      "Epoch 636 | Loss: 0.7898725483989929\n",
      "\n",
      "Epoch 637 | Loss: 0.7875274928999599\n",
      "\n",
      "Epoch 638 | Loss: 0.7851851408818605\n",
      "\n",
      "Epoch 639 | Loss: 0.7828454797876162\n",
      "\n",
      "Epoch 640 | Loss: 0.780508497307045\n",
      "\n",
      "Epoch 641 | Loss: 0.7781741813749852\n",
      "\n",
      "Epoch 642 | Loss: 0.7758425201694366\n",
      "\n",
      "Epoch 643 | Loss: 0.773513502109722\n",
      "\n",
      "Epoch 644 | Loss: 0.7711871158546709\n",
      "\n",
      "Epoch 645 | Loss: 0.7688633503008184\n",
      "\n",
      "Epoch 646 | Loss: 0.7665421945806229\n",
      "\n",
      "Epoch 647 | Loss: 0.7642236380607065\n",
      "\n",
      "Epoch 648 | Loss: 0.7619076703401082\n",
      "\n",
      "Epoch 649 | Loss: 0.7595942812485583\n",
      "\n",
      "Epoch 650 | Loss: 0.7572834608447723\n",
      "\n",
      "Epoch 651 | Loss: 0.7549751994147558\n",
      "\n",
      "Epoch 652 | Loss: 0.7526694874701338\n",
      "\n",
      "Epoch 653 | Loss: 0.7503663157464949\n",
      "\n",
      "Epoch 654 | Loss: 0.7480656752017493\n",
      "\n",
      "Epoch 655 | Loss: 0.7457675570145078\n",
      "\n",
      "Epoch 656 | Loss: 0.7434719525824747\n",
      "\n",
      "Epoch 657 | Loss: 0.7411788535208573\n",
      "\n",
      "Epoch 658 | Loss: 0.7388882516607927\n",
      "\n",
      "Epoch 659 | Loss: 0.7366001390477891\n",
      "\n",
      "Epoch 660 | Loss: 0.7343145079401815\n",
      "\n",
      "Epoch 661 | Loss: 0.7320313508076071\n",
      "\n",
      "Epoch 662 | Loss: 0.72975066032949\n",
      "\n",
      "Epoch 663 | Loss: 0.7274724293935461\n",
      "\n",
      "Epoch 664 | Loss: 0.7251966510942998\n",
      "\n",
      "Epoch 665 | Loss: 0.7229233187316154\n",
      "\n",
      "Epoch 666 | Loss: 0.7206524258092449\n",
      "\n",
      "Epoch 667 | Loss: 0.718383966033386\n",
      "\n",
      "Epoch 668 | Loss: 0.7161179333112596\n",
      "\n",
      "Epoch 669 | Loss: 0.7138543217496947\n",
      "\n",
      "Epoch 670 | Loss: 0.7115931256537336\n",
      "\n",
      "Epoch 671 | Loss: 0.7093343395252437\n",
      "\n",
      "Epoch 672 | Loss: 0.707077958061548\n",
      "\n",
      "Epoch 673 | Loss: 0.7048239761540649\n",
      "\n",
      "Epoch 674 | Loss: 0.7025723888869628\n",
      "\n",
      "Epoch 675 | Loss: 0.7003231915358273\n",
      "\n",
      "Epoch 676 | Loss: 0.6980763795663383\n",
      "\n",
      "Epoch 677 | Loss: 0.6958319486329632\n",
      "\n",
      "Epoch 678 | Loss: 0.693589894577659\n",
      "\n",
      "Epoch 679 | Loss: 0.6913502134285884\n",
      "\n",
      "Epoch 680 | Loss: 0.6891129013988446\n",
      "\n",
      "Epoch 681 | Loss: 0.6868779548851923\n",
      "\n",
      "Epoch 682 | Loss: 0.684645370466815\n",
      "\n",
      "Epoch 683 | Loss: 0.6824151449040771\n",
      "\n",
      "Epoch 684 | Loss: 0.6801872751372948\n",
      "\n",
      "Epoch 685 | Loss: 0.6779617582855201\n",
      "\n",
      "Epoch 686 | Loss: 0.6757385916453318\n",
      "\n",
      "Epoch 687 | Loss: 0.6735177726896407\n",
      "\n",
      "Epoch 688 | Loss: 0.6712992990665032\n",
      "\n",
      "Epoch 689 | Loss: 0.6690831685979451\n",
      "\n",
      "Epoch 690 | Loss: 0.6668693792787959\n",
      "\n",
      "Epoch 691 | Loss: 0.6646579292755324\n",
      "\n",
      "Epoch 692 | Loss: 0.6624488169251324\n",
      "\n",
      "Epoch 693 | Loss: 0.660242040733937\n",
      "\n",
      "Epoch 694 | Loss: 0.6580375993765241\n",
      "\n",
      "Epoch 695 | Loss: 0.6558354916945878\n",
      "\n",
      "Epoch 696 | Loss: 0.6536357166958306\n",
      "\n",
      "Epoch 697 | Loss: 0.6514382735528621\n",
      "\n",
      "Epoch 698 | Loss: 0.649243161602106\n",
      "\n",
      "Epoch 699 | Loss: 0.6470503803427183\n",
      "\n",
      "Epoch 700 | Loss: 0.6448599294355104\n",
      "\n",
      "Epoch 701 | Loss: 0.6426718087018832\n",
      "\n",
      "Epoch 702 | Loss: 0.6404860181227676\n",
      "\n",
      "Epoch 703 | Loss: 0.6383025578375742\n",
      "\n",
      "Epoch 704 | Loss: 0.636121428143149\n",
      "\n",
      "Epoch 705 | Loss: 0.6339426294927406\n",
      "\n",
      "Epoch 706 | Loss: 0.6317661624949682\n",
      "\n",
      "Epoch 707 | Loss: 0.6295920279128047\n",
      "\n",
      "Epoch 708 | Loss: 0.6274202266625603\n",
      "\n",
      "Epoch 709 | Loss: 0.6252507598128786\n",
      "\n",
      "Epoch 710 | Loss: 0.6230836285837352\n",
      "\n",
      "Epoch 711 | Loss: 0.6209188343454469\n",
      "\n",
      "Epoch 712 | Loss: 0.6187563786176837\n",
      "\n",
      "Epoch 713 | Loss: 0.616596263068491\n",
      "\n",
      "Epoch 714 | Loss: 0.6144384895133164\n",
      "\n",
      "Epoch 715 | Loss: 0.6122830599140414\n",
      "\n",
      "Epoch 716 | Loss: 0.6101299763780228\n",
      "\n",
      "Epoch 717 | Loss: 0.6079792411571365\n",
      "\n",
      "Epoch 718 | Loss: 0.6058308566468292\n",
      "\n",
      "Epoch 719 | Loss: 0.6036848253851761\n",
      "\n",
      "Epoch 720 | Loss: 0.6015411500519414\n",
      "\n",
      "Epoch 721 | Loss: 0.5993998334676486\n",
      "\n",
      "Epoch 722 | Loss: 0.5972608785926534\n",
      "\n",
      "Epoch 723 | Loss: 0.5951242885262203\n",
      "\n",
      "Epoch 724 | Loss: 0.5929900665056098\n",
      "\n",
      "Epoch 725 | Loss: 0.5908582159051632\n",
      "\n",
      "Epoch 726 | Loss: 0.5887287402353998\n",
      "\n",
      "Epoch 727 | Loss: 0.5866016431421133\n",
      "\n",
      "Epoch 728 | Loss: 0.5844769284054749\n",
      "\n",
      "Epoch 729 | Loss: 0.5823545999391417\n",
      "\n",
      "Epoch 730 | Loss: 0.5802346617893676\n",
      "\n",
      "Epoch 731 | Loss: 0.5781171181341205\n",
      "\n",
      "Epoch 732 | Loss: 0.5760019732822012\n",
      "\n",
      "Epoch 733 | Loss: 0.5738892316723705\n",
      "\n",
      "Epoch 734 | Loss: 0.5717788978724745\n",
      "\n",
      "Epoch 735 | Loss: 0.5696709765785787\n",
      "\n",
      "Epoch 736 | Loss: 0.5675654726141045\n",
      "\n",
      "Epoch 737 | Loss: 0.565462390928967\n",
      "\n",
      "Epoch 738 | Loss: 0.5633617365987187\n",
      "\n",
      "Epoch 739 | Loss: 0.5612635148236979\n",
      "\n",
      "Epoch 740 | Loss: 0.5591677309281756\n",
      "\n",
      "Epoch 741 | Loss: 0.5570743903595108\n",
      "\n",
      "Epoch 742 | Loss: 0.5549834986873059\n",
      "\n",
      "Epoch 743 | Loss: 0.5528950616025656\n",
      "\n",
      "Epoch 744 | Loss: 0.5508090849168594\n",
      "\n",
      "Epoch 745 | Loss: 0.5487255745614861\n",
      "\n",
      "Epoch 746 | Loss: 0.5466445365866412\n",
      "\n",
      "Epoch 747 | Loss: 0.5445659771605881\n",
      "\n",
      "Epoch 748 | Loss: 0.5424899025688291\n",
      "\n",
      "Epoch 749 | Loss: 0.5404163192132821\n",
      "\n",
      "Epoch 750 | Loss: 0.5383452336114566\n",
      "\n",
      "Epoch 751 | Loss: 0.5362766523956344\n",
      "\n",
      "Epoch 752 | Loss: 0.5342105823120507\n",
      "\n",
      "Epoch 753 | Loss: 0.5321470302200777\n",
      "\n",
      "Epoch 754 | Loss: 0.5300860030914107\n",
      "\n",
      "Epoch 755 | Loss: 0.5280275080092552\n",
      "\n",
      "Epoch 756 | Loss: 0.5259715521675168\n",
      "\n",
      "Epoch 757 | Loss: 0.523918142869991\n",
      "\n",
      "Epoch 758 | Loss: 0.5218672875295579\n",
      "\n",
      "Epoch 759 | Loss: 0.5198189936673737\n",
      "\n",
      "Epoch 760 | Loss: 0.5177732689120679\n",
      "\n",
      "Epoch 761 | Loss: 0.5157301209989388\n",
      "\n",
      "Epoch 762 | Loss: 0.5136895577691526\n",
      "\n",
      "Epoch 763 | Loss: 0.5116515871689421\n",
      "\n",
      "Epoch 764 | Loss: 0.5096162172488067\n",
      "\n",
      "Epoch 765 | Loss: 0.5075834561627145\n",
      "\n",
      "Epoch 766 | Loss: 0.505553312167303\n",
      "\n",
      "Epoch 767 | Loss: 0.5035257936210835\n",
      "\n",
      "Epoch 768 | Loss: 0.5015009089836432\n",
      "\n",
      "Epoch 769 | Loss: 0.49947866681485203\n",
      "\n",
      "Epoch 770 | Loss: 0.497459075774065\n",
      "\n",
      "Epoch 771 | Loss: 0.4954421446193285\n",
      "\n",
      "Epoch 772 | Loss: 0.4934278822065876\n",
      "\n",
      "Epoch 773 | Loss: 0.4914162974888906\n",
      "\n",
      "Epoch 774 | Loss: 0.489407399515597\n",
      "\n",
      "Epoch 775 | Loss: 0.48740119743158195\n",
      "\n",
      "Epoch 776 | Loss: 0.4853977004764471\n",
      "\n",
      "Epoch 777 | Loss: 0.4833969179837233\n",
      "\n",
      "Epoch 778 | Loss: 0.4813988593800801\n",
      "\n",
      "Epoch 779 | Loss: 0.4794035341845332\n",
      "\n",
      "Epoch 780 | Loss: 0.4774109520076486\n",
      "\n",
      "Epoch 781 | Loss: 0.4754211225507516\n",
      "\n",
      "Epoch 782 | Loss: 0.4734340556051322\n",
      "\n",
      "Epoch 783 | Loss: 0.47144976105125047\n",
      "\n",
      "Epoch 784 | Loss: 0.4694682488579433\n",
      "\n",
      "Epoch 785 | Loss: 0.46748952908162805\n",
      "\n",
      "Epoch 786 | Loss: 0.46551361186550794\n",
      "\n",
      "Epoch 787 | Loss: 0.46354050743877534\n",
      "\n",
      "Epoch 788 | Loss: 0.46157022611581505\n",
      "\n",
      "Epoch 789 | Loss: 0.45960277829540735\n",
      "\n",
      "Epoch 790 | Loss: 0.45763817445992816\n",
      "\n",
      "Epoch 791 | Loss: 0.45567642517455115\n",
      "\n",
      "Epoch 792 | Loss: 0.4537175410864468\n",
      "\n",
      "Epoch 793 | Loss: 0.45176153292398086\n",
      "\n",
      "Epoch 794 | Loss: 0.4498084114959128\n",
      "\n",
      "Epoch 795 | Loss: 0.4478581876905919\n",
      "\n",
      "Epoch 796 | Loss: 0.44591087247515276\n",
      "\n",
      "Epoch 797 | Loss: 0.443966476894709\n",
      "\n",
      "Epoch 798 | Loss: 0.44202501207154704\n",
      "\n",
      "Epoch 799 | Loss: 0.44008648920431626\n",
      "\n",
      "Epoch 800 | Loss: 0.4381509195672205\n",
      "\n",
      "Epoch 801 | Loss: 0.43621831450920545\n",
      "\n",
      "Epoch 802 | Loss: 0.43428868545314586\n",
      "\n",
      "Epoch 803 | Loss: 0.4323620438950315\n",
      "\n",
      "Epoch 804 | Loss: 0.43043840140315054\n",
      "\n",
      "Epoch 805 | Loss: 0.42851776961727156\n",
      "\n",
      "Epoch 806 | Loss: 0.4266001602478244\n",
      "\n",
      "Epoch 807 | Loss: 0.4246855850750774\n",
      "\n",
      "Epoch 808 | Loss: 0.4227740559483159\n",
      "\n",
      "Epoch 809 | Loss: 0.4208655847850152\n",
      "\n",
      "Epoch 810 | Loss: 0.4189601835700141\n",
      "\n",
      "Epoch 811 | Loss: 0.41705786435468595\n",
      "\n",
      "Epoch 812 | Loss: 0.4151586392561065\n",
      "\n",
      "Epoch 813 | Loss: 0.41326252045622086\n",
      "\n",
      "Epoch 814 | Loss: 0.41136952020100764\n",
      "\n",
      "Epoch 815 | Loss: 0.40947965079964116\n",
      "\n",
      "Epoch 816 | Loss: 0.40759292462365104\n",
      "\n",
      "Epoch 817 | Loss: 0.4057093541060803\n",
      "\n",
      "Epoch 818 | Loss: 0.4038289517406395\n",
      "\n",
      "Epoch 819 | Loss: 0.4019517300808603\n",
      "\n",
      "Epoch 820 | Loss: 0.40007770173924484\n",
      "\n",
      "Epoch 821 | Loss: 0.3982068793864137\n",
      "\n",
      "Epoch 822 | Loss: 0.39633927575025185\n",
      "\n",
      "Epoch 823 | Loss: 0.39447490361504967\n",
      "\n",
      "Epoch 824 | Loss: 0.3926137758206436\n",
      "\n",
      "Epoch 825 | Loss: 0.3907559052615533\n",
      "\n",
      "Epoch 826 | Loss: 0.3889013048861154\n",
      "\n",
      "Epoch 827 | Loss: 0.3870499876956155\n",
      "\n",
      "Epoch 828 | Loss: 0.38520196674341683\n",
      "\n",
      "Epoch 829 | Loss: 0.3833572551340859\n",
      "\n",
      "Epoch 830 | Loss: 0.38151586602251525\n",
      "\n",
      "Epoch 831 | Loss: 0.3796778126130439\n",
      "\n",
      "Epoch 832 | Loss: 0.37784310815857275\n",
      "\n",
      "Epoch 833 | Loss: 0.37601176595968033\n",
      "\n",
      "Epoch 834 | Loss: 0.3741837993637314\n",
      "\n",
      "Epoch 835 | Loss: 0.372359221763987\n",
      "\n",
      "Epoch 836 | Loss: 0.37053804659870565\n",
      "\n",
      "Epoch 837 | Loss: 0.368720287350247\n",
      "\n",
      "Epoch 838 | Loss: 0.3669059575441686\n",
      "\n",
      "Epoch 839 | Loss: 0.3650950707483205\n",
      "\n",
      "Epoch 840 | Loss: 0.3632876405719355\n",
      "\n",
      "Epoch 841 | Loss: 0.3614836806647188\n",
      "\n",
      "Epoch 842 | Loss: 0.3596832047159305\n",
      "\n",
      "Epoch 843 | Loss: 0.35788622645346757\n",
      "\n",
      "Epoch 844 | Loss: 0.35609275964293985\n",
      "\n",
      "Epoch 845 | Loss: 0.35430281808674563\n",
      "\n",
      "Epoch 846 | Loss: 0.3525164156231401\n",
      "\n",
      "Epoch 847 | Loss: 0.3507335661253026\n",
      "\n",
      "Epoch 848 | Loss: 0.3489542835003997\n",
      "\n",
      "Epoch 849 | Loss: 0.3471785816886435\n",
      "\n",
      "Epoch 850 | Loss: 0.3454064746623484\n",
      "\n",
      "Epoch 851 | Loss: 0.34363797642498084\n",
      "\n",
      "Epoch 852 | Loss: 0.34187310101020896\n",
      "\n",
      "Epoch 853 | Loss: 0.34011186248094527\n",
      "\n",
      "Epoch 854 | Loss: 0.3383542749283878\n",
      "\n",
      "Epoch 855 | Loss: 0.33660035247105546\n",
      "\n",
      "Epoch 856 | Loss: 0.33485010925381986\n",
      "\n",
      "Epoch 857 | Loss: 0.33310355944693515\n",
      "\n",
      "Epoch 858 | Loss: 0.3313607172450602\n",
      "\n",
      "Epoch 859 | Loss: 0.3296215968662808\n",
      "\n",
      "Epoch 860 | Loss: 0.32788621255112416\n",
      "\n",
      "Epoch 861 | Loss: 0.32615457856157126\n",
      "\n",
      "Epoch 862 | Loss: 0.3244267091800651\n",
      "\n",
      "Epoch 863 | Loss: 0.32270261870851413\n",
      "\n",
      "Epoch 864 | Loss: 0.3209823214672911\n",
      "\n",
      "Epoch 865 | Loss: 0.31926583179422907\n",
      "\n",
      "Epoch 866 | Loss: 0.31755316404361184\n",
      "\n",
      "Epoch 867 | Loss: 0.3158443325851604\n",
      "\n",
      "Epoch 868 | Loss: 0.3141393518030158\n",
      "\n",
      "Epoch 869 | Loss: 0.3124382360947165\n",
      "\n",
      "Epoch 870 | Loss: 0.31074099987017223\n",
      "\n",
      "Epoch 871 | Loss: 0.3090476575506326\n",
      "\n",
      "Epoch 872 | Loss: 0.3073582235676528\n",
      "\n",
      "Epoch 873 | Loss: 0.30567271236205235\n",
      "\n",
      "Epoch 874 | Loss: 0.30399113838287234\n",
      "\n",
      "Epoch 875 | Loss: 0.30231351608632545\n",
      "\n",
      "Epoch 876 | Loss: 0.3006398599347433\n",
      "\n",
      "Epoch 877 | Loss: 0.2989701843955183\n",
      "\n",
      "Epoch 878 | Loss: 0.2973045039400411\n",
      "\n",
      "Epoch 879 | Loss: 0.2956428330426334\n",
      "\n",
      "Epoch 880 | Loss: 0.29398518617947633\n",
      "\n",
      "Epoch 881 | Loss: 0.29233157782753416\n",
      "\n",
      "Epoch 882 | Loss: 0.29068202246347297\n",
      "\n",
      "Epoch 883 | Loss: 0.28903653456257494\n",
      "\n",
      "Epoch 884 | Loss: 0.28739512859764793\n",
      "\n",
      "Epoch 885 | Loss: 0.2857578190379301\n",
      "\n",
      "Epoch 886 | Loss: 0.28412462034799\n",
      "\n",
      "Epoch 887 | Loss: 0.28249554698662144\n",
      "\n",
      "Epoch 888 | Loss: 0.2808706134057344\n",
      "\n",
      "Epoch 889 | Loss: 0.2792498340492403\n",
      "\n",
      "Epoch 890 | Loss: 0.2776332233519332\n",
      "\n",
      "Epoch 891 | Loss: 0.27602079573836497\n",
      "\n",
      "Epoch 892 | Loss: 0.27441256562171734\n",
      "\n",
      "Epoch 893 | Loss: 0.2728085474026669\n",
      "\n",
      "Epoch 894 | Loss: 0.27120875546824785\n",
      "\n",
      "Epoch 895 | Loss: 0.2696132041907071\n",
      "\n",
      "Epoch 896 | Loss: 0.268021907926357\n",
      "\n",
      "Epoch 897 | Loss: 0.2664348810144207\n",
      "\n",
      "Epoch 898 | Loss: 0.2648521377758751\n",
      "\n",
      "Epoch 899 | Loss: 0.2632736925122866\n",
      "\n",
      "Epoch 900 | Loss: 0.26169955950464346\n",
      "\n",
      "Epoch 901 | Loss: 0.2601297530121827\n",
      "\n",
      "Epoch 902 | Loss: 0.25856428727121156\n",
      "\n",
      "Epoch 903 | Loss: 0.2570031764939251\n",
      "\n",
      "Epoch 904 | Loss: 0.2554464348672175\n",
      "\n",
      "Epoch 905 | Loss: 0.2538940765514896\n",
      "\n",
      "Epoch 906 | Loss: 0.25234611567945103\n",
      "\n",
      "Epoch 907 | Loss: 0.2508025663549169\n",
      "\n",
      "Epoch 908 | Loss: 0.24926344265160036\n",
      "\n",
      "Epoch 909 | Loss: 0.24772875861189958\n",
      "\n",
      "Epoch 910 | Loss: 0.24619852824568028\n",
      "\n",
      "Epoch 911 | Loss: 0.24467276552905223\n",
      "\n",
      "Epoch 912 | Loss: 0.24315148440314296\n",
      "\n",
      "Epoch 913 | Loss: 0.24163469877286367\n",
      "\n",
      "Epoch 914 | Loss: 0.24012242250567284\n",
      "\n",
      "Epoch 915 | Loss: 0.23861466943033324\n",
      "\n",
      "Epoch 916 | Loss: 0.23711145333566475\n",
      "\n",
      "Epoch 917 | Loss: 0.23561278796929186\n",
      "\n",
      "Epoch 918 | Loss: 0.2341186870363871\n",
      "\n",
      "Epoch 919 | Loss: 0.2326291641984085\n",
      "\n",
      "Epoch 920 | Loss: 0.2311442330718329\n",
      "\n",
      "Epoch 921 | Loss: 0.22966390722688462\n",
      "\n",
      "Epoch 922 | Loss: 0.22818820018625863\n",
      "\n",
      "Epoch 923 | Loss: 0.22671712542383907\n",
      "\n",
      "Epoch 924 | Loss: 0.22525069636341372\n",
      "\n",
      "Epoch 925 | Loss: 0.2237889263773829\n",
      "\n",
      "Epoch 926 | Loss: 0.2223318287854644\n",
      "\n",
      "Epoch 927 | Loss: 0.2208794168533925\n",
      "\n",
      "Epoch 928 | Loss: 0.2194317037916142\n",
      "\n",
      "Epoch 929 | Loss: 0.21798870275397877\n",
      "\n",
      "Epoch 930 | Loss: 0.21655042683642442\n",
      "\n",
      "Epoch 931 | Loss: 0.21511688907565923\n",
      "\n",
      "Epoch 932 | Loss: 0.2136881024478388\n",
      "\n",
      "Epoch 933 | Loss: 0.21226407986723722\n",
      "\n",
      "Epoch 934 | Loss: 0.2108448341849169\n",
      "\n",
      "Epoch 935 | Loss: 0.2094303781873907\n",
      "\n",
      "Epoch 936 | Loss: 0.20802072459528187\n",
      "\n",
      "Epoch 937 | Loss: 0.20661588606197906\n",
      "\n",
      "Epoch 938 | Loss: 0.20521587517228634\n",
      "\n",
      "Epoch 939 | Loss: 0.2038207044410708\n",
      "\n",
      "Epoch 940 | Loss: 0.20243038631190416\n",
      "\n",
      "Epoch 941 | Loss: 0.20104493315570085\n",
      "\n",
      "Epoch 942 | Loss: 0.19966435726935342\n",
      "\n",
      "Epoch 943 | Loss: 0.19828867087436158\n",
      "\n",
      "Epoch 944 | Loss: 0.19691788611545913\n",
      "\n",
      "Epoch 945 | Loss: 0.19555201505923683\n",
      "\n",
      "Epoch 946 | Loss: 0.19419106969276093\n",
      "\n",
      "Epoch 947 | Loss: 0.1928350619221882\n",
      "\n",
      "Epoch 948 | Loss: 0.1914840035713776\n",
      "\n",
      "Epoch 949 | Loss: 0.1901379063804984\n",
      "\n",
      "Epoch 950 | Loss: 0.18879678200463443\n",
      "\n",
      "Epoch 951 | Loss: 0.1874606420123851\n",
      "\n",
      "Epoch 952 | Loss: 0.18612949788446356\n",
      "\n",
      "Epoch 953 | Loss: 0.18480336101229156\n",
      "\n",
      "Epoch 954 | Loss: 0.18348224269659014\n",
      "\n",
      "Epoch 955 | Loss: 0.18216615414596882\n",
      "\n",
      "Epoch 956 | Loss: 0.18085510647551115\n",
      "\n",
      "Epoch 957 | Loss: 0.1795491107053569\n",
      "\n",
      "Epoch 958 | Loss: 0.1782481777592827\n",
      "\n",
      "Epoch 959 | Loss: 0.176952318463279\n",
      "\n",
      "Epoch 960 | Loss: 0.17566154354412553\n",
      "\n",
      "Epoch 961 | Loss: 0.17437586362796295\n",
      "\n",
      "Epoch 962 | Loss: 0.17309528923886383\n",
      "\n",
      "Epoch 963 | Loss: 0.17181983079740004\n",
      "\n",
      "Epoch 964 | Loss: 0.1705494986192094\n",
      "\n",
      "Epoch 965 | Loss: 0.16928430291355945\n",
      "\n",
      "Epoch 966 | Loss: 0.16802425378190922\n",
      "\n",
      "Epoch 967 | Loss: 0.1667693612164707\n",
      "\n",
      "Epoch 968 | Loss: 0.16551963509876774\n",
      "\n",
      "Epoch 969 | Loss: 0.16427508519819317\n",
      "\n",
      "Epoch 970 | Loss: 0.16303572117056572\n",
      "\n",
      "Epoch 971 | Loss: 0.1618015525566858\n",
      "\n",
      "Epoch 972 | Loss: 0.16057258878088876\n",
      "\n",
      "Epoch 973 | Loss: 0.1593488391495994\n",
      "\n",
      "Epoch 974 | Loss: 0.15813031284988516\n",
      "\n",
      "Epoch 975 | Loss: 0.15691701894800741\n",
      "\n",
      "Epoch 976 | Loss: 0.15570896638797474\n",
      "\n",
      "Epoch 977 | Loss: 0.15450616399009462\n",
      "\n",
      "Epoch 978 | Loss: 0.1533086204495252\n",
      "\n",
      "Epoch 979 | Loss: 0.15211634433482793\n",
      "\n",
      "Epoch 980 | Loss: 0.15092934408651978\n",
      "\n",
      "Epoch 981 | Loss: 0.1497476280156266\n",
      "\n",
      "Epoch 982 | Loss: 0.14857120430223722\n",
      "\n",
      "Epoch 983 | Loss: 0.14740008099405777\n",
      "\n",
      "Epoch 984 | Loss: 0.146234266004968\n",
      "\n",
      "Epoch 985 | Loss: 0.14507376711357892\n",
      "\n",
      "Epoch 986 | Loss: 0.14391859196179083\n",
      "\n",
      "Epoch 987 | Loss: 0.1427687480533543\n",
      "\n",
      "Epoch 988 | Loss: 0.14162424275243313\n",
      "\n",
      "Epoch 989 | Loss: 0.14048508328216847\n",
      "\n",
      "Epoch 990 | Loss: 0.13935127672324574\n",
      "\n",
      "Epoch 991 | Loss: 0.1382228300124648\n",
      "\n",
      "Epoch 992 | Loss: 0.13709974994131255\n",
      "\n",
      "Epoch 993 | Loss: 0.13598204315453805\n",
      "\n",
      "Epoch 994 | Loss: 0.13486971614873192\n",
      "\n",
      "Epoch 995 | Loss: 0.1337627752709081\n",
      "\n",
      "Epoch 996 | Loss: 0.13266122671709074\n",
      "\n",
      "Epoch 997 | Loss: 0.13156507653090463\n",
      "\n",
      "Epoch 998 | Loss: 0.1304743306021689\n",
      "\n",
      "Epoch 999 | Loss: 0.12938899466549647\n"
     ]
    }
   ],
   "source": [
    "model = Model(layer=Dense)\n",
    "model.compile(loss=MSELoss(), optimizer=Adam(learning_rate=0.01))\n",
    "\n",
    "X_train = np.random.normal(0, 1, (100,3))\n",
    "y_train = np.array(\n",
    "    [[x1 * 1.5 + x3 * 3.5, x2 * 2.5 + x3 * 3.5] for x1, x2, x3 in X_train]\n",
    ")\n",
    "\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
