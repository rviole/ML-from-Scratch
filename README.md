# Machine Learning Projects From Scratch
A set of Machine Learning Projects developer from scratch. Serves as a Portfolio project.

# ðŸš§ In progress ...

## Repository Structure

### `> ./Gradient-Descent/`

| Filename                  | Description                                              | Link       |
|---------------------------|----------------------------------------------------------|------------|
| gradient-descent-1.ipynb  | Basic gradient descent implementation without optimization. | [Link](#)  |
| gradient-descent-2.ipynb  | Added learning rate scheduling for better convergence.    | [Link](#)  |
| gradient-descent-3.ipynb  | Introduced momentum-based optimizer for stability.        | [Link](#)  |
| gradient-descent-4.ipynb  | Implemented Adam optimizer with bias correction.          | [Link](#)  |
| mini-batch-gd.ipynb       | Mini-batch gradient descent with MSE and Adam optimizer.  | [Link](#)  |

### `> ./models/`

| Filename                  | Description                                              | Link       |
|---------------------------|----------------------------------------------------------|------------|
| 1_Dense_MultiOut.ipynb    | Dense layer with multiple outputs and Adam optimizer.     | [Link](#)  |
| 2_Dense_SingleOut.ipynb   | Dense layer with single output and MSE loss.              | [Link](#)  |
| 3_sequential-test-1.ipynb | Sequential model with multiple dense layers.              | [Link](#)  |
